{"pages":[{"title":"About","text":"","link":"/About/index.html"},{"title":"categories","text":"","link":"/categories/index.html"},{"title":"Tags","text":"","link":"/tags/index.html"},{"title":"Project","text":"","link":"/project/index.html"}],"posts":[{"title":"C++学习笔记-多态","text":"多态指不同的对象发送同一个消息，不同对象对应同一消息产生不同行为。多态存在于具有继承关系的类中，当父类函数被申明为虚函数，子类重写了父类虚函数时，就具备了多态发生的条件。 多态1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/* C++学习笔记：面向对象，多态*/#include &lt;iostream&gt;class Animal{public: void bark() { std::cout &lt;&lt; \"动物叫...\" &lt;&lt; std::endl; }};class Dog: public Animal{public: void bark() { std::cout &lt;&lt; \"wang wang wang ...\" &lt;&lt; std::endl; }};class Cat: public Animal{public: void bark() { std::cout &lt;&lt; \"miao miao miao ...\" &lt;&lt; std::endl; }};void animalBark(Animal *animal){ animal-&gt;bark();}int main(){ Animal *animal = new Animal(); Dog *dog = new Dog(); Cat *cat = new Cat(); animalBark(animal); animalBark(dog); animalBark(cat); return 0;} 123动物叫...动物叫...动物叫... 父类函数添加 virtual ，将其声明为虚函数。 12345678class Animal{public: virtual void bark() { std::cout &lt;&lt; \"动物叫...\" &lt;&lt; std::endl; }}; 123动物叫...wang wang wang ...miao miao miao ... 基类中的虚函数是一个使用关键字 virtual 声明的函数。派生类中已经对函数进行定义的情况下，定义一个基类的虚函数，就是要告诉编译器我们不想对这个函数进行静态链接。 我们所希望的是根据调用函数的对象的类型对程序中在任何给定指针中被调用的函数的选择。这种操作被称为动态链接，或者后期绑定。 多态的三个条件 类间存在继承 要有虚函数重写 父类指针或引用指向子类对象 重载、重写、重定义重载：同一个类中函数名相同，参数列表相同。以下代码表示 bark() 函数的重载。 12345678910111213141516class Animal{private: std::string name;public: virtual void bark() { std::cout &lt;&lt; \"动物叫...\" &lt;&lt; std::endl; } virtual void bark(std::string name) { std::cout &lt;&lt; name &lt;&lt; \"正在叫...\" &lt;&lt; std::endl; }}; 重写：指子类覆盖父类的虚函数，要求函数名和参数均相同，如下所示： 1234567891011121314151617class Animal{public: virtual void bark() { std::cout &lt;&lt; \"动物叫...\" &lt;&lt; std::endl; }};class Dog: public Animal{public: void bark() { std::cout &lt;&lt; \"wang wang wang ...\" &lt;&lt; std::endl; }};","link":"/post/e7609a12.html"},{"title":"C++学习笔记-引用","text":"引用格式一个已存在变量的别名，通过这个别名就可以用来修改指向的变量的值。引用和指针很像，在很多情况下就是简化版的指针。引用比指针弱的地方在于引用必须在创建时初始化，并且不能再改变指向的对象，而指针可以为空，也可以改变指向的内存地址。 引用的基本规则12345678910111213141516171819202122232425262728293031#include &lt;iostream&gt;int main(){ int a = 10; // 定义一个 a int &amp;b = a; // 定义一个 a 的引用 int *p = &amp;a; // 定义一个指向 a 的指针 *p = 20; std::cout &lt;&lt; \"a = \" &lt;&lt; a &lt;&lt; std::endl; b = 30; std::cout &lt;&lt; \"a = \" &lt;&lt; a &lt;&lt; \" , b = \" &lt;&lt; b &lt;&lt; std::endl; ///////////////////////////////////////////////////// int c; // &amp;b = c; 错误，b 已经是 a 的引用，不可修改引用关系 // float &amp;f = c; 错误，引用类型不匹配 int &amp;bb = b; // 可以引用一个引用 bb = 40; std::cout &lt;&lt; \"a = \" &lt;&lt; a &lt;&lt; \" , b = \" &lt;&lt; b &lt;&lt; \" , bb = \" &lt;&lt; bb &lt;&lt; std::endl; return 0;} 引用的使用方式 typename &amp;b = a, &amp; 符号前有符号表示引用，否则表示取地址 引用是一种关系申明，表示它和某个变量的关系，它们类型相同，并共享一片内存 引用一经申明就不可以修改 可以引用一个引用 引用作为函数参数12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#include &lt;iostream&gt;struct Person{ char name[50]; int age;};void printfA(Person *p);void printfB(Person &amp;p);void printfC(Person p);int main(){ Person person = {\"aaaa\", 18}; std::cout &lt;&lt; \"==========参数为指针类型==========\" &lt;&lt; std::endl; printfA(&amp;person); std::cout &lt;&lt; \"third time = \" &lt;&lt; person.age &lt;&lt; std::endl; std::cout &lt;&lt; \"==========参数为引用类型==========\" &lt;&lt; std::endl; printfB(person); std::cout &lt;&lt; \"third time = \" &lt;&lt; person.age &lt;&lt; std::endl; std::cout &lt;&lt; \"==========参数为结构体类型==========\" &lt;&lt; std::endl; printfC(person); std::cout &lt;&lt; \"third time = \" &lt;&lt; person.age &lt;&lt; std::endl; return 0;}// 指针类型，同一块内存上操作void printfA(Person *p){ std::cout &lt;&lt; \"first time = \" &lt;&lt; p-&gt;age &lt;&lt; std::endl; p-&gt;age = 20; std::cout &lt;&lt; \"second time = \" &lt;&lt; p-&gt;age &lt;&lt; std::endl;}// 引用类型，同一块内存上操作void printfB(Person &amp;p){ std::cout &lt;&lt; \"first time = \" &lt;&lt; p.age &lt;&lt; std::endl; p.age = 30; std::cout &lt;&lt; \"second time = \" &lt;&lt; p.age &lt;&lt; std::endl;}// 结构体类型，形参的修改在栈区上void printfC(Person p){ std::cout &lt;&lt; \"first time = \" &lt;&lt; p.age &lt;&lt; std::endl; p.age = 40; std::cout &lt;&lt; \"second time = \" &lt;&lt; p.age &lt;&lt; std::endl;} 123456789101112==========参数为指针类型==========first time = 18second time = 20third time = 20==========参数为引用类型==========first time = 20second time = 30third time = 30==========参数为结构体类型==========first time = 30second time = 40third time = 30 以上这段代码分别将一个结构体用指针形式、引用形式和结构体变量形式作为形参传入到函数中，并对其值进行修改，最后打印结果。 我们可以看到指针类型和引用类型对变量进行修改，因为它们都指向同一块内存。结构体类型，形参的修改在栈区上，并不会对堆区中的结构体变量本身产生影响。 注：关于堆区、栈区的内存四区概念有问题可以看 C语言学习笔记-指针01。 引用是一个变量的别名，有时候起到和指针一样的效果 引用比指针具有更强的可读性 引用作为函数返回值 若返回栈变量: 不能成为其它引用的初始值(不能作为左值使用) 若返回静态变量或全局变量: 可以成为其他引用的初始值(可作为右值使用,也可作为左值使用) 引用作为函数返回-值返回栈变量代码示例 引用作为函数返回-值返回静态变量代码示例 指针引用都在代码里了，关键代码如下，点击查看完整示例 12345678910111213141516171819202122232425262728293031int getTeacher(Teacher **teacher){ Teacher *t = NULL; t = (Teacher*)malloc(sizeof(Teacher)); if(t == NULL) { return -1; } strcpy(t-&gt;name, \"Mary\"); t-&gt;age = 30; *teacher = t; return 0;}int getTeacher02(Teacher *&amp;teacher){ teacher = (Teacher *)malloc(sizeof(Teacher)); if(teacher == NULL) { return -1; } strcpy(teacher-&gt;name, \"Lucy\"); teacher-&gt;age = 20; return 0;} const 引用const 最常见的作用就是在变量作为函数形参的时候加上 const 修饰，起到对形参的保护作用，加了 const 修饰的参数就不会在函数中被修改。 const 如果和引用放在一起会擦出什么火花？ 12345678const int a = 10;// int &amp;b = a; errconst int &amp;b = a;int c = 20;const int &amp;d = c;// d = 30; errc = 30; 第一组代码想说明的是 const 修饰的常量，如果我想用一直普通的引用指向它是不可以的。假设我们可以用一个普通的 b 做为 a 的引用，那就可以使用 b 去修改 a 所指代的内存，而 a 指向的内存是被 const 保护的，是不允许修改的。不过我们可以使用 const 修饰的引用去指向 a，此时他们的安全级别一样，都不会导致内存被修改的安全问题。 第二组代码想说明的 const 修饰的引用安全级别更高，可以用安全级别高的去引用安全级别低的。这时候造成的现象是 d 被 const 修饰不能修改，而 c 任然可以修改，虽然是同一片内存但是 d 也无法阻止 c 进行修改。 1234void printA(const Teacher &amp;teacher) { //teacher.age = 33; printf(\"teacher.age:%d \\n\", teacher.age);} 上面这段代码则表示 const 修饰的形参是只读的，不允许在函数中进行修改，起到了保护形参的作用。 总结一下： const 引用可以指向安全级别比其低的或者同级的 const 引用常在形参传递过程中起保护形参的作用","link":"/post/824d7309.html"},{"title":"C/C++ 中的命令行参数","text":"C/C++ 中的 main 函数经常带有 argc, argv ,比如 int main(int argc, char** argv) 或者 int main(int argc, char* argv[])，其中 argc 表示我们从命令行键入的参数，argv[] 即为参数列表。 Java 中的 public static void main(String argc[]) 和 Python 中的 sys.argv 中也都带有命令行参数。 通过命令行参数我们可以就能由 main 函数入口传递参数到程序内部。 1234567891011#include &lt;stdio.h&gt; int main(int argc, char ** argv) { int i; for (i=0; i &lt; argc; i++) printf(\"Argument %d is %s.\\n\", i, argv[i]); return 0; } 加入我们编译之后运行 ./hello a b c d 将会输出 12345Argument 0 is ./hello.Argument 1 is a.Argument 2 is b.Argument 3 is c.Argument 4 is d. 由此得出两个结论 参数列表中包含 ./hello 参数个数要算上 ./hello","link":"/post/b482364a.html"},{"title":"C++学习笔记-内联函数、默认参数和函数重载","text":"内联函数能够将函数体直接插入在函数调用的位置，减少了函数调用时出栈、入栈的过程，提高程序性能。 默认参数与占位符让我们在定义函数的时候能够设置默认值，提高了函数定义的灵活性。 函数的重载则允许我们在参数列表不同的情况下使用同名函数，解除了 C 语言中函数名必须不同的限制。 以上都是 C++ 在 C 语言基础上对函数定义的扩展，可以放在一起进行学习。 inline 内联函数123456789101112// 主函数循环调用 my_min() 函数for(int i = 0; i &lt; 1000; i++){ min = my_min(a, b); cout &lt;&lt; \"min = \" &lt;&lt; min &lt;&lt; endl;}// 比较两个值的大小int my_min(int a, int b){ return (a &lt; b ? a : b);} 当主函数调用函数的时候会有频繁的入栈、出栈操作。如果想减少这部分时间开销，在 C 语言中我们使用宏定义，在 C++ 中使用内联函数。 1234567#define MY_MAX(a, b) ((a) &lt; (b) ? (a) : (b))for(int i = 0; i &lt; 1000; i++){ min = MY_MAX(a, b); cout &lt;&lt; \"min = \" &lt;&lt; min &lt;&lt; endl;} 使用 C 语言中的宏定义我们可以让被调用的函数由预编译器展开，不会再有出栈入栈的过程，然而这样做存在一个问题。由于宏定义在编译的时候就展开，如果使用 MY_MAX(a++, b++) 的方式调用就会被展开成 MY_MAX(a++, b++) ((a++) &lt; (b++) ? (a++) : (b++))。 C++ 采用 inline 关键字来申明一个内联函数。内联函数是一种特殊的函数,具有普通函数的特征，但是C++编译器直接将函数体插入在函数调用的地方。 12345// inline 关键字修饰的内联函数inline int my_max(int a, int b){ return (a &gt; b ? a : b);} 最后是内联函数使用的注意事项: 不能存在任何形式的循环语句 不能存在过多的条件判断语句 不能对函数进行取址操作 函数内联声明必须在调用语句之前 默认参数与占位符默认参数与占位符用于 C++ 定义函数的时候，相对于 C 语言有有更多的特性。 1234567891011121314151617#include &lt;iostream&gt;int function_name(int a, int b = 10){ std::cout &lt;&lt; \"a = \" &lt;&lt; a &lt;&lt; \" b = \" &lt;&lt; b &lt;&lt; std::endl;}int main(){ int a = 20; int b = 30; function_name(a, b); function_name(a); return 0;} 在函数 int function_name(int a, int b = 10) 中，我们在函数定义的过程中给 b 一个默认值，当函数调用时如果未传入 b 就会使用默认的 b 的值。 关于默认参数有这样几条规则 可以有多个默认值 默认值必须从后面写起 typename function_name(int a, int b, ... int x =10, int y =20) 一旦在一个函数调用中开始使用默认参数值,那么这个参数后的所有参数都必须使用默认参数值 占位符就感觉比较鸡肋了,我们使用一个没有名字的只有类型的形参作为占位符，但因为它没有名字，在函数中也没有办法使用。 1234567891011// 占位符int func(int a, int b, int) { return (a + b);}// 占位符并赋予默认值int func(int a, int b, int = 10) { return (a + b);} 函数重载12int funtion_name(int a, int b);int funtion_name(int a); 以上这段代码在 C 语言中是会报错的，因为 C 语言禁止函数同名，而在 C++ 中这样是允许的，被称为函数重载。 一个函数包含这样三个部分 返回值类型 方法名名称 参数列表（参数类型，参数个数） 1234void func(int a);//okvoid func(char a);//ok, 参数个数相同，参数类型不同 void func(int a, int b);//ok 参数个数不同char func(int a);//error,与第一一个函数有冲突","link":"/post/e95932f5.html"},{"title":"C++学习笔记-构造函数、析构函数、拷贝构造函数","text":"C++ 引入了面向对象的概念，面向对象的思想能够抽象出现实世界的实体，以此解决更加复杂的问题。 类是面向对象的核心，类即是我们对事物抽象之后的产物。C++ 中的类用 class 关键字修饰，后面紧跟着类名 class ClassName。 现实世界的实体应该怎么抽象？一部分抽象为是事物的基本属性，一部分抽象为事物的行为。以抽象一只狗为例，狗的基本属性比如说有品种、年龄、毛色、重量等，而它的行为比如说有奔跑、行走、吃东西、叫等。 类中就用变量来表示事物的基本属性，行为则用函数来表示，这就是面向对象思想的核心。在此基础上又有继承、多态等概念，也是为了进一步表现对象与对象之间的关系。 本文讲的是 C++ 中类的构造函数、析构函数以及拷贝构造函数。构造函数区别于普通的函数，是专门用来初始化一个对象的；析构函数则是在函数被销毁时自动调用做善后工作的；拷贝构造函数是另一种初始化类的方法，它直接用类来初始化一个新类。 构造函数12345678910111213141516171819202122232425class Dog{private: char name[50]; int age;public: Dog(char *dogName, int dogAge) { strcpy(name, dogName); age = dogAge; } void initDog(char *dogName, int dogAge) { strcpy(name, dogName); age = dogAge; } void bark() { std::cout &lt;&lt; name &lt;&lt; \": wang wang~~\" &lt;&lt; std::endl; }}; 初始化一个类，需要把参数传给一个类，比如说用 void initDog(char *dogName, int dogAge) 这个方法。C++ 给我提供了一种特殊的函数叫做构造函数就像 Dog(char *dogName, int dogAge) 这样。我们可以用 Dog dog2(&quot;bbb&quot;, 5); 的方式来调用构造函数并初始化类。 1234567class 类名{ 类名(参数列表) { 构造体 }}; 构造函数的格式，及注意事项： 没有返回值 方法名和类名一致 构造函数可以重载，让参数列表不同 默认存在无参构造函数，当自定义构造函数之后无参构造函数失效，此时需要手动定义 构造函数代码示例 析构函数C++中的类可以定义一个特殊的成员函数清理对象,这个特殊的成员函数叫做析构函数。 1234567class 类名{ ~类名(参数列表) { 析构体 }}; 析构函数格式，及注意事项: 无返回值 方法名和类名一致，前面有个 ~ 符号 默认存在一个析构函数 析构函数不可重载 123456789101112131415161718192021222324252627282930313233class Dog{private: char *name; int age;public: Dog(char *dogName, int dogAge) { std::cout &lt;&lt; \"调用了构造函数.\" &lt;&lt; std::endl; name = new char[50]; strcpy(name, dogName); age = dogAge; } void bark() { std::cout &lt;&lt; name &lt;&lt; \": wang wang~~\" &lt;&lt; std::endl; } ~Dog() { std::cout &lt;&lt; \"调用了析构函数.\" &lt;&lt; std::endl; if(name != NULL) { delete name; name = NULL; } }}; 同样是 Dog 类，和文章开头的 Dog 类别比较有一点小的改动。private 类型变量 name，我将其由字符数组类型更改为了字符指针类型。新的 Dog 类就需要我们在使用的时候为 name 申明一块内存空间，就想我在其构造函数中所做的一样。 与之相对的就是在 Dog 类使用完成之后 free() 之前申明的内存空间。 析构函数代码示例 拷贝构造函数在第一小节我们看到了普通的构造函数是怎么使用的，之前还提到了构造函数有无参构造函数和有参数构造函数。在没有显示申明构造函数的时候，类自带一个无参构造函数，而当我们显示申明构造函数之后，默认的无参构造函数就失效了，此时如果任然需要无参构造函数，那就需要我们自己显示申明。 接下来再介绍一种构造函数叫做拷贝构造函数，由一个以存在的类来初始化一个新的类就可以使用拷贝构造函数，此时将不由构造器来初始化，而是由拷贝构造器来初始化。 拷贝构造函数与构造函数、析构函数一样，也存在默认的拷贝构造函数，我们可以直接使用如下 12345Dog dog(\"bbb\", 5);dog.bark();Dog dog2(dog);dog2.bark(); 如果想要自定一个拷贝构造函数格式如下 1234567class 类名{ 类名(const 类名 &amp;dog) { 拷贝构造体 }}; 123456789101112131415161718192021222324252627282930class Dog{private: char name[50]; int age;public: Dog(char *dogName, int dogAge) { std::cout &lt;&lt; \"调用了构造函数.\" &lt;&lt; std::endl; strcpy(name, dogName); age = dogAge; } Dog(const Dog &amp;dog) { std::cout &lt;&lt; \"调用了拷贝构造函数.\" &lt;&lt; std::endl; strcpy(name, dog.name); age = dog.age; } void bark() { std::cout &lt;&lt; name &lt;&lt; \": wang wang~~\" &lt;&lt; std::endl; }}; 深拷贝和浅拷贝 与结构体一样，类也存在深拷贝和浅拷贝的问题。浅拷贝即拷贝之后两个变量共用一块内存空间，深拷贝即新建一块内存来保存被拷贝的信息。 浅拷贝不是真正意义上的拷贝。在结构体发生浅拷贝时，如果我们释放该结构体，将会影响其他引用该结构体的其他变量。在类中的浅拷贝，如果类中包含的数据元素全部在栈上,浅拷贝也可以满足需求的。但如果堆上的数据,则会发生多次析构行为。 注：关于结构体的深拷贝和浅拷贝可以看我这篇文章 C语言学习笔记-结构体。 系统提供的默认拷贝构造器执行的就是浅拷贝操作，如果我们想要将其修改为深拷贝就需要自己手动来实现拷贝构造函数。 12345678Dog(const Dog &amp;dog){ std::cout &lt;&lt; \"调用了拷贝构造函数.\" &lt;&lt; std::endl; name = new char[50]; strcpy(name, dog.name); age = dog.age;}","link":"/post/a51fdb12.html"},{"title":"C 语言-格式化输出函数 printf()","text":"printf “格式字符串” 候选字符 格式字符串 作用 %d 将整数转成十进制 %f 将整数转成浮点数 %u 十进制无符号整数 %o 将整数转成八进制 %c 将整数转成对应的 ASCII 字符 %s 将整数转成字符串 %x 整数转成小写十六进制 %X 整数转成大写十六进制 %p 输出 %% 输出百分比符号，不进行转换 printf 中特殊规定的字符 规定字符 作用 \\n 换行操作 \\f 清屏并换页 \\r 回车 \\t Tab 符 \\xth 用 16 进制表示的 ASCII 码","link":"/post/d37b0970.html"},{"title":"C++学习笔记-继承","text":"面向对象有三个特性：封装继承和多态。实现一个类就是实现了一个对象的封装。继承是为了表示对象和对象之间的关系，生物学中有界门纲目科属种的说法，比如说喜鹊、麻雀、燕子它们有各自的特性，可以将它们看成一个个类，它们都属于鸟类，因为它们有鸟类共同的特征，会飞啊、有羽毛的啊。 继承就是抽象出对象的共性成为一个父类，子类用继承的方式获得父类的共性，并且子类有权拥有自己的个性，也能对父类的共性做个性化的修改。 本文并不详细介绍继承的概念，而是记录继承中一些关键点和注意事项。 访问控制 访问控制符 作用 public 公有继承，公开的大家都能访问 protected 保护继承，子类允许父类 private 私有继承，只能通过 get() 这样的函数访问 访问控制的存在能够保证让对象在继承中任然保持封装特性，亲兄弟也得明算账，能让你访问的就让你访问，不允许的我用 private 提前说明，你也别来碰。 代码示例 类的兼容性原则类的兼容性原则意思就是在使用父类的地方可以使用其子类来替代。因为子类通过公有继承已经获得了父类除了构造函数、析构函数之外的属性和方法。 子类对象可以当做父类对象来使用 子类对象可以赋值给父类对象 父类对象可以用子类对象来初始化 父类指针可以指向子类对象 子类创建和销毁的过程子类继承了父类，有了父类的属性和方法，所以再创建和销毁的过程中必不可少地要调用父类的构造方法和析构函数。 子类创建到销毁的过程 调用父类的构造函数 执行子类的构造函数 当父类的构造函数有参数时，需要在子类的初始化列表中显示调用 析构函数调用的先后顺序与构造函数相反 代码示例 多继承和虚继承C++ 允许一个类继承自多个类，同时拥有多个类的特性，这被称为多继承。多继承采用 class C: public Child1, public B 的形式实现，在继承的类之间添加逗号即可。 虚继承指的是类实现了多继承，其中继承的多个类中有两个或者以上都继承自同一个父类。 虚地址会造成一个二义性问题，我们知道类继承自另外一个类就会获得另外一个类的属性，在多继承中被继承的两个类来自于同一父类，就会产生下图所示的情况。 class C 有重复获取了两次 class B 中的变量 b，而 class B 有一个变量 b，class C 就面对使用哪个 b 的二义性问题。 解决方案就是让 class B1 和 class B2 在继承时都使用 vitural 修饰。 virtual 对子类声明为虚继承，使这个子类成为虚基类，使公共父类在子类中只产生一个子对象，","link":"/post/5afabdd4.html"},{"title":"C语言学习笔记-字符串","text":"字符串初始化 访问字符串 字符串的拷贝 字符串初始化C 语言没有字符串类型，利用字符类型来模拟，以 \\0 结尾。 12345678910111213141516171819202122232425262728#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;stdio.h&gt;int main(){ // 如果用字符数组来初始化字符串，末尾不是\\0结尾后面的会乱码 char buf[] = {'a', 'b', 'c'}; printf(\"buf = %s\\n\", buf); // 指定数组长度未初始化的地方会补零，读到0就作为字符串结束标记，则不会乱码 char buf1[100] = {'a', 'b', 'c'}; printf(\"buf1 = %s\\n\", buf1); // '字符 0' ≠ 0 = '\\0' char buf2[100] = {'a', 'b', 'c', '0', '1', '2'}; printf(\"buf2 = %s\\n\", buf2); char buf3[100] = {'a', 'b', 'c', 0, '1', '2'}; printf(\"buf3 = %s\\n\", buf3); char buf4[100] = {'a', 'b', 'c', '\\0', '1', '2'}; printf(\"buf4 = %s\\n\", buf4); // 常用初始化字符串的方法 char str[] = \"safafasga\"; // strlen() 和 sizeof() 的区别: // 字符串末尾以\\0结尾，strlen() 计算字符串长短; sizeof()计算大小还会包含\\0 printf(\"strlen() = %d, sizeof() = %d\\n\", strlen(str), sizeof(str)); char str2[100] = \"safafasga\"; // 制定数组大小的情况下，未制定的位置将会自动补零 printf(\"strlen() = %d, sizeof() = %d\\n\", strlen(str2), sizeof(str2)); return 0;} 访问字符串123456789101112131415161718192021222324252627282930313233343536#include &lt;stdio.h&gt;#include &lt;string.h&gt;/*** 遍历字符串的方法**/int main(){ char *buf = \"fdsafasdgag\"; for(int i = 0; i &lt; strlen(buf); ++i) { printf(\"%c\", buf[i]); } printf(\"\\n\"); char *p = buf; for(int i = 0; i &lt; strlen(buf); i++) { printf(\"%c\", p[i]); } printf(\"\\n\"); for(int i = 0; i &lt; strlen(buf); i++) { printf(\"%c\", *(p + i)); } printf(\"\\n\"); for(int i = 0; i &lt; strlen(buf); i++) { printf(\"%c\", *(buf + i)); } printf(\"\\n\"); // p 和 buf 等价么 // buf 是常量，常量是不可变的 // p 是变量，可变 // p++; // buf++; // err return 0;} 字符串的拷贝1234567891011121314151617181920212223242526272829303132333435363738#include &lt;stdio.h&gt;#include &lt;string.h&gt;/*** 1. 进行非空判断，避免异常* 2. 不要直接使用形参**/int my_strcpy(char *dst, char *src){ // 非空判断 if(dst == NULL || src == NULL) return -1; // 不要直接使用形参 // 会改变数组的首地址位置 char *to = dst; char *from = src; while(*to++ == *from++); // 上面把形参结果来不起作用，只有这样才行，之后再看一下 // while(*dst++ == *src++); return 0;}/*** 1. 实现字符串拷贝函数* 2. 写出健壮的代码的注意事项**/int main(){ char *src = \"dfagfadga\"; char dst[100] = {0}; int res = my_strcpy(dst, src); if(res != 0) { fprintf(stderr,\"copy str error.\"); return -1; } printf(\"dst: %s\\n\", dst); return 0;}","link":"/post/a99472bd.html"},{"title":"C++学习笔记-静态方法、静态函数、this指针","text":"静态变量、静态方法和 this 指针都是为了更好表现类的概念。 类中的静态变量能够实现同类对象中的信息共享，共享状态能够实现许多实用的功能，比如说计数。 静态变量不能用普通函数直接访问，就需要用到静态函数来管理静态变量。 this 指针用 this-&gt;name = name 的形式解决类中函数传入的参数与类中成员变量冲突的问题。 总之，通过代码来说明问题更容易理解。 静态变量、静态方法和 this 指针使用代码示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/* 面向对象，静态变量、静态方法, this 指针 */#include &lt;iostream&gt;#include &lt;cstring&gt;class Student{private: // 学生编号 int number; // 学生分数 int score;public: // 静态变量，学生总数 static int studentCount; // 静态变量，所有学生总分 static int sumScore;public: Student(int number, int score) { this-&gt;number = number; this-&gt;score = score; studentCount++; sumScore += score; } // 静态方法 static double getAvg() { return sumScore / studentCount; } Student(/* args */);};// 静态变量赋值，所有对象共享int Student::sumScore = 0;int Student::studentCount = 0;int main(){ Student stu1(111, 50); Student stu2(112, 70); Student stu3(114, 90); // 静态方法调用 double avg = Student::getAvg(); std::cout &lt;&lt; \"average score = \" &lt;&lt; avg &lt;&lt; std::endl; return 0; } 静态成员变量： static 成员变量实现了同类对象间信息共享。 static 成员类外存储,求类大小,并不包含在内。 static 成员是命名空间属于类的全局变量,存储在 data 区 static 成员只能类外初始化。 可以通过类名访问(无对象生成时亦可),也可以通过对象访问 静态成员函数： 静态成员函数的意义,不在于信息共享,数据沟通,而在于管理静态数据成员, 完成对静态数据成员的封装。 静态成员函数只能访问静态数据成员。原因:非静态成员函数,在调用时 this 指针被当作参数传进。而静态成员函数属于类,而不属于对象,没有 this 指针 this 指针: 类成员变量的形参和类的属性名字相同，可以使用 this 指针，如 this-&gt;name = name","link":"/post/cd8fc6b5.html"},{"title":"C语言学习笔记-写一个最简单的makefile","text":"示例代码 最简单的 makefile12app: main.c add.c mul.c sub.c gcc main.c add.c mul.c sub.c -o app 目标：生产名为 app 的可执行文件 依赖：可执行文件通过 .c 文件生成 命令：通过 gcc 命令生成 第一个版本的问题在于每次都需要编译所有的 .c 文件，如果想要修改哪个文件就只编译修改过的文件就可以这样那样写： 1234567891011121314app:main.o add.o mul.o sub.o gcc main.o add.o mul.o sub.o -o appmain.o:main.c gcc -c main.cadd.o:add.c gcc -c add.cmul.o:mul.c gcc -c mul.csub.o:sub.c gcc -c sub.c 目标：生成名为 app 的可执行文件 依赖：预编译完成的 .o 文件 命令：系列 gcc 命令 makefile的工作原理makefile中的变量12345678obj=main.o add.o mul.o sub.otarget=appCC=gcc$(target):$(obj) gcc $(obj) -o $(target) %.o:%.c $(CC) -c $&lt; -o $@ %.o:%.c模式匹配 自动变量，只能在规则中的命令中使用 $&lt;规则中第一个依赖 $@规则中的目标 $^规则中所有依赖 makefile中的函数1234567891011121314target=appsrc=$(wildcard ./*.c)obj=$(patsubst ./%.c, ./%.o, $(src))CC=gccCPPFLAGS=-I$(target):$(obj) $(CC) $(obj) -o $(target) %.o:%.c $(CC) -c $&lt; -o $@ .PHONY:cleanclean: rm -f $(obj) $(target)","link":"/post/24de7431.html"},{"title":"C语言学习笔记-const关键字","text":"c语言中 const 关键字使用示例 const 修饰的变量定义时要初始化，不初始化后面就没有办法赋值了 const 运用在指针上 c 语言中的 const 是个冒牌货，使用指针任然能够修改 12345678910111213141516171819202122232425262728293031323334#include &lt;stdio.h&gt; int main(){ char buf[] = \"dfasfadsgafdg\"; const char *p = buf; // p[1] = \"2\"; err p = \"0x11\"; // const 此时修饰的是 *p，表示 p 指向的那块内存的内容 *p 是不可变的 // char const *p1 = buf; // p1[1] = '2; // 交换顺序这里 const char 与 char const 相同 char * const p1 = buf; p1[1] = '2'; // p1 = \"0x11\"; err // const 此时修饰的是 p，表示指针变量 p 本身是不可修改的，而指针变量指向的内容 *p 是可以修改的 const char * const p3 = buf; // p3[1] = '2; err // p3 = \"abc\"; err // 两个 const 分别修饰了 p 和 *p，此时无论是指针还是指针指向的内存都不可变，完成处于只读状态 const int a = 123; // a = 321; err int *q = NULL; q = &amp;a; *q = 321; printf(\"a: %d\\n\", a); // c 语言中的 const 是个冒牌货，使用指针任然能够修改 return 0;}","link":"/post/5c7372a9.html"},{"title":"C语言学习笔记-文件操作","text":"C语言中我们使用一个指针变量指向一个文件，这个文件就是文件指针。这个文件指针就是 FILE 结构体，它被包含在头文件 “stdio.h” 中。拿到文件指针再结合文件操作的 API，我们就可以对文件进行读写操作。 文件操作打开文件 fopen()12#include &lt;stdio.h&gt;FILE *fopen(const char *path, const char *mode); 文件的打开操作表示返回一个指向制定文件的 FILE 结构体。我们需要指定文件位置和操作方式，特别需要注意的是区分不同的文件操作方式将会产生的结果。 1234567891011r Open text file for reading. The stream is positioned at the beginning of the file.r+ Open for reading and writing. The stream is positioned at the beginning of the file.w Truncate file to zero length or create text file for writing. The stream is positioned at the beginning of the file.w+ Open for reading and writing. The file is created if it does not exist, otherwise it is truncated. The stream is positioned at the beginning of the file.a Open for appending (writing at end of file). The file is created if it does not exist. The stream is positioned at the end of the file.a+ Open for reading and appending (writing at end of file). The file is created if it does not exist. The initial file position for reading is at the beginning of the file, but output is always appended to the end of the file. 关闭文件 fclose()12#include &lt;stdio.h&gt;int fclose(FILE *stream); 文件操作完成后,必须要用fclose()函数进行关闭,这是因为对打开的文件进行写入时,若文件缓冲区的空间未被写入的内容填满,这些内容不会写到打开的文件中去而丢失。只有对打开的文件进行关闭操作时,停留在文件缓冲区的内容才能写到该文件中去,从而使文件完整。再者一旦关闭了文件,该文件对应的FILE结构将被释放,从而使关闭的文件得到保护,因为这时对该文件的存取操作将不会进行。文件的关闭也意味着释放了该文件的缓冲区。 它表示该函数将关闭FILE指针对应的文件,并返回一个整数值。若成功地关闭了文件,则返回一个0值,否则返回一个非0值。 fgetc() 和 fputc() 按字符读写文件首先用 fopen() 读入一个文件FILE *fp = **fopen**(&quot;../data/file01.txt&quot;, &quot;r+&quot;); 指定文件位置以及读写格式，r+表示打开文件进行读写操作。 写操作使用 fputc() 逐个字符写入： 1234567char text[] = \"This is a text for test.\";int length = strlen(text);for(int i = 0; i &lt; length; i++){ fputc(text[i], fp);} 读操作使用 fgetc() 逐个字符读取，当读到结束标志位 EOF 时停止 123456789101112// 方法一while( (ch = fgetc(fp)) != EOF ){ printf(&quot;%c&quot;, ch);}// 方法二while(!feof(fp)){ ch = fgetc(fp); printf(&quot;%c&quot;, ch);} 逐个字符读写文件，示例代码 fgets() 和 fputs() 按行读写文件123456789101112131415161718192021222324252627282930/* 按行读写 */#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int main(){ FILE *fp = fopen(\"../data/file02.txt\", \"r+\"); if(fp == NULL) { perror(\"fopen(): file is NULL.\"); } char tmp[100] = \"aaaaaaaaa\"; fputs(tmp, fp); char buf[100]; while(!feof(fp)) { char *p = fgets(buf, sizeof(buf), fp); if(p != NULL) { printf(\"buf = %s\", buf); printf(\"p = %s\", p); } } return 0;} fwrite() 和 fread() 按块读写文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596#define _CRT_SECURE_NO_WARNINGS #include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;stdlib.h&gt;#define FILE_NAME \"../data/file03.txt\"struct teacher{ int age; int id; char *name; int name_len;};int main(void){ FILE *fp = NULL;#if 0 int write_ret = 0; fp = fopen(FILE_NAME, \"wb+\"); if (fp == NULL) { fprintf(stderr, \"fopen error\\n\"); return -1; } struct teacher t1; char *name = \"zhang3\"; t1.age = 10; t1.id = 20; t1.name = malloc(64); memset(t1.name, 0, 64); strcpy(t1.name, name); t1.name_len = strlen(name); write_ret = fwrite(&amp;t1, sizeof(struct teacher), 1, fp); if (write_ret &lt; 0) { fprintf(stderr, \"write error\\n\"); return -1; } write_ret = fwrite(t1.name, t1.name_len, 1, fp); if (write_ret &lt; 0) { fprintf(stderr, \"write error\\n\"); return -1; } if (fp != NULL) { fclose(fp); }#endif// #if 0 struct teacher t2 = { 0 }; int read_ret = 0; fp = fopen(FILE_NAME, \"rb+\"); if (fp == NULL) { fprintf(stderr, \"fopen r+error\\n\"); return -1; } read_ret = fread(&amp;t2, sizeof(struct teacher), 1, fp); if (read_ret &lt; 0) { fprintf(stderr, \"fread error\\n\"); fclose(fp); return -1; } t2.name = malloc(t2.name_len + 1); memset(t2.name, 0, t2.name_len + 1); read_ret = fread(t2.name, t2.name_len, 1, fp); if (read_ret &lt; 0) { fprintf(stderr, \"fread error\\n\"); fclose(fp); return -1; } printf(\"id : %d, age : %d, name:%s, name_len :%d\\n\", t2.id, t2.age, t2.name, t2.name_len); if (fp != NULL) { fclose(fp); }// #endif return 0;}","link":"/post/fe52dfa7.html"},{"title":"C语言学习笔记-指针01","text":"指针是 C 语言的灵魂，现在对于指针的掌握肯定是不透彻的，然学习是一个迭代的过程，姑且写出目前自己的理解。 指针的概念123456789101112131415161718192021#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;stdio.h&gt;int main(){ int a = 10; int *p = NULL; p = (int *)malloc(sizeof(int)); p = &amp;a; printf(\"%d\\n\", p); printf(\"%d\\n\", *p); if(p != NULL) { free(p); p = NULL; }} 先来看这样一段代码 p 是一个指针变量，*p 是指针指向的内存空间的保存的值。 &amp;a 表示取变量 a 所在内存的地址，p = &amp;a 表示将内存 a 所在的地址值赋值给 p，相当于指针 p 指向 a 所在的内存。 接下来分别打印 p 和 *p 来验证上面的说法 最后我们释放内存空间 明确几个概念： 指针是一个变量 注意区分指针变量和它指向的内存块 改变指针变量的值不会影响指针指向的内存区域 改变指针指向的内存区域也不会改变指针变量的值 内存四区先来看这样一段代码 123456789101112131415161718192021#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;stdio.h&gt;char *get_str(){ char str[] = \"abcdefg\"; return str;}int main(){ char buf[128] = {0}; strcpy(buf, get_str()); printf(\"buf = %s\\n\", buf); // char *p = NULL; // p = get_str(); // printf(\"p = %s\\n\", p); return 0;} char *p 是一个 char 类型的指针变量，看代码的意思是希望通过 get_str() 方法给指针 p 赋值。如果你运行一下这段代码会发现它是会报错的，至于为什么会报错就要分析一下内存四区了。 区域 作用 栈区(stack) 由编译器自动分配释放，存放函数的参数值，局部变量值等。 堆区（heap） 一般由程序员分配释放（动态内存申请与释放），若程序员不释放，程序结束时可能由操作系统回收。 全局区（静态区） 全局变量和静态变量的存储是放在一起的，初始化的全局变量和静态变量在一块区域，未被初始化的全局变量和未初始化的静态变量在相邻的另一块区域，该区域在程序结束后由操作系统释放。 程序代码区 存放函数体的二进制代码。 现在通过内存四区的理论来分析上面这一段代码。 声明了一个名为 buf 的变量 调用 get_str() 声明一个数组 str ，它是一个局部变量所以再栈区 字符串 “abcdef…” 是字符串常量，所以再全局区（静态区） str = “abcdef” 会将全局区的字符串常量拷贝到 str 数组内存中 紧接着 get_str() 调用结束，与之相关的内存就会被销毁 strcpy() 希望将 get_str() 返回的字符串拷贝给 buf，但是因为这一块内存已经被销毁了，就会报错 注：有时候以上的操作可能会成功，这可能是因为没有及时销毁，可以用我上面注释掉的指针操作的代码做练习，用内存四区的方式分析，赋值是一定不会成功的，原理相同。 正确的赋值方式我们可以使用 malloc() 将变量保存在堆区，堆区的内存在函数执行完之后不会立即销毁，而是由我们自己销毁，或者再程序运行完之后由操作系统来销毁。 123456789101112131415161718192021222324252627282930#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;stdio.h&gt;char *get_str2(){ char *tmp = (char *)malloc(100); if(tmp == NULL) { return NULL; } strcpy(tmp, \"adsaffa\"); return tmp;}int main(){ char buf[128] = {0}; // strcpy(buf, get_str()); // printf(\"buf = %s\\n\", buf); char *p = NULL; p = get_str2(); if(p != NULL) { printf(\"p = %s\\n\", p); free(p); p = NULL; } return 0;} 使用指针的几个注意事项这一小节属于使用指针过程中遇到的一些问题，以及如何避免，有个故事说：人如果知道自己会死在哪里，就死也不要去那里就行了。使用指针也一样，指针使用会遇到很多的坑，知道哪里有坑就要尽可能避免。 修改内存时要保证内存可写12345678910111213#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;stdio.h&gt;int main(){ char *p = \"abcdef\"; char q[] = \"fdasfafdfas\"; p[2] = \"1”; // 会报错 err q[2] = \"1\"; printf(\"p: %s\\n\", p); printf(\"q: %s\\n\", q); return 0;} 修改 p[2] 会报错，因为 abcdef 是字符串常量，保存在全局区（静态区），所以它是不能被修改的。使用指针的第一个事项就是修改内存的时候保证内存可写。 指针的步长指针的步长由指针指向的内存类型决定，比如说 int p 步长就是 4，chat p 步长就是 1。步长的意思就是每次 p++ 操作之后，地址移动的距离。可以分别打印 p 和 p++ 的值看一看就知道了。 由此还想讲一个问题就是如何计算一个动态数组的大小。比如 int a[] = {1, 2, 3, 4}，可以使用 sizeof(a)/sizeof(a[0])的方式计算数组大小。 不允许 NULL 或者未知非法地址拷贝内存12char *p =NULL;strcpy(p, “1232143”); // 报错 strcpy() 执行的操作时将字符串拷贝给指针 p 所指向的内存,此时指针 p 指向的内存是 NULL，就是说没有执行任何内存，字符串也就没地方拷贝，自然会发生错误。 如果我们让char* p = 0x11; 任意赋一个值，也会报错，向未知非法地址拷贝也是不被允许的。 正确的做法就是将 p 指向一个已经分配好内存的指针，比如 char *q = “fdsafas” 。 所以当我们给一个使用 malloc() 分配内存之后应该习惯性地加一个判断，比如int *p = (int *)malloc(sizeof(int));之后应该进行判断if(p == NULL)如果为空则说明内存分配失败，就应该对异常进行处理。一直对应的，释放内存是有个也应该讲指针赋值为空free(p); p = NULL;。 通过指针间接赋值我们定义一个函数会有返回值，返回值可能是一个结果、可能表示一种状态。比如说int findMax(int *a, int n);在这个函数中我们出入一个数组，然后返回这个数组中最大的值。 那现在如果我想返回这个数组的最大值、最小值该怎么办？ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;int fun(int *a, int n, int *max, int *min){ if(a == NULL || n &lt;= 0) { return -1; } int tmp_max, tmp_min, sum = *a; for(int i = 1; i &lt; n; i++) { if(a[i] &lt; tmp_min) { tmp_min = a[i]; } if(a[i] &gt; tmp_max) { tmp_max = a[i]; } } max = &amp;tmp_max; min = &amp;tmp_min; return 0;}int main(){ int a[5] = {2, 6, 9, 10, 1}; int max = 0; int min = 0; int res = fun(a, 5, &amp;max, &amp;min); if(res == -1) { perror(\"fun() err.\"); return -1; } printf(\"max = %d, min = %d\\n\", max, min); return 0;} 定义一个函数int fun(int *a, int n, int *max, int *min); 返回值表示成功或者失败 a 是数组指针 n 是数组大小 max 和 int 是 int 类型的指针 关键就在于 max 和 int 这两个指针，它们指向的两个内存分别保存数组的最大和最小值，而这两个指针是由主函数传入的，此时就完成你了最大值和最小值传递。 通过指针间接赋值是指针很强大的一个功能，我们可以看到很多函数都是这样定义的。","link":"/post/2f02c8ae.html"},{"title":"C语言学习笔记-结构体","text":"结构体的类型和定义 结构体的赋值 结构体的数组 结构体嵌套一级指针 结构体嵌套二级指针 结构体作为函数参数 结构体深拷贝、浅拷贝 结构体的类型和定义结构体是一种数据类型，用 struct 关键字来修饰，定义一个结构体可以这样： 12345struct Teacher{ char name[50]; int age;} 如果用 typedef 修饰，就可以直接使用 Teacher 1234567typedef struct Teacher{ char name[50]; int age;}Teacher teacher = NULL; 为结构体申明变量有多种方式： 12345678910111213141516171819202122232425262728293031// 初始化结构体变量1: 定义类型的同时定义变量struct Teacher{ char name[50]; int age;}t1, t2;// 初始化结构体变量2struct Student{ char name[50]; int age;}s1 = {\"Mike\", 15}; // 初始化结构体变量3struct{ char name[50]; int age;}dog = {\"Luck\", 3}; // 初始化结构体变量4struct Teacher t3 = {\"Mary\", 21};// 初始化结构体变量5struct Teacher t4;struct Teacher *pTeacher = NULL;pTeacher = &amp;t4;strcpy(pTeacher-&gt;name, \"John\");pTeacher-&gt;age = 30; 结构体的赋值结构体赋值之前要先给结构体申请内存。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/* 结构体赋值 */#include &lt;stdio.h&gt;#include &lt;string.h&gt;struct Teacher{ char name[50]; int age;};typedef struct Teacher teacher_t;void show_teacher(teacher_t t);void copyTeacher(teacher_t *to, teacher_t *from);int main(){ teacher_t t1, t2, t3; // 结构体是一种数据类型，分配空间之后才能赋值 memset(&amp;t1, 0, sizeof(t1)); strcpy(t1.name, \"teacher\"); t1.age = 30; show_teacher(t1); // 直接赋值 t2 = t1; show_teacher(t2); // 作为参数传递到用于拷贝的函数 copyTeacher(&amp;t3, &amp;t1); show_teacher(t3); return 0;}void copyTeacher(teacher_t *to, teacher_t *from){ *to = *from;}void show_teacher(teacher_t t){ printf(\"teacher name = %s\\n\", t.name); printf(\"teacher age = %d\\n\", t.age);} 结构体的数组指针数组可以分成静态结构体数组和动态结构体数组两种。 123456789101112131415161718// 静态结构体数组Teacher t1[3] = {\"a\", 18, \"a\", 28, \"a\", 38};for(int i = 0; i &lt; 3; i++){ printf(\"%s, %d\\n\", t1[i].name, t1[i].age);}// 动态结构体数组Teacher *p = NULL;p = (Teacher *)malloc(3 * sizeof(Teacher));char buf[50];for(int i = 0; i &lt; 3; i++){ sprintf(buf, \"name%d\", i); strcpy(p[i].name, buf); p[i].age = 20 + i;} 结构体数组 结构体嵌套指针我们在定义结构体的时候，其中有一个属性使用了一级指针： 12345struct Teacher{ char *name; int age;}; 如上所示char *name是一个指针类型的变量，指针类型的变量当我们为其赋值时要分配内存空间，释放结构体的时候也要先释放其中指针内存的变量。 示例代码，结构体嵌套一级指针 示例代码，结构体嵌套二级指针 结构体深拷贝、浅拷贝当结构体中嵌套了指针，采用浅拷贝的方式如下 12345678Student stu;stu.name = (char *)malloc(30);strcpy(stu.name, \"aaaaaa\");// 浅拷贝，stu 和 sut2 的name 指针指向同一块内存Student stu2;stu2 = stu;printf(\"name = %s\\n\", stu2.name); 此时 stu.name 和 stu2.name 指向同一块内存空间，当释放其中一个指针的时候，另一个 name 的值也就消失了。 深拷贝的方式指的就是 stu2.name 指向一块新的内存空间，这块内存空间拷贝 stu.name 指向的空间的内容，就像下面这样。 12345// 深拷贝，stu3 重新申请一块内存Student stu3;stu3.name = (char *)malloc(30);strcpy(stu3.name, stu.name);printf(\"name = %s\\n\", stu3.name); 示例代码，结构体的深拷贝和浅拷贝","link":"/post/e261fd69.html"},{"title":"C语言学习笔记-静态库、动态库的制作和使用","text":"本文将介绍 C 语言静态库和动态库制作和使用的过程，系统环境是 Ubuntu16.04，其他系统制作方法可能略有差别。 示例代码 目录结构12345678910.├── README.md├── include│ └── head.h├── lib├── main.c└── src ├── add.c ├── mul.c ├── sub.c include - 头文件目录 lib - 库文件目录 src - 源代码目录 静态库本节介绍如何将代码编译成静态库。当我们希望程序响应更快，或者不想提供源代码，我们可以使用静态库。 编译静态库123456789101112131415# 将 .c 文件编译成 .o 文件➜ lsadd.c mul.c sub.c➜ gcc *.c -c -I ../include➜ lsadd.c add.o mul.c mul.o sub.c sub.o# 将 .o 文件打包，生成 .a 文件➜ ar rcs libMyCalc.a *.o➜ lsadd.c libMyCalc.a mul.o sub.oadd.o mul.c sub.c# 将 .a 文件移动到 lib 目录下➜ mv libMyCalc.a ../lib 使用静态库1234567# 方式 1gcc main.c lib/libMyCalc.a -I include -o sum./sum# 方式 2gcc main.c -Iinclude -L lib -l MyCalc -o myapp./myapp 动态库 编译动态库123456789101112131415# .c 编译为 .o➜ src git:(master) ✗ lsadd.c mul.c sub.c➜ src git:(master) ✗ gcc -fPIC -c *.c -I ../include➜ src git:(master) ✗ lsadd.c add.o mul.c mul.o sub.c sub.o# .o 打包为 .so➜ src git:(master) ✗ gcc -shared -o libMyCalc.so *.o -Iinclude➜ src git:(master) ✗ lsadd.c libMyCalc.so mul.o sub.oadd.o mul.c sub.c# .so 移动到 lib➜ src git:(master) ✗ mv libMyCalc.so ../lib 使用动态库1234567# 方式 1gcc main.c lib/libMyCalc.so -o app -Iinclude./app# 方式 2gcc main.c -Iinclude -L lib -l MyCalc -o myapp./myapp 如果在使用动态库的过程中遇到了问题，请看下一小结。 动态库链接失败问题动态库是由动态连机器加载的，通过ldd app我们可以查看可执行文件执行的时候依赖的所有动态库。交由动态连接器管理的动态库都能被正确加载，比如说/lib目录下的库文件。我们自定义的动态库没有被加载就是因为没有告知动态连接器我们的动态库在哪里。 方法一 临时配置要想汤动态连机器知道我们的动态库在哪，一种方式是直接把自定义的动态库丢到/lib目录下，这样自然就能加载到了，当然我想没有人会想这么做的。另一种方式就是在配置文件中配置动态库的位置，比如像下面的这样： 1export LD_LIBRARY_PATH=我们的动态库位置 LD_LIBRARY_PATH我们可以将动态库的位置保存在这里，此时就能顺利运行程序，但是重启终端将会失效，临时测试的时候使用很方便。 方法二 永久配置1231. vim /etc/ld.so.conf2. 将动态库的路径配置在里面3. sudo ldconfig -v","link":"/post/62b06016.html"},{"title":"STL-STL基础概念","text":"STL(Standard Template Library,标准模板库)，是惠普实验室开发的一系列软件的统 称。现在主要出现在 c++ 中，但是在引入 c++ 之前该技术已经存在很长时间了。 STL 从广义上分为: 容器(container) 算法(algorithm) 迭代器(iterator),容器和算法之 间通过迭代器进行无缝连接。STL 几乎所有的代码都采用了模板类或者模板函数，这相比传 统的由函数和类组成的库来说提供了更好的代码重用机会。 STL(Standard Template Library)标准模板库,在我们 c++ 标准程序库中隶属于 STL 的 占到了 80%以上。 在 c++标准中，STL 被组织成以下 13 个头文件： 1&lt;algorithm&gt;、&lt;deque&gt;、&lt;functional&gt;、&lt;iterator&gt;、&lt;vector&gt;、&lt;list&gt;、&lt;map&gt;、 &lt;memory&gt;、&lt;numeric&gt;、&lt;queue&gt;、&lt;set&gt;、&lt;stack&gt; 、&lt;utility&gt; 容器 容器即数据结构，比如说 vector 是动态数组，stack 是栈。 容器可以嵌套容器 容器可以分为序列化容器和关联式容器。序列化容器即按照元素进入容器的先后顺序来排列；关联式容器即按照容器定义的其他规则来存放元素。 迭代器：迭代器是为了遍历容器中的元素，可以理解是指针 算法：STL 为我们提供的算法，算法即用有限的步骤解决问题 12345678910111213141516171819202122232425262728293031323334#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;//----------------------------------// stl 包括三部分：容器、迭代器、算法//----------------------------------using namespace std;int main(){ vector&lt;int&gt; v; // 容器，stl 的标准容器之一，动态数组 v.push_back(1); // Vector 容器提供的插入数据的方法 v.push_back(3); v.push_back(6); v.push_back(4); v.push_back(3); vector&lt;int&gt;::iterator pBegin = v.begin(); // 迭代器，获取指向第一个元素的指针 vector&lt;int&gt;::iterator pEnd = v.end(); // 迭代器，获取指向最后一个元素的指针 int n = count(pBegin, pEnd, 3); // 算法，统计 3 出现的次数 cout &lt;&lt; \"n = \" &lt;&lt; n &lt;&lt; endl; // 使用迭代器遍历 vector while(pBegin != pEnd) { cout &lt;&lt; *pBegin &lt;&lt; endl; pBegin++; } return 0;} 接下来一系列的文章将介绍 STL 中的常用容器和常用算法。","link":"/post/543335f8.html"},{"title":"STL-list 容器","text":"链表通过数据域保存元素，通过指针域表示相邻元素之间的关系。 采用动态存储分配，不会造成内存浪费和溢出 链表执行插入和删除操作的效率高 链表灵活，但是空间和时间额外耗费较大 list 构造函数1234list&lt;T&gt; lstT;//list 采用采用模板类实现,对象的默认构造形式：list(beg,end);//构造函数将[beg, end)区间中的元素拷贝给本身。list(n,elem);//构造函数将 n 个 elem 拷贝给本身。list(const list &amp;lst);//拷贝构造函数。 list 数据元素插入和删除操作1234567891011push_back(elem);//在容器尾部加入一个元素pop_back();//删除容器中最后一个元素push_front(elem);//在容器开头插入一个元素pop_front();//从容器开头移除第一个元素insert(pos,elem);//在 pos 位置插 elem 元素的拷贝，返回新数据的位置。insert(pos,n,elem);//在 pos 位置插入 n 个 elem 数据，无返回值。insert(pos,beg,end);//在 pos 位置插入[beg,end)区间的数据，无返回值。clear();//移除容器的所有数据erase(beg,end);//删除[beg,end)区间的数据，返回下一个数据的位置。erase(pos);//删除 pos 位置的数据，返回下一个数据的位置。remove(elem);//删除容器中所有与 elem 值匹配的元素。 list 大小操作1234size();//返回容器中元素的个数empty();//判断容器是否为空resize(num);//重新指定容器的长度为 num，若容器变长，则以默认值填充新位置。如果容器变短，则末尾超出容器长度的元素被删除。resize(num, elem);//重新指定容器的长度为 num， 若容器变长，则以 elem 值填充新位置。如果容器变短，则末尾超出容器长度的元素被删除。 list 赋值操作1234assign(beg, end);//将[beg, end)区间中的数据拷贝赋值给本身。assign(n, elem);//将 n 个 elem 拷贝赋值给本身。list&amp; operator=(const list &amp;lst);//重载等号操作符swap(lst);//将 lst 与本身的元素互换。 list 数据的存取12front();//返回第一个元素。back();//返回最后一个元素。 list 反转排列排序12reverse();//反转链表，比如 lst 包含 1,3,5 元素，运行此方法后， lst 就包含 5,3,1 元素。sort(); //list 排序","link":"/post/b0cfebdb.html"},{"title":"STL-deque 容器","text":"deque 是 “double-ended queue”的缩写,和 vector 一样，deque 也支持随机存取。 与 vector 不同的是，vector 是单向开口的，deque 是双向开口的，在两端进行插入和删除操作的时间复杂度为 O(1)。此外，deque 没有容量的概念，因为它是动态的以分段的连续空间组合而成，随时可 以增加一段新的空间并链接起来，换句话说，像 vector 那样“因旧空间不足而重新分配一 块更大的空间，然后再复制元素，释放空间”这样的操作不会发生在 deque 身上，也因此 deque 没有必要提供所谓的空间保留功能。 双端插入和删除元素效率较高. 指定位置插入也会导致数据元素移动,降低效率. 可随机存取,效率高. deque 构造函数1234deque&lt;T&gt; deqT;//默认构造形式deque(beg, end);//构造函数将[beg, end)区间中的元素拷贝给本身。deque(n, elem);//构造函数将 n 个 elem 拷贝给本身。deque(const deque &amp;deq);//拷贝构造函数。 deque 赋值操作1234assign(beg, end);//将[beg, end)区间中的数据拷贝赋值给本身。assign(n, elem);//将 n 个 elem 拷贝赋值给本身。deque&amp; operator=(const deque &amp;deq); //重载等号操作符swap(deq);// 将 deq 与本身的元素互换 deque 大小操作1234deque.size();//返回容器中元素的个数deque.empty();//判断容器是否为空deque.resize(num);//重新指定容器的长度为 num,若容器变长，则以默认值填充新位置。如果容器 变短，则末尾超出容器长度的元素被删除。deque.resize(num, elem); //重新指定容器的长度为 num,若容器变长，则以 elem 值填充新位置,如果容器变短，则末尾超出容器长度的元素被删除。 deque 双端插入和删除操作1234push_back(elem);//在容器尾部添加一个数据push_front(elem);//在容器头部插入一个数据pop_back();//删除容器最后一个数据pop_front();//删除容器第一个数据 deque 数据存取1234at(idx);//返回索引 idx 所指的数据，如果 idx 越界，抛出 out_of_range。operator[];//返回索引 idx 所指的数据，如果 idx 越界，不抛出异常，直接出错。front();//返回第一个数据。back();//返回最后一个数据 deque 插入操作123insert(pos,elem);//在 pos 位置插入一个 elem 元素的拷贝，返回新数据的位置。insert(pos,n,elem);//在 pos 位置插入 n 个 elem 数据，无返回值。insert(pos,beg,end);//在 pos 位置插入[beg,end)区间的数据，无返回值。 deque 是分段连续的内存空间，通过中控器维持一种连续内存空间的状态， 其实现复杂性要大于 vector queue stack 等容器，其迭代器的实现也更加复杂。 在需要对 deque 容器元素进行排序的时候，建议先将 deque 容器中数据数据元素拷贝到 vector 容 器中，对 vector 进行排序，然后再将排序完成的数据拷贝回 deque 容器。 deque 删除操作123clear();//移除容器的所有数据erase(beg,end);//删除[beg,end)区间的数据，返回下一个数据的位置。erase(pos);//删除 pos 位置的数据，返回下一个数据的位置。","link":"/post/564ccba3.html"},{"title":"STL-map and multimap","text":"map 以键值对的形式存储数据，所有元素根据键值自动排序。pair 的第 一元素被称为键值，第二元素被称为实值。map 也是以红黑树为底层实现机制。 map 和 multimap 区别在于，map 不允许相同 key 值存在，multimap 则允许相同 key 值存在。 对组类模板：template struct pair. 12345678910111213//第一种方法创建一个对组pair&lt;string, int&gt; pair1(string(\"name\"), 20);cout &lt;&lt; pair1.first &lt;&lt; endl; //访问 pair 第一个值cout &lt;&lt; pair1.second &lt;&lt; endl;//访问 pair 第二个值// 第二种pair&lt;string, int&gt; pair2 = make_pair(\"name\", 30);cout &lt;&lt; pair2.first &lt;&lt; endl;cout &lt;&lt; pair2.second &lt;&lt; endl;//pair=赋值pair&lt;string, int&gt; pair3 = pair2;cout &lt;&lt; pair3.first &lt;&lt; endl;cout &lt;&lt; pair3.second &lt;&lt; endl; map 构造函数12map&lt;T1, T2&gt; mapTT;//map 默认构造函数:map(const map &amp;mp);//拷贝构造函数 map 赋值操作12map&amp; operator=(const map &amp;mp);//重载等号操作符swap(mp);//交换两个集合容器 map 大小操作12size();//返回容器中元素的数目empty();//判断容器是否为空 map 插入数据元素操作1234567891011map.insert(...);//往容器插入元素，返回pair&lt;iterator,bool&gt;map&lt;int, string&gt; mapStu; // 第一种通过 pair 的方式插入对象mapStu.insert(pair&lt;int, string&gt;(3, \"小张\"));// 第二种通过 pair 的方式插入对象mapStu.inset(make_pair(-1, \"校长\"));// 第三种通过 value_type 的方式插入对象mapStu.insert(map&lt;int, string&gt;::value_type(1,\"小李\"));// 第四种通过数组的方式插入值 mapStu[3] = \"小刘\";mapStu[5] = \"小王\"; map 删除操作1234clear();//删除所有元素erase(pos);//删除 pos 迭代器所指的元素，返回下一个元素的迭代器。erase(beg,end);//删除区间[beg,end)的所有元素 ，返回下一个元素的迭代器。erase(keyElem);//删除容器中 key 为 keyElem 的对组。 map 查找操作12345find(key);//查找键 key 是否存在,若存在， 返回该键的元素的迭代器；/若不存在，返回 map.end();count(keyElem);//返回容器中 key 为 keyElem 的对组个数。对 map 来说，要么是 0，要么是 1。对 multimap 来说，值可能大于 1。lower_bound(keyElem);//返回第一个 key&lt;=keyElem 元素的迭代器。upper_bound(keyElem);//返回第一个 key&gt;keyElem 元素的迭代器。equal_range(keyElem);//返回容器中 key 与 keyElem 相等的上下限的两个迭代器。","link":"/post/8d66854b.html"},{"title":"STL-queue 容器","text":"queue 是一种先进先出(first in first out, FIFO)的数据类型,他有两个口，只允许从队尾插入，队头弹出。 必须从一个口数据元素入队，另一个口数据元素出队。 不能随机存取，不支持遍历 queue 构造函数12queue&lt;T&gt; queT;//queue 采用模板类实现，queue 对象的默认构造形式：queue(const queue &amp;que);//拷贝构造函数 queue 存取、插入和删除操作1234push(elem);//往队尾添加元素pop();//从队头移除第一个元素back();//返回最后一个元素front();//返回第一个元素 queue 赋值操作1queue&amp; operator=(const queue &amp;que);//重载等号操作符 queue 大小操作12empty();//判断队列是否为空size();//返回队列的大小","link":"/post/4244b416.html"},{"title":"STL-set and multiset","text":"set 的底层是红黑树。具有良好的查找效率。set 容器中不允许出现重复的元素，multiset 允许重复元素。 set 构造函数123set&lt;T&gt; st;//set 默认构造函数：mulitset&lt;T&gt; mst; //multiset 默认构造函数:set(const set &amp;st);//拷贝构造函数 set 赋值操作12set&amp; operator=(const set &amp;st);//重载等号操作符 swap(st);//交换两个集合容器 set 大小操作12size();//返回容器中元素的数目empty();//判断容器是否为空 set 插入和删除操作12345insert(elem);//在容器中插入元素。clear();//清除所有元素erase(pos);//删除 pos 迭代器所指的元素，返回下一个元素的迭代器。erase(beg, end);//删除区间[beg,end)的所有元素 ，返回下一个元素的迭代器。erase(elem);//删除容器中值为 elem 的元素。 set 查找操作1234find(key);//查找键 key 是否存在,若存在， 返回该键的元素的迭代器；若不存在， 返回 map.end();lower_bound(keyElem);//返回第一个 key&gt;=keyElem 元素的迭代器。upper_bound(keyElem);//返回第一个 key&gt;keyElem 元素的迭代器。equal_range(keyElem);//返回容器中 key 与 keyElem相等的上下限的两个迭代器。","link":"/post/adaa2861.html"},{"title":"STL-string 容器","text":"string 是对 char * 的封装，具有如下特性： char 是一个指针，string 是一个类。string 实现了对 char 的封装，是 char* 的容器 string 封装了许多字符串操作的方法，比如 find、copy、delete、replace、insert 等 不用考虑内存释放和越界，内存由 string 类负责维护 string 与 char* 互相转换1234567// string 转 char*string str = \"www.shuiyujie.com\";const char* cstr = str.c_str();// char* 装 stringchar * s = \"www.shuiyujie.com\";string sstr(s); string 的构造函数123456789101112131415string();//创建一个空的字符串,例如: string str;string(const string&amp; str);//使用一个string对象初始化另一个string对象string(const char* s);//使用字符串 s 初始化 string(int n, charc);//使用 n 个字符 c 初始化//例子://默认构造函数string s1;//拷贝构造函数string s2(s1);string s2 = s1;//带参数构造函数char* str = \"www.shuiyujie.com\";string s3(str);string s4(10, 'a'); string 基本赋值操作12345678string&amp; operator=(const char* s);//char*类型字符串赋值给当前的字符串string&amp; operator=(const string &amp;s);//把字符串 s 赋给当前的字符串string&amp; operator=(char c);//字符赋值给当前的字符串string&amp; assign(const char *s);//把字符串 s 赋给当前的字符串string&amp; assign(const char *s, int n);//把字符串 s 的前 n 个字符赋给当前的字符串string&amp; assign(const string &amp;s);//把字符串 s 赋给当前字符串string&amp; assign(int n, char c);//用 n 个字符 c 赋给当前字符串string&amp; assign(const string &amp;s, int start, int n);//将 s 从 start 开始 n 个字符赋值给字符串 string 取字符串操作1234567char&amp; operator[](int n);//通过[]方式取字符char&amp; at(int n);//通过 at 方法获取字符//例子:string s = \"www.shuiyujie.com\";char c = s[];c = s.at(1); Q: string 中存取字符[]和 at 的异同? A: 相同,[]和 at 都可以返回第 n 个字符 不同，at 访问越界会抛出异常，[]越界会直接程序会挂掉。 string 拼接操作12345678string&amp; operator+=(const string&amp; str);//重载+=操作符string&amp; operator+=(const char* str);//重载+=操作符string&amp; operator+=(const char c);//重载+=操作符string&amp; append(const char *s);//把字符串 s 连接到当前字符串结尾string&amp; append(const char *s, int n);//把字符串 s 的前 n 个字符连接到当前字符串结尾string&amp; append(const string &amp;s);//同 operator+=()string&amp; append(const string &amp;s, int pos, int n);//把字符串 s 中从 pos 开始的 n 个字符连接到当前字符串结尾string&amp; append(int n, char c);//在当前字符串结尾添加 n 个字符 c string 查找和替换12345678910int find(const string&amp; str, int pos = 0) const; //查找 str 第一次出现位置,从 pos 开始查找int find(const char* s, int pos = 0) const; //查找 s 第一次出现位置,从 pos 开始查找int find(const char* s, int pos, int n) const; //从 pos 位置查找 s 的前 n 个字符第一次位置int find(const char c, int pos = 0) const; //查找字符 c 第一次出现位置int rfind(const string&amp; str, int pos = npos) const;//查找 str 最后一次位置,从 pos 开始查找int rfind(const char* s, int pos = npos) const;//查找 s 最后一次出现位置,从 pos 开始查找int rfind(const char* s, int pos, int n) const;//从 pos 查找 s 的前 n 个字符最后一次位置int rfind(const char c, int pos = 0) const; //查找字符 c 最后一次出现位置string&amp; replace(int pos, int n, const string&amp; str); //替换从 pos 开始 n 个字符为字符串 strstring&amp; replace(int pos, int n, const char* s); //替换从 pos 开始的 n 个字符为字符串 s string 比较操作12345678/*compare 函数在&gt;时返回 1， &lt;时返回 -1，==时返回 0。比较区分大小写，比较时参考字典顺序，排越前面的越小。大写的 A 比小写的 a 小。*/int compare(const string &amp;s) const;//与字符串 s 比较int compare(const char *s) const;//与字符串 s 比较 string 子串1string substr(int pos = 0, int n = npos) const;//返回由 pos 开始的 n 个字符组成的字符串 string 插入和删除操作1234string&amp; insert(int pos, const char* s); //插入字符串 string&amp; insert(int pos, const string&amp; str); //插入字符串string&amp; insert(int pos, int n, char c);//在指定位置插入 n 个字符 cstring&amp; erase(int pos, int n = npos);//删除从 Pos 开始的 n 个字符","link":"/post/2d250e1c.html"},{"title":"STL-stack 容器","text":"栈 stack 是一种先进后出(first in last out,FILO)的数据结构，它只有一个出口，stack 只允许在栈顶新增元素，移除元素。 栈不能遍历,不支持随机存取，只能通过 top 从栈顶获取和删除元素。 stack 构造函数12stack&lt;T&gt; stkT;//stack 采用模板类实现, stack 对象的默认构造形式：stack(const stack &amp;stk);//拷贝构造函数 stack 赋值操作1stack&amp; operator=(const stack &amp;stk);//重载等号操作符 stack 数据存取操作123push(elem);//向栈顶添加元素pop();//从栈顶移除第一个元素top();//返回栈顶元素 stack 大小操作12empty();//判断堆栈是否为空size();//返回堆栈的大小","link":"/post/ac4a7cfa.html"},{"title":"STL-vector 容器","text":"vector 是动态数组，连续内存空间，具有随机存取效率高的优点。 vector 是单口容器，在队尾插入和删除元素效率高，在指定位置插入会导致数据 元素移动，效率低。 vector 构造函数12345678vector&lt;T&gt; v; //采用模板实现类实现，默认构造函数vector(v.begin(), v.end());//将 v[begin(), end())区间中的元素拷贝给本身。vector(n, elem);//构造函数将 n 个 elem 拷贝给本身。vector(const vector &amp;vec);//拷贝构造函数。//例子 使用第二个构造函数我们可以...int arr[] = {2,3,4,1,9};vector&lt;int&gt; v1(arr, arr + sizeof(arr)/sizeof(int)); vector 常用赋值操作12345678assign(beg, end);//将[beg, end)区间中的数据拷贝赋值给本身。assign(n, elem);//将 n 个 elem 拷贝赋值给本身。vector&amp; operator=(const vector &amp;vec);//重载等号操作符swap(vec);// 将 vec 与本身的元素互换。//第一个赋值函数，可以这么写：int arr[] = { 0, 1, 2, 3, 4 };assign(arr, arr + 5);//使用数组初始化 vector vector 大小操作123456size();//返回容器中元素的个数empty();//判断容器是否为空resize(int num);//重新指定容器的长度为 num，若容器变长，则以默认值填充新位置。如果容器变短，则末尾超出容器长度的元素被删除。resize(int num, elem);//重新指定容器的长度为 num，若容器变长，则以 elem 值填充新位置。如果容器变短，则末尾超出容器长&gt;度的元素被删除。capacity();//容器的容量reserve(int len);//容器预留 len个元素长度，预留位置不初始化，元素不可访问。 resize 若容器变长，则以默认值填充新位置。如果容器变短，则末尾超出容器长度的 元素被删除。 reserve 是容器预留空间，但在空间内不真正创建元素对象，所以在没有添加新的对 象之前，不能引用容器内的元素. resize 是改变容器的大小，且在创建对象，因此，调用这个函数之后，就可以引用容器内的对象了. vector 数据存取操作1234at(int idx); //返回索引 idx 所指的数据，如果 idx 越界，抛出 out_of_range 异常。operator[];//返回索引 idx 所指的数据，越界时，运行直接报错front();//返回容器中第一个数据元素back();//返回容器中最后一个数据元素 vector 插入和删除操作123456insert(const_iterator pos, int count,ele);//迭代器指向位置 pos 插入 count 个元素 ele.push_back(ele); //尾部插入元素 elepop_back();//删除最后一个元素erase(const_iterator start, const_iterator end);//删除迭代器从 start 到 end 之间的元素erase(const_iterator pos);//删除迭代器指向的元素clear();//删除容器中所有元素 总结vector 是个动态数组，当空间不足的时候插入新元素，vector 会重新申请一块更大的 内存空间，将旧空间数据拷贝到新空间，然后释放旧空间。vector 是单口容器，所以在尾 端插入和删除元素效率较高，在指定位置插入，势必会引起数据元素移动，效率较低。","link":"/post/39bf26c3.html"},{"title":"STL-常用算法","text":"常用遍历、查找、拷贝和替换、算数生成、集合算法。 遍历算法12345678910111213141516171819/*遍历算法,遍历容器元素@param beg 开始迭代器@param end 结束迭代器@param _callback 函数回调或者函数对象@return 函数对象*/for_each(iterator beg, iterator end, _callback);/*transform 算法,将指定容器区间元素搬运到另一容器中注意: transform 不会给目标容器分配内存，所以需要我们提前分配好内存@param beg1 源容器开始迭代器@param end1 源容器结束迭代器@param beg2 目标容器开始迭代器@param _cakkback 回调函数或者函数对象@return 返回目标容器迭代器*/transform(iterator beg1, iterator end1, iterator beg2, _callbakc) 查找算法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/*find 算法, 查找元素@param beg 容器开始迭代器@param end 容器结束迭代器@param value 查找的元素@return 返回查找元素的位置*/find(iterator beg, iterator end, value) /*adjacent_find 算法,查找相邻重复元素@param beg 容器开始迭代器@param end 容器结束迭代器@param _callback 回调函数或者谓词(返回 bool 类型的函数对象)@return 返回相邻元素的第一个位置的迭代器*/adjacent_find(iterator beg, iterator end, _callback);/*binary_search 算法二分查找法注意: 在无序序列中不可用@param beg 容器开始迭代器@param end 容器结束迭代器@param value 查找的元素@return bool 查找返回 true 否则 false*/bool binary_search(iterator beg, iterator end, value);/*find_if 算法 条件查找@param beg 容器开始迭代器@param end 容器结束迭代器@param callback 回调函数或者谓词(返回 bool 类型的函数对象)@return bool 查找返回 true 否则 false*/find_if(iterator beg, iterator end, _callback);/*count 算法 统计元素出现次数@param beg 容器开始迭代器@param end 容器结束迭代器@param value 回调函数或者谓词(返回 bool 类型的函数对象)@return int 返回元素个数*/count(iterator beg, iterator end, value);/*count 算法 统计元素出现次数@param beg 容器开始迭代器@param end 容器结束迭代器@param callback 回调函数或者谓词(返回 bool 类型的函数对象)@return int 返回元素个数*/count_if(iterator beg, iterator end, _callback); 排序算法1234567891011121314151617181920212223242526272829303132/*merge 算法 容器元素合并，并存储到另一容器中@param beg1 容器 1 开始迭代器@param end1 容器 1 结束迭代器@param beg2 容器 2 开始迭代器@param end2 容器 2 结束迭代器@param dest 目标容器开始迭代器*/merge(iterator beg1, iterator end1, iterator beg2, iterator end2, iterator dest) /*sort 算法 容器元素排序注意:两个容器必须是有序的@param beg 容器 1 开始迭代器@param end 容器 1 结束迭代器@param _callback 回调函数或者谓词(返回 bool 类型的函数对象)*/sort(iterator beg, iterator end, _callback)/*sort 算法 对指定范围内的元素随机调整次序@param beg 容器开始迭代器@param end 容器结束迭代器*/random_shuffle(iterator beg, iterator end) /*reverse 算法 反转指定范围的元素@param beg 容器开始迭代器@param end 容器结束迭代器*/reverse(iterator beg, iterator end) 拷贝和替换算法1234567891011121314151617181920212223242526272829303132/*copy 算法 将容器内指定范围的元素拷贝到另一容器中@param beg 容器开始迭代器@param end 容器结束迭代器@param dest 目标容器结束迭代器*/copy(iterator beg, iterator end, iterator dest) /*replace 算法 将容器内指定范围的旧元素修改为新元素@param beg 容器开始迭代器@param end 容器结束迭代器@param oldvalue 旧元素@param oldvalue 新元素*/replace(iterator beg, iterator end, oldvalue, newvalue) /*replace_if 算法 将容器内指定范围满足条件的元素替换为新元素@param beg 容器开始迭代器@param end 容器结束迭代器@param callback 函数回调或者谓词(返回 Bool 类型的函数对象)@param oldvalue 新元素*/replace_if(iterator beg, iterator end, _callback, newvalue)/*swap 算法 互换两个容器的元素@param c1 容器 1@param c2 容器 2*/swap(container c1, container c2) 算数生成算法123456789101112131415/*accumulate 算法 计算容器元素累计总和@param beg 容器开始迭代器@param end 容器结束迭代器@param value 累加值*/accumulate(iterator beg, iterator end, value)/*fill 算法 向容器中添加元素@param beg 容器开始迭代器@param end 容器结束迭代器@param value t 填充元素*/fill(iterator beg, iterator end, value) 集合算法1234567891011121314151617181920212223242526272829303132333435/*set_intersection 算法 求两个 set 集合的交集注意:两个集合必须是有序序列@param beg1 容器 1 开始迭代器@param end1 容器 1 结束迭代器@param beg2 容器 2 开始迭代器@param end2 容器 2 结束迭代器@param dest 目标容器开始迭代器@return 目标容器的最后一个元素的迭代器地址*/set_intersection(iterator beg1, iterator end1, iterator beg2, iterator end2, iterator dest) /*set_union 算法 求两个 set 集合的并集注意:两个集合必须是有序序列@param beg1 容器 1 开始迭代器@param end1 容器 1 结束迭代器@param beg2 容器 2 开始迭代器@param end2 容器 2 结束迭代器@param dest 目标容器开始迭代器@return 目标容器的最后一个元素的迭代器地址*/set_union(iterator beg1, iterator end1, iterator beg2, iterator end2, iterator dest)/*set_difference 算法 求两个 set集合的差集注意:两个集合必须是有序序列@param beg1 容器 1 开始迭代器@param end1 容器 1 结束迭代器@param beg2 容器 2 开始迭代器@param end2 容器 2 结束迭代器@param dest 目标容器开始迭代器@return 目标容器的最后一个元素的迭代器地址*/set_difference(iterator beg1, iterator end1, iterator beg2, iterator end2, iterator dest)","link":"/post/b974f564.html"},{"title":"目录-C/C++学习笔记","text":"C 语言学习笔记 C语言学习笔记-静态库、动态库的制作和使用 C语言学习笔记-写一个最简单的makefile C语言学习笔记-文件操作 C语言学习笔记-结构体 C语言学习笔记-const关键字 C语言学习笔记-字符串 C语言学习笔记-指针01 C++ 学习笔记 C++学习笔记-引用 C++学习笔记-内联函数、默认参数和函数重载 C++学习笔记-构造函数、析构函数、拷贝构造函数 C++学习笔记-静态方法、静态函数、this指针 C++学习笔记-继承 C++学习笔记-多态 零散知识点 C/C++ 中的命令行参数 C 语言-格式化输出函数 printf() STL 学习笔记 STL-STL基础概念 STL-string 容器 STL-vector 容器 STL-deque 容器 STL-queue 容器 STL-stack 容器 STL-list 容器 STL-set and multiset STL-map and multimap STL-常用算法","link":"/post/789284ab.html"},{"title":"【Caffe】Caffe实战手写数字分类","text":"Caffe是优秀的深度学习开源框架，并具有良好的开源生态，我们可以在Model zoo中找到许多模型的实现。本文以 Caffe 提供的 Training LeNet on MNIST with Caffe 为例，介绍 Caffe 使用流程，并且在原文基础上增加可视化 accuracy 和 loss 的内容。 本文的目标是能够了解 Caffe 基本的使用流程。 准备数据在安装和编译 Caffe 之后进入根目录，执行以下命令，将会下载 MNIST 数据集。 123cd $CAFFE_ROOT./data/mnist/get_mnist.sh #下载 mnist 数据集./examples/mnist/create_mnist.sh # 将下载下来的数据集格式调整为 caffe 能够解析的格式 数据集包括 mnist_train_lmdb 和 mnist_test_lmdb 两部分。 定义 NetCaffe 提供的示例中使用 lenet_train_test.prototxt 定义 LeNet 的网络结构。LetNet 网络结构为卷积层 -&gt; 池化层 -&gt; 卷积层 -&gt; 池化层 -&gt; 全连接层 -&gt; 全连接层 -&gt; 全连接层。Caffe 用 layer 来表示表示网络，网络被定义在以.prototxt结尾的文件中，因为 Caffe 使用了 Google Protobuf 作为数据传输的格式。 在 lenet_train_test.prototxt 中我们可看到name: &quot;LeNet&quot;表示网络结构的名称为 LeNet，接下来是 123456789101112131415layer { name: \"mnist\" # 名称 type: \"Data\" # 输入层 transform_param { scale: 0.00390625 # 归一化，范围为 0-1 } data_param { source: \"mnist_train_lmdb\" # 指定要读取的数据 backend: LMDB batch_size: 64 } top: \"data\" top: \"label\"}... 我们可以通过 http://ethereon.github.io/netscope/#/editor 生成网络图像，或者使用 caffe 提供的脚本，它在caffe/python/draw_net.py。 配置 SolverSolver 用来指定训练的一些参数，比如使用哪个网络、迭代次数、优化方法、使用 GPU 还是 CPU 等信息。 12345678910111213141516171819202122232425# The train/test net protocol buffer definitionnet: \"examples/mnist/lenet_train_test.prototxt\"# test_iter specifies how many forward passes the test should carry out.# In the case of MNIST, we have test batch size 100 and 100 test iterations,# covering the full 10,000 testing images.test_iter: 100# Carry out testing every 500 training iterations.test_interval: 500# The base learning rate, momentum and the weight decay of the network.base_lr: 0.01momentum: 0.9weight_decay: 0.0005# The learning rate policylr_policy: \"inv\"gamma: 0.0001power: 0.75# Display every 100 iterationsdisplay: 100# The maximum number of iterationsmax_iter: 10000# snapshot intermediate resultssnapshot: 5000snapshot_prefix: \"examples/mnist/lenet\"# solver mode: CPU or GPUsolver_mode: GPU 训练训练的时候指定 Solver，保存权值文件的路径，日志：./examples/mnist/train_lenet.sh -gpu 1 12345#!/usr/bin/env shset -eSOLVER=examples/mnist/lenet_solver.prototxtWEIGHTS=./lenet_iter_10000.caffemodel./build/tools/caffe train --solver=${SOLVER} $@ 2&gt;&amp;1 | tee log.txt 通过解析日志，我们能够可视化模型训练过程中的 accuray 和 loss 的情况。 1234567891011121314151617181920# 解析日志文件,将 acc 和 loss 输出到 .refine 文件grep \"Test net output #0: accuracy =\" log.txt &gt; trainacc.refinegrep \"Test net output #1: loss =\" log.txt &gt; trainloss.refine# 生成如下所示的 .refine 文件# trainacc.refineI0615 10:16:15.671094 11161 solver.cpp:414] Test net output #0: accuracy = 0.9903I0615 10:16:16.061339 11161 solver.cpp:414] Test net output #0: accuracy = 0.9903I0615 10:16:16.451835 11161 solver.cpp:414] Test net output #0: accuracy = 0.988I0615 10:16:16.850911 11161 solver.cpp:414] Test net output #0: accuracy = 0.9906# trainloss.refineI0615 10:16:15.671116 11161 solver.cpp:414] Test net output #1: loss = 0.0298686 (* 1 = 0.0298686 loss)I0615 10:16:16.061362 11161 solver.cpp:414] Test net output #1: loss = 0.0285139 (* 1 = 0.0285139 loss)I0615 10:16:16.451859 11161 solver.cpp:414] Test net output #1: loss = 0.0348767 (* 1 = 0.0348767 loss)I0615 10:16:16.850932 11161 solver.cpp:414] Test net output #1: loss = 0.0284803 (* 1 = 0.0284803 loss)# 接着用 python 脚本解析 .refine 绘制 acc 和 loss 曲线python show_acc.pypython show_loss.py Python 脚本可以在 Github Gist 中查看，需要根据之前生成的日志进行小改动。 可以看到迭代 100 次 loss 已经降到很低了,之后略有降低,300次左右基本上就在 0.3, 0.4 左右 与之相对的，100 次左右准确率就有 0.96 了,缓慢上升,最后准确率稳定在 0.98 。 测试测试的方法和训练的方法基本一致，使用 ./examples/mnist/test_lenet.sh -gpu 1 123456789101112#!/usr/bin/env shset -eMODEL=examples/mnist/lenet_iter_10000.caffemodelTRAIN_NET=examples/mnist/lenet_train_test.prototxt./build/tools/caffe test -model ${TRAIN_NET} -weights ${MODEL} $@ 2&gt;&amp;1 | tee test_log.txt# 结果如下所示...I0616 15:29:32.107722 13441 caffe.cpp:304] Batch 49, accuracy = 1I0616 15:29:32.107739 13441 caffe.cpp:304] Batch 49, loss = 0.00704199I0616 15:29:32.107748 13441 caffe.cpp:309] Loss: 0.0412109I0616 15:29:32.107769 13441 caffe.cpp:321] accuracy = 0.9862I0616 15:29:32.107782 13441 caffe.cpp:321] loss = 0.0412109 (* 1 = 0.0412109 loss) 用上面同样的方法能够可视化测试的 loss 和 accuracy。 本文介绍了 Caffe 的基本使用流程，这样就可以把一些别人写好的网络用起来了。进一步我们需要了解如何用 Caffe 自定义网络结构，调整网络的参数，完成更加个性化的任务。 参考： Training LeNet on MNIST with Caffe A step by step guide to Caffe Caffe Caffe Model zoo","link":"/post/96cd1245.html"},{"title":"计算机视觉学习路线","text":"深度学习算法工程师的基本要求 熟练掌握python和c++编程，至少熟悉 Caffe 和 Tensorflow/Pytorch 两种框架。 熟练玩转深度学习各类模型架构使用和设计。 熟练玩转数据的整理和使用，必须深刻理解数据在深度学习任务中的地位。 编程语言C/C++ C/C++面试基础知识总结 Google 开源项目风格指南 (中文版) Python Python - 100天从新手到大师 List of Data Science Cheatsheets to rule the world 一些有趣且鲜为人知的 Python 特性. Python 爬虫相关 Linux Linux命令大全搜索工具，内容包含Linux命令手册、详解、学习、搜集 shell &amp; git &amp; vim OpenCV 《OpenCV3编程入门》书本配套源码 LearnOpencv 基于OpenCV4.0 C++/Python SDK的案例代码演示程序与效果图像 opencv 理论知识相关论文 computer version Awesome-AutoML-Papers Most popular metrics used to evaluate object detection algorithms. virgilio 深度学习 CS231 李飞飞 已授权个人翻译笔记 深度学习500问 《神经网络与深度学习》 Neural Network and Deep Learning 《机器学习》（西瓜书）公式推导解析 吴恩达老师的机器学习课程个人笔记 深度学习入门教程&amp;&amp;优秀文章&amp;&amp;Deep Learning Tutorial 机器学习&amp;深度学习网站资源汇总（Machine Learning Resources） 深度学习工程模板 Deep Learning Models 深度学习模型大合集 Awesome Deep Learning 机器学习 统计学习方法 《统计学习方法》的代码实现 《统计学习方法》知识点总结 Numpy手写主流机器学习模型 100-Days-Of-ML-Code 100-Days-Of-ML-Code中文版 机器学习算法python实现 Homemade Machine Learning Awesome Machine Learning 开源框架TensorFlow TensorFlow 2.0 Tutorials TensorFlow examples TensorFlow Tutorial and Examples for Beginners (support TF v1 &amp; v2) TensorFlow Course An Open Source Machine Learning Framework for Everyone Pytorch Awesome-Pytorch-list Pytorch模型训练实用教程 Caffe BVLC/caffe Darknet darknet深度学习框架源码分析 AlexeyAB/darknet","link":"/post/9027adc3.html"},{"title":"Protobuf 编译 Java","text":"Google Protocol Buffers 简称 Protobuf，它提供了一种灵活、高效、自动序列化结构数据的机制，可以联想 XML，但是比 XML 更小、更快、更简单。仅需要自定义一次你所需的数据格式，然后用户就可以使用 Protobuf 编译器自动生成各种语言的源码，方便的读写用户自定义的格式化的数据。与语言无关，与平台无关，还可以在不破坏原数据格式的基础上，依据老的数据格式，更新现有的数据格式。 官方下载地址： https://github.com/google/protobuf/releases/tag/v2.6.1 protobuf-2.6.1 百度云盘： 链接:http://pan.baidu.com/s/1hrK7m7a 密码:epnb 安装过程 解压文件 unzip protobuf-2.6.1.zip 进入目录 cd protobuf-2.6.1 自定义编译目录 ./configure –prefix= /Users/shui/company/protobuf 安装 make mak install 配置环境变量 vim .bash_profile 添加如下配置 export PROTOBUF=/Users/shui/company/protobufexport PATH=$PROTOBUF/bin:$PATH` 使配置生效 source .bash_profile 查看是否生效 protoc –version 安装结束，进行编译 指定需要进行编译的 proto 文件 指定编译产生的 java 文件存放的位置 假设文件名为 file.proto,文件放置在 filedir 目录下；产生的java文件也位于 filedir 目录下，编译命令如下： protoc /filedir/file/proto –java_out=/filedir 如果有很多需要编译的 proto 文件，可以进入项目目录 protoc *.proto –java_out=/filedir 参考： https://github.com/google/protobuf/tree/master/javahttp://blog.csdn.net/u013045971/article/details/50592998http://my.oschina.NET/KingPan/blog/283881?fromerr=8vajR5S9","link":"/post/7e6ba807.html"},{"title":"Ubuntu配置JDK","text":"wget下载jdk8 1wget --no-cookies --no-check-certificate --header \"Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie\" \"http://download.oracle.com/otn-pub/java/jdk/8u141-b15/336fa29ff2bb4ef291e347e091f7f4a7/jdk-8u141-linux-x64.tar.gz\" 解压 1tar xzf jdk-8u141-linux-x64.tar.gz 配置环境变量 vim /etc/profile 1234JAVA_HOME=/home/shui/java/jdk1.8.0_141JRE_HOME=/home/shui/java/jdk1.8.0_141/jreCLASS_PATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libPATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin 使配置生效 123export JAVA_HOME JRE_HOME CLASS_PATH PATHsource /etc/profile","link":"/post/1d66a96c.html"},{"title":"CentOS 7 配置","text":"本文说明如何在 Parallels 虚拟机上安装 CentOS 7 以及对其的一些基本配置，几个常用配置文件的说明和 JDK, Tomcat 和 Mysql 的安装。 CentOS 7 基本配置安装 centos 7首先下载镜像文件，我装的是 CentOS-7-x86_64-Minimal-1708.iso。我从网易的镜像下载，下载完后上传了一份到百度云盘： 网易镜像地址：http://mirrors.163.com/centos/7/isos/x86_64/百度云盘链接:http://pan.baidu.com/s/1gf7w1uN 密码:5lbx 之后按照引导即可完成，有问题可以参看 Mac利用PD虚拟机安装Centos7。 更换 yum 源yum 是一种包管理工具，就像 Java 中常用的 maven，或者安卓中用的 Gradle，再或者 Node.js 中的 npm。通过他我们能够统一地下载安装软件。但是由于网络原因下载缓慢，所以要把源换成国内的。更换过程如下： 备份： mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup 去下面的源下载对应版本repo文件, 放入/etc/yum.repos.d/ repo文件下载地址： 网易:http://mirrors.163.com/.help/centos.html阿里:http://mirrors.aliyun.com/repo/ 运行以下命令生成缓存 yum clean allyum makecache yum 源配置完成 通过 yum 安装一些基本软件net-tools 提供dig, nslookup, ipconfig等，用于配置网络： yum install net-tools 添加 wget 下载文件： yum install wget 创建一个普通用户并赋予 root 权限用普通账号进行登录可以避免 root 用户进行错误操作，而且用普通用户登录就像给服务器建立了两道墙，必须先用普通用户登录再设置能用 root 账号登录，所以后面还要配置禁止 root 用户用过 SSH 登录。 创建普通用户 useradd shuipasswd shui输入密码 这个普通用户有时也需要使用 root 权限，所以讲他加入到sudoers 用户组，允许其使用sudo临时调用 root 权限 echo ‘shui ALL=(ALL) ALL’&gt;&gt; /etc/sudoerstail -1 /etc/sudoersshui ALL=(ALL) ALL 禁止 root 使用 ssh 登入进入配置文件： /etc/ssh/sshd_config 找到如下语句进行修改 PermitRootLogin yes 把它改成 PermitRootLogin no 重启 sshd systemctl restart sshd.service 这样别人就要必须要获取普通用户账号密码，然后才能破解 root 将防火墙换成 iptablesCentOS 7.0 默认使用的是 firewall 作为防火墙，常用的是 iptables。先关闭 firewall 再安装 iptables。 关闭 firewall 1234#停止firewallsystemctl stop firewalld.service #禁止firewall开机启动systemctl disable firewalld.service 安装 iptables yum -y install iptables-services 启动 iptables 1234#重启防火墙使配置生效systemctl restart iptables.service #设置防火墙开机启动systemctl enable iptables.service 关闭 SELinux查看 SELinux 状态 /usr/sbin/sestatus -v | grep SELinuxSELinux status: enabled # 表示为开启状态 永久关闭，重启生效 vi /etc/selinux/config#修改内容如下SELINUX=disabled 更改系统语言查看当前系统语言 12345localectlSystem Locale: LANG=zh_CN.UTF-8 VC Keymap: cn X11 Layout: cn 查看系统中存在的语言列表，因为很长通过 grep 来查找需要的语言是否存在 12345678localectl list-locales | grep USen_USen_US.iso88591en_US.iso885915en_US.utf8.. 设置自己要改的语言 1localectl set-locale LANG=en_US.UTF-8 参考：CentOS yum 源的配置与使用 安裝 CentOS 7 後必做的七件事 Change system language in centos 7 一些配置文件的修改修改主机名可以用hostname来查看你的主机名，修改主机名配置文件： vi /etc/hostname 重启生效 reboot 修改 ip 地址 vi /etc/sysconfig/network-scripts/ifcfg-eth0 在网卡中配置如下内容可以设置静态 ip 12345678DEVICE=eth0TYPE=EthernetONBOOT=yesBOOTPROTO=staticIPADDR=192.168.0.11NETMASK=255.255.255.0DNS1=192.168.0.1DNS2=8.8.8.8 配置完之后保存重启网络 service network restart 设置 ip 和 hostname 的映射 vi /etc/hosts 添加上 ip 和 hostname 的键值对，举例前面设置hostname为 main 设置ip为 192.168.0.11 在最后追加一行： 123127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain6192.168.0.11 main 之后可以用主机名进行访问 安装 JDK将 JDK 安装包上传，上传可以使用 scp,rz 从本机上传，也可以直接下载。 解压 JDK 安装包： tar -zxvf jdk-8u151-linux-x64.tar.gz -C /usr/local 配置环境变量： 12345vi /etc/profile# 追加内容如下export JAVA_HOME=/usr/local/jdk1.8.0_151export PATH=$PATH:$JAVA_HOME/bin 加载环境变量： source /etc/profile 更多 linux配置java环境变量(详细) 安装 Tomcat点击此处下载安装包。本文使用的版本是apache-tomcat-8.5.23.tar.gz，下载后再安装包传到 Linux 主机。 解压安装包： tar -zxvf apache-tomcat-8.5.23.tar.gz -C /usr/local/ 启动 tomacat /usr/local/apache-tomcat-8.5.23/bin/startup.sh 查看 tomcat 进程 ps -ef | grep tomcat 访问http://192.168.2.224:8080/即主机 ip + tomcat 端口。小猫出现表示成功。 安装 MysqlMysql 安装之前先留个心，安装过程中可能会需要记录密码，有些默认没有密码，请留心有没有提示记录密码，然而没看见也没关系就是要再折腾一下。本文演示用yum安装 mysql 数据库。 配置YUM源1234567891011# 下载mysql源安装包shell&gt; wget http://dev.mysql.com/get/mysql57-community-release-el7-8.noarch.rpm# 安装mysql源shell&gt; yum localinstall mysql57-community-release-el7-8.noarch.rpm# 检查mysql源是否安装成功yum repolist enabled | grep &quot;mysql.*-community.*&quot;# 成功显示如下mysql-connectors-community/x86_64 MySQL Connectors Community 42mysql-tools-community/x86_64 MySQL Tools Community 51mysql57-community/x86_64 MySQL 5.7 Community Server 227 安装MySQL yum install mysql-community-server 启动 mysql systemctl start mysqld 查看MySQL的启动状态 systemctl status mysqld 修改 root 默认密码mysql安装完成之后，在/var/log/mysqld.log文件中给root生成了一个默认密码。通过下面的方式找到root默认密码，然后登录mysql进行修改： grep ‘temporary password’ /var/log/mysqld.log2017-11-15T16:26:37.970235Z 1 [Note] A temporary password is generated for root@localhost: d54aqgZr69&gt;d 此时默认的密码就是d54aqgZr69&gt;d，用 root 身份登录之后修改密码： mysql -uroot -pALTER USER ‘root‘@’localhost’ IDENTIFIED BY ‘MyNewPass1!’; 注：mysql 的密码需要有一定复杂度 更多请参考:CentOS7下安装MySQL5.7安装与配置（YUM）","link":"/post/99732d8a.html"},{"title":"Linux目录结构","text":"/bin - 基本命令的二进制文件。 /boot - 引导加载程序的静态文件。 /dev - 设备文件。 /etc - 配置文件。 /home - 普通用户主目录的父目录。 /lib - 共享库文件。 /lib64 - 共享64位库文件。 /lost+found - 存放未链接文件。 /media - 自动识别设备的挂载目录。 /mnt - 临时挂载文件系统的挂载点。 /opt - 可选插件软件包安装位置。 /proc - 内核和进程信息。 /root - 超级管理员用户主目录。 /run - 存放系统运行时需要的东西。 /sbin - 超级用户的二进制文件。 /sys - 设备的伪文件系统。 /tmp - 临时文件夹。 /usr - 用户应用目录。 /var - 变量数据目录。","link":"/post/5e2eb880.html"},{"title":"Linux进程","text":"ps：显示当前所有进程的运行情况。 top：实时显示当前所有任务的资源占用情况。 jobs：列出所有活动作业的状态信息。 bg：设置在后台中运行作业。 fg：设置在前台中运行作业。 kill：发送信号给某个进程。 killall：杀死指定名字的进程。 shutdown：关机或者重启系统。 使用ps命令查看进程信息","link":"/post/87698413.html"},{"title":"Linux 权限","text":"Linux 是多用户的操作系统，同一时间可以有多个用户同时操作同一台计算机。为了让用户和用户之间不相互影响，必须要有一种机制来保障每一个用户的行为不会越界对其他用户造成不必要的影响。 用户和用户组了解 Linux 的权限管理首先要了解用户和组的概念。Linux 引入了用户和用户组的概念，一个用户可以拥有多个文件和目录， 用户对这个文件或目录的访问权限拥有控制权。同时用户可以属于一个或者多个用户组，用户组中的用户拥有同属于这个组的对文件的访问控制权。 Linux 会给每个用户分配一个 uid（标识用户） 和 gid (标识用户组)，在创建用户的时候默认就会创建一个和用户名同名的用户组，我可以用id命令来查看： iduid=0(root) gid=0(root) 组=0(root) 环境=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 这些信息都是配置在配置文件中的，我们有必要了解这些信息在哪些配置文件中,他们主要配置在三个文件中/etc/shadow,/etc/passwd和/etc/group。 用户帐户 定义在/etc/passwd 文件里面，用户组定义在/etc/group 文件里面。当用户帐户和用户组创建以后， 这些文件随着文件/etc/shadow 的变动而修改，文件/etc/shadow 包含了关于用户密码的信息。 对于每个用户帐号，文件/etc/passwd 定义了用户（登录）名、uid、gid、帐号的真实姓名、家目录 和登录 shell。如果你查看一下文件/etc/passwd 和文件/etc/group 的内容，你会注意到除了普通 用户帐号之外，还有超级用户（uid 0）帐号，和各种各样的系统用户。 基本的用户管理创建一个普通用户添加用户 useradd shui 设置密码 passwd shui 按提示输入密码即可 这样就会创建一个新的用户，我们可以在/etc/group中看到新建的默认用户组的信息shui:x:1000:也可以再/etc/shadow,/etc/passwd看到相关信息。 为用户配置sudo权限配置sudo权限就是将永不加入到sudoers用户组中，这是一个特殊的用户组，在这个用户组中的用户可以通过在命令前面添加sudo临时获取root的权限。 用root编辑 vi /etc/sudoers 在文件的如下位置，为hadoop添加一行即可 root ALL=(ALL) ALLshui ALL=(ALL) ALL 或者使用如下语句也是相同效果 echo ‘shui ALL=(ALL) ALL’&gt;&gt; /etc/sudoers 然后，hadoop用户就可以用sudo来执行系统级别的指令 文件权限的操作前面说过用户具有对文件的的访问控制权，访问控制权具有可读、可写、可操作三种，我们来具体看一下 linux 文件权限的描述格式解读用ll命令来看一下根目录下的文件信息,我们复制其中的一部分： 1234dr-xr-xr-x. 5 root root 4096 11月 2 10:34 bootdrwxr-xr-x. 20 root root 3140 11月 2 10:36 devdrwxr-xr-x. 74 root root 8192 11月 2 20:48 etcdrwxr-xr-x. 3 root root 18 11月 2 19:03 home 每个文件的信息大同小异，关注最前面的十个字符，他就表示文件的操作权限。 以/etc目录的信息为例drwxr-xr-x. 74 root root 8192 11月 2 20:48 etc 第一位表示文件类型,d 表示这是一个文件夹，文件属性还有以下内容 后面的九位分别代表用户权限、用户组权限和其他用户权限 r:表示可读 read w:表示可惜 write x:表示可执行 excute /etc 目录的权限 rwxr-xr-x 就表示，root 用户具有可读可写可操作的权限，文件所有者的组成员可以访问该目录，但是不能新建、重命名、删除文件，其他成员可以访问该目录，但是不能新建、重命名、删除文件。 chmod 更改权限只有root和文件的所有者才能更改文件的权限，更改文件的权限有两种方式，一种是使用符号，另一种是使用八进制数字。 符号方式修改文件权限符号即前面rwx对应的含义，ugoa则分别表示用户(user)、用户组(group)、其他人(other)和所有(all),一组示例来演示： 123chmod g-rw haha.dat 表示将haha.dat对所属组的rw权限取消chmod o-rw haha.dat 表示将haha.dat对其他人的rw权限取消chmod u+x haha.dat 表示将haha.dat对所属用户的权限增加x 八进制的方式来修改权限一个八进制数字可以表示三个二进制数，二进制的 111 对应八进制的 7，而 111 正好可以表示 rwx 的含义，1 则代表有权限 0 则代表没有权限。 八进制 二进制 符号 0 000 — 1 001 —-x 2 010 -w- 3 011 -wx 4 100 r– 5 101 r-x 6 110 rw- 7 111 rwx 例如： chmod 664 haha.dat修改成 rw-rw-r– 一些人喜欢使用八进制表示法，而另一些人则非常喜欢符号表示法。符号表示法的优点是， 允许你设置文件模式的某个属性，而不影响其他的属性。","link":"/post/40efde90.html"},{"title":"Linux三剑客——Git","text":"","link":"/post/fd2c899.html"},{"title":"Ubuntu OpenSSH Server","text":"本文介绍如何使用OpenSSH实现计算机之间的远程控制和数据交换。你将了解到OpenSSH的一些配置以及如何在Ubuntu中修改这些配置。 Ubuntu16.04是目前Ubuntu较为稳定的版本，本文使用该版本进行说明。 介绍OpenSSH基于SSH协议，是用于实现计算机之间远程控制和数据交换的工作的工具。 传统的工具实现远程登录(telnet)和rcp等功能的方式不安全的，他们会用明文的方式交换用户密码。OpenSSH用后台进程和客户端工具来提高安全性，对远程控制和数据交换操作进行加密，比其他传统工具更加高效。 OpenSSH使用sshd持续地监听来自各个客户端程序的连接。当客户端发出连接请求，ssh根据客户端的连接类型来判断是否建立连接。比如，如果远程计算机是一个ssh客户端程序，OpenSSH将会在认证之后建立一个控制会话。如果远程用户使用scp进行连接，OpenSSH在认证之后会与客户端建立连接，并在后台初始化一个安全的文件拷贝。 OpenSSH可以使用密码、公钥和 Kerberos 等多种方式进行认证。 安装OpenSSH的安装非常简单，分别安装OpenSSH Sever和OpenSSH Client。 sudo apt install openssh-clientsudo apt install openssh-server 配置OpenSSH的配置文件是/etc/ssh/sshd_config，查看详细配置可以使用 man sshd_config 在修改配置文件之前我们应当对配置文件进行备份 sudo cp /etc/ssh/sshd_config /etc/ssh/sshd_config.originalsudo chmod a-w /etc/ssh/sshd_config.original 我们可以通过修改配置文件做这些事情： 将OpenSSH监听的默认TCP端口从2222改为默认端口22，可以修改Port 2222 允许运行使用公式登录，可以使用PubkeyAuthentication yes 修改完成之后重启服务使其生效 sudo systemctl restart sshd.service SSH Keys配置了ssh key允许主机之间直接通信而不用输入密码。 首选生成ssh key，使用一下命令并一路回车 ssh-keygen -t rsa 此时会在~/.ssh文件夹在生产一个密钥文件和一个公钥文件，我们将公钥拷贝给远程的主机 ssh-copy-id username@remotehost 之后用相同的方式将远程主机的公钥拷贝给本机，就可以实现双方免密登录。 最后我们还要注意，认证用户需要对用于认证的文件有读写的权限。 chmod 600 .ssh/authorized_keys 引用OpenSSH Server","link":"/post/cbbc9ca0.html"},{"title":"Linux中几种常用的文件传输方式","text":"整理scp,wget,ftp以及其他Linux中常用的文件传输方式的介绍。 scp当没有安装web server和ftp server的时候或感觉上面的方法比较麻烦，那么用scp命令就会排上用场。 scp是什么？scp是secure copy的简写，用于在Linux下进行远程拷贝文件的命令，和它类似的命令有cp，不过cp只是在本机进行拷贝不能跨服务器，而且scp传输是加密的。可能会稍微影响一下速度。 scp有什么用？1、我们需要获得远程服务器上的某个文件，远程服务器既没有配置ftp服务器，没有开启web服务器，也没有做共享，无法通过常规途径获得文件时，只需要通过scp命令便可轻松的达到目的。 2、我们需要将本机上的文件上传到远程服务器上，远程服务器没有开启ftp服务器或共享，无法通过常规途径上传是，只需要通过scp命令便可以轻松的达到目的。 scp使用方法获取远程服务器上的文件 scp root@192.168.0.223:/apps/test/a.md /Users/shui/Desktop/b.md root@192.168.0.223 : 使用root用户登录服务器192.168.0.223 /apps/test/a.md:本机要传递过去的文件 /Users/shui/Desktop/b.md：远程主机目录 获取远程服务器上的目录 scp -r root@192.168.0.223:/apps/test/a /Users/shui/Desktop/b 将本地文件上传到服务器上 scp test.txt root@192.168.0.223:/apps/test/a.txt root@192.168.0.223 : 使用root用户登录远程服务器192.168.0.223 test.txt:本机要传递过去的文件 /apps/test/a.txt：远程主机目录和文件名 将本地目录上传到服务器上 scp -r dir1 root@192.168.0.223:/apps/test/a 当 scp 指定端口时 scp -P 2222 -r dir1 root@192.168.0.223:/apps/test/a 可能有用的几个参数 -v 和大多数 linux 命令中的 -v 意思一样 , 用来显示进度 . 可以用来查看连接 , 认证 , 或是配置错误 .-C 使能压缩选项 .-4 强行使用 IPV4 地址 .-6 强行使用 IPV6 地址 . 参考：scp 命令 Wget Linux系统中的wget是一个下载文件的工具，它用在命令行下。对于Linux用户是必不可少的工具，我们经常要下载一些软件或从远程服务器恢复备份到本地服务器。wget支持HTTP，HTTPS和FTP协议，可以使用HTTP代理。所谓的自动下载是指，wget可以在用户退出系统的之后在后台执行。这意味这你可以登录系统，启动一个wget下载任务，然后退出系统，wget将在后台执行直到任务完成，相对于其它大部分浏览器在下载大量数据时需要用户一直的参与，这省去了极大的麻烦。 wget 可以跟踪HTML页面上的链接依次下载来创建远程服务器的本地版本，完全重建原始站点的目录结构。这又常被称作”递归下载”。在递归下载的时候，wget 遵循Robot Exclusion标准(/robots.txt). wget可以在下载的同时，将链接转换成指向本地文件，以方便离线浏览。 wget 非常稳定，它在带宽很窄的情况下和不稳定网络中有很强的适应性.如果是由于网络的原因下载失败，wget会不断的尝试，直到整个文件下载完毕。如果是服务器打断下载过程，它会再次联到服务器上从停止的地方继续下载。这对从那些限定了链接时间的服务器上下载大文件非常有用。 下载单个文件 wget http://www.minjieren.com/wordpress-3.1-zh_CN.zip 下载并以不同的文件名保存 wget -O tomcat.tar.gz http://mirrors.tuna.tsinghua.edu.cn/apache/tomcat/tomcat-8/v8.5.24/bin/apache-tomcat-8.5.24.tar.gz 后台下载 wget -b http://mirrors.hust.edu.cn/apache/maven/maven-3/3.5.2/binaries/apache-maven-3.5.2-bin.tar.gz 参考：每天一个linux命令（61）：wget命令 Ftp功能 ftp 命令使用文件传输协议（File Transfer Protocol, FTP）在本地主机和远程主机之间或者在两个远程主机之间进行文件传输。 FTP 协议允许数据在不同文件系统的主机之间传输。尽管这个协议在传输数据上提供了高适应性，但是它并没有尝试去保留一个特定文件系统上的文件属性（例如一个文件的保护模式或者修改次数）。而且 FTP 协议很少对一个文件系统的整体结构作假定，也不提供这样的功能，比如递归的拷贝子目录。在使用 ftp 命令时，需要注意 FTP 协议的这些特性。当需要保留文件属性或者需要递归的拷贝子目录时，可以使用 rcp/scp 等命令。 语法 ftp [-dignv][主机名称或IP地址] 参数： -d 详细显示指令执行过程，便于排错或分析程序执行的情形。-i 关闭互动模式，不询问任何问题。-g 关闭本地主机文件名称支持特殊字符的扩充特性。-n 不使用自动登陆。-v 显示指令执行过程。 Linux ftp命令 其他摘自：Linux 上的常用文件传输方式介绍与比较 综上所述各种文件传输方式的特征表现各有千秋，我们从以下几个方面综合对比，更深入地了解它们各自的特性。 传输性能wget 通过支持后台执行及断点续传提高文件传输效率 ； rsync 则以其高效的传输及压缩算法达到快传输的目的。 配置难度rcp 只需进行简单的配置，创建 .rhost 文件以及设置 /etc/hosts 文件中主机名与 IP 地址列表； wget 设置设置方便简单，只需在客户端指定参数执行命令即可； rsync 在使用前需要对服务端 /etc/rsyncd.conf 进行参数设定，配置内容相对复杂。 安全性能ftp、rcp 不保证传输的安全性，scp、rsync 则均可基于 ssh 认证进行传输，提供了较强的安全保障。 wget 也可通过指定安全协议做到安全传输。 通过上述的对比不难发现，每种文件传输方法基于其自身的特点与优势均有其典型的适用场景： ftp 作为最常用的入门式的文件传输方法，使用简单，易于理解，并且可以实现脚本自动化； rcp 相对于 ftp 可以保留文件属性并可递归的拷贝子目录； scp 利用 ssh 传输数据，并使用与 ssh 相同的认证模式，相对于 rcp 提供更强的安全保障； wget，实现递归下载，可跟踪 HTML 页面上的链接依次下载来创建远程服务器的本地版本，完全重建原始站点的目录结构，适合实现远程网站的镜像； curl 则适合用来进行自动的文件传输或操作序列，是一个很好的模拟用户在网页浏览器上的行为的工具； rsync 更适用于大数据量的每日同步，拷贝的速度很快，相对 wget 来说速度快且安全高效。","link":"/post/a6fc1711.html"},{"title":"实现 SSH 免密登录","text":"SSH (Secure Shell的) 是一种网络协议，用于计算机之间的加密登录。 通过使用SSH，你可以把所有传输的数据进行加密更加安全可靠。使用SSH，还有一个额外的好处就是传输的数据是经过压缩的，所以可以加快传输的速度。SSH 有很多功能，它既可以代替 Telnet，又可以为FTP、Pop、甚至为 PPP 提供一个安全的”通道”。 主机之间通过 SSH 进行连接的时候需要输入密码进行校验。在部署分布式应用时，主机间要建立良好的通信，首先要做的就是配置 SSH 免密登录。 以下演示在centos 7中配置免密登录。 配置主机间的免密登录配置免密登录什么是免密登录呢？ 通常我们登录 SSH 是通过账号和免密来登录的，输入ssh username@ip-server然后输入密码。 如果每次都输入密码会很麻烦，而且要对多台主机进行自动化管理，每次都要输入密码不现实。我们可以配置公钥和密钥进行免密登录。免密登录做的事情其实就是通过 SSH 的公钥和密钥来校验身份信息。 首先你要知道每台主机有一份公钥和一份私钥。我们要做的事情可以用一张图来表示： 1.生成密匙对 ssh-keygen 之后可以在/root/.ssh中看到生成的密匙对 123[root@main /]# cd /root/.ssh/[root@main .ssh]# lsid_rsa id_rsa.pub 2.拷贝一份 A 的公钥给 B ssh-copy-id 192.168.0.10输入密码 此时在 B 的authorized_keys中就会有一份 A 的id_rsa.pub公钥信息。 注：第二步操作的做的事情其实就是一个拷贝密钥的工作，也可以手动拷贝，但是用上面的命令更方便。 3.最后我们就可以免密登录,也就是不输入密码 A 就可以登录 B ssh root@192.168.0.10 192.168.0.10 为 B 的 ip 地址 如果要退出登录，输入exit即可。 给主机起一个别名192.168.0.10 是 ip 地址，也就是说登录的时候我们还要输入一次 ip。我们可以给每个主机配置一个别名，用ssh ip-server的方式登录。 就像人有身份证也有名字一样，我们可以通过 ip 来辨识主机。给他一个别名就是给一个hostname。 可以用hostname来查看你的主机名，要改主机名改他的配置文件 vi /etc/hostname在其中替换为你要改的名字，比如 main 重启生效 reboot 这样主机名已经改掉了，还差一步。我们要让主机名和我们的 ip 关联在一起，修改/etc/hosts文件 vi /etc/hosts添加上 ip 和 hostname 的键值对 例如： 1234127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain6192.168.0.11 main192.168.0.10 slave 两边都配置完成可以用ssh slave直接连接slave。如果你想自己免密连接自己那就按照上面的步骤给自己配置一份密匙就行了，动手试试吧。 SSH 协议是什么以及更多参考SSH 协议介绍 数字签名是什么 SSH原理与运用（一）：远程登录 SSH原理与运用（二）：远程操作与端口转发 如何在CentOS 7上修改主机名","link":"/post/ea055f0d.html"},{"title":"OpenCV-Mat表达式","text":"利用 C++中的运算符重载，OpenCV 2 中引入了 Mat 运算表达式。这一新特 点使得使用 C++进行编程时，就如同写 Matlab 脚本，代码变得简洁易懂，也便于维护。 下面给出 Mat 表达式所支持的运算。下面的列表中使用 A 和 B 表示 Mat 类 型的对象，使用 s 表示 Scalar 对象，alpha 表示 double 值。 加法，减法，取负：A+B，A-B，A+s，A-s，s+A，s-A，-A 缩放取值范围：A*alpha 矩阵对应元素的乘法和除法： A.mul(B)，A/B，alpha/A 矩阵乘法：A*B （注意此处是矩阵乘法，而不是矩阵对应元素相乘） 矩阵转置：A.t() 矩阵求逆和求伪逆：A.inv() 矩阵比较运算：A cmpop B，A cmpop alpha，alpha cmpop A。此处 cmpop 可以是&gt;，&gt;=，==，!=，&lt;=，&lt;。如果条件成立，则结果矩阵（8U 类型矩阵）的对应元素被置为 255；否则置 0。 矩阵位逻辑运算：A logicop B，A logicop s，s logicop A，~A，此处 logicop 可以是&amp;，|和^。 矩阵对应元素的最大值和最小值：min(A, B)，min(A, alpha)，max(A, B)， max(A, alpha)。 矩阵中元素的绝对值：abs(A) 叉积和点积：A.cross(B)，A.dot(B)","link":"/post/1208a55a.html"},{"title":"OpenCV-图像的遍历","text":"计算机使用 0/1 编码存储图像，数字图像在计算机中同样也使用 0/1 编码来存储。在计算机看来图像是一堆亮度不同的点组成的矩阵。一般灰度图用 2 维矩阵来表示，彩色图片是多通道的，则用 3 维矩阵来表示。 我们一般接触的图像都是 8 位整数（CV_8U），所以灰度图像包含 0～255 灰度，其中 0 代表最⿊，1表⽰最⽩。 彩色图像比如 RGB 图像，每个像素用三个字节来表示，而 OpenCV 中存储 RGB 图像以 BGR 的顺序存储图像，所以存储方式如上所示。 本文将介绍遍历灰度图像和彩色图像的方法，其本质即为遍历图像矩阵，可以对比二维数组的遍历来学习。 使用 at() 遍历图像1234567891011121314151617181920212223242526272829303132333435363738#include &lt;opencv2/core/core.hpp&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;int main(){ // 使用构造器创建 Mat，注意类型 cv::Mat grayImage(400, 500, CV_8UC1); cv::Mat colorImage(400, 500, CV_8UC3); for(int i = 0; i &lt; grayImage.rows; i++) { for(int j = 0; j &lt; grayImage.cols; j++) { // 灰度图像是单通道的 grayImage.at&lt;uchar&gt;(i, j) = (i + j) % 255; } } for(int i = 0; i &lt; colorImage.rows; i++) { for(int j = 0; j &lt; colorImage.cols; j++) { // 三通道用向量来表示 cv::Vec3b pixel; pixel[0] = i % 255; pixel[1] = j % 255; pixel[2] = 0; colorImage.at&lt;cv::Vec3b&gt;(i, j) = pixel; } } cv::imshow(\"1. GrayImage\", grayImage); cv::imshow(\"2. ColorImage\", colorImage); cv::waitKey(0); return 0;} at() 的优点在于可读性强，缺点在于效率不高。图像遍历操作时常用且开销很大的操作，所以不推荐使用 at() 做图像的遍历操作。 使用指针遍历1234567891011121314151617181920212223242526272829303132333435363738#include &lt;opencv2/core/core.hpp&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;int main(){ cv::Mat grayImage(400, 500, CV_8UC1); cv::Mat colorImage(400, 500, CV_8UC3); for(int i = 0; i &lt; grayImage.rows; i++) { uchar *p = grayImage.ptr&lt;uchar&gt;(i); for(int j =0; j &lt; grayImage.cols; j++) { p[j] = (i + j) % 255; } } for(int i = 0; i &lt; colorImage.rows; i++) { cv::Vec3b *p = colorImage.ptr&lt;cv::Vec3b&gt;(i); for(int j =0; j &lt; colorImage.cols; j++) { p[j][0] = i % 255; p[j][1] = j % 255; p[j][2] = 0; } } cv::imshow(\"1. GrayImage\", grayImage); cv::imshow(\"2. ColorImage\", colorImage); cv::waitKey(0); return 0;} 程序是用 image.ptr() 返回矩阵每一行的头指针，紧接着遍历这一行的元素。 指针的优点在于访问速度快，缺点在于指针较为复杂，不熟悉指针的朋友容易犯错且不易查找错误。 迭代器遍历1234567891011121314151617181920212223242526272829303132#include &lt;opencv2/core/core.hpp&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;int main(){ cv::Mat grayImage(400, 500, CV_8UC1); cv::Mat colorImage(400, 500, CV_8UC3); cv::MatIterator_&lt;uchar&gt; grayit, grayend; for (grayit = grayImage.begin&lt;uchar&gt;(), grayend = grayImage.end&lt;uchar&gt;(); grayit != grayend; grayit++) { *grayit = rand() % 255; } cv::MatIterator_&lt;cv::Vec3b&gt; colorit, colorend; for (colorit = colorImage.begin&lt;cv::Vec3b&gt;(), colorend = colorImage.end&lt;cv::Vec3b&gt;(); colorit != colorend; colorit++) { (*colorit)[0] = rand() % 255; (*colorit)[1] = rand() % 255; (*colorit)[2] = rand() % 255; } cv::imshow(\"1. GrayImage\", grayImage); cv::imshow(\"2. ColorImage\", colorImage); cv::waitKey(0); return 0;} 在 C++ 的 STL 库，或者 Java, Python 等语言中都提供了对迭代器的支持，OpenCV 也支持使用迭代器的方式进行遍历，代码如上所示。 本文介绍了遍历 Mat 的三种方式: 使用 at() 遍历，使用指针遍历，以及使用迭代器遍历。推荐使用指针的方式遍历图像，其效率最高，在编写图像处理的算法时，效率是我们不可忽视的要素。","link":"/post/dfe68fea.html"},{"title":"OpenCV-基本数据结构","text":"本文介绍 OpenCV 的基本数据结构，做到心中有数就不会在阅读示例代码的时候发憷。 Mat 类Mat 是 OpenCV 中最重要的一种数据结构，OpenCV 将其定义为一个类，用于存储图像矩阵。 属性 释义 dims 矩阵的维度，如 3x4x5 的矩阵为 3 维 data uchar 类型指针, 指向矩阵数据内存 rows, cols 矩阵的行数、列数 type 矩阵元素类型 + 通道数 depth 像素位数(bist) channels 通道数量 elemSize 矩阵中每一个元素的数据大小 elemSize1 单通道的矩阵元素占用的数据大小 type 表示矩阵元素类型和通道数。矩阵元素类型一般都是 8 位无符号整数，即 CV_8U，彩色图像一般为 3 通道，灰度图像则为单通道。所以灰度图像的 type 可以表示为 CV_8UC1，3 通道的 RGB 图像的 type 可以表示为 CV_8UC3。 以 CV_8UC3 为例，depth = CV_8U，channels = 3。 elemSize = channels depth / 8 ，type是CV_8UC3，elemSize = 3 8 / 8 = 3bytes。 elemSize1 = depth / 8，type是CV_8UC3，elemSize1 = 8 / 8 = 1bytes。 通过遍历图像可以体会 Mat 类的使用，可以参考 OpenCV-图像的遍历。 Ponit 类 - 点的表示Point 类表示二维坐标系下的点，即 (x, y) 形式的 2D 点。 1234567// 方法一Point point1 = Point(10, 8);// 方法二Point point2;point2.x = 8;point2.y = 10; 其中 Point_&lt;int&gt;, Point2i, Point 等价，Point_&lt;float&gt;, Point2f 等价。 Scalar 类 - 颜色的表示Scalar() 表示具有 4 个元素的数组，用于传递像素值，如 RGB 颜色值。RGB 颜色值只有三个参数，Scalar() 用不到第四个参数可以缺省。 1Mat M(3, 2, CV_8UC3, Scalar(0,0,255)); 其中 Scalar(0,0,255) 表示 BGR 的值分别为 (0, 0, 255) 是红色。 Size 类 - 尺寸的表示12345typedef Size_&lt;int&gt; Size2i;typedef Size_&lt;int64&gt; Size2l;typedef Size_&lt;float&gt; Size2f;typedef Size_&lt;double&gt; Size2d;typedef Size2i Size; 源代码中的定义上述代码所示。Size_ 是模板类，Size_&lt;int&gt; 表示其模板类型为 int。之后给 Size_&lt;int&gt; 别名为 Size2i，再给 Size2i 别名为 Size。由此可见，Size_&lt;int&gt;, Size2i, Size 等价。 Size size = Size(8, 10); 表示宽和长分别为 8 和 10。 Rect 类 - 矩形的表示 Rect 类的成员变量有 x, y, width, heigh Size() 返回值为 Size area() 返回矩形面积 contains(Point) 判断点是否在矩形内 inside(Rect) 判断矩形是否在该矩形内 tl() 返回左上角点坐标 br() 返回右下角点坐标 12345678// 矩形交集Rect rect = rect1 &amp; rect2;// 矩形并集Rect rect = rect1 | rect2;// 平移操作Rect rectShift = rect + point;// 缩放操作Rect rectScale = rect + size;","link":"/post/463fc5c6.html"},{"title":"Ubuntu16.04配置OpenCV环境","text":"本文介绍在 Ubuntu16.04 中配置 OpenCV 的环境 Linux 环境: Ubuntu16.04 LST 软件版本: opencv-3.4.0 、opencv_contrib-3.4.0 (安装包在文末下载) 参考文档：Installation in Linux 依赖安装执行以下命令 12345[compiler] sudo apt-get install build-essential[required] sudo apt-get install cmake git libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-dev cmake-gui[optional] sudo apt-get install python-dev python-numpy libtbb2 libtbb-dev libjpeg-dev libpng-dev libtiff-dev libjasper-dev libdc1394-22-dev 下载以下两个文件，注意版本 opencv-3.4.0 、opencv_contrib-3.4.0 解压文件，并新建一个build文件夹作为编译目录，如下 1234opencv/├── build├── opencv-3.4.0└── opencv_contrib-3.4.0 使用CMake-gui进行编译使用cmake-gui生成Makefile,并进行编译 生成 Makefile 点击 Browse_Source… 引入 opencv-3.4.0 文件夹 点击 Browse_Build… 引入 build 文件夹 不想编译 protobuf 可以选择 -D BUILD_PROTOBUF=OFF PROTOBUF_UPDATE_FILES=ON dnn 也会依赖 protobuf 也可以选择不编译 cuda 相关的用不到也不可以不编译 点击 Configure 点击 Generate 弹出如下对话框，选择使用Makefile生成的系统平台 123注：1. 第一次会弹出`CMakeSetup`选择`default`那个就可以了2. 开始的时候没有上图红色部分 之后我们勾选下面这几个选项 编译成静态库，取消选择 BUILD_SHARED_LIBS 勾选 OPENCV_ENABLE_NOFREE 选择 OPENCV_EXTRA_MODULES_PATH 引入 opencv_contrib-3.4.0 下的 modules 文件夹 点击 Configure 点击 Generate 编译进入 build 文件夹路径 make -j7 # 7 表示7个并发 修改 opencv.pv 文件 cd /build/unix_install vim opencv.pc 12345678910111213# Package Information for pkg-configprefix=/usr/localexec_prefix=${prefix}libdir=${exec_prefix}/libincludedir_old=${prefix}/include/opencvincludedir_new=${prefix}/includeName: OpenCVDescription: Open Source Computer Vision LibraryVersion: 3.4.0Libs: -L${exec_prefix}/lib -lopencv_stitching -lopencv_superres -lopencv_videostab -lopencv_aruco -lopencv_bgsegm -lopencv_bioinspired -lopencv_ccalib -lopencv_dpm -lopencv_face -lopencv_photo -lopencv_freetype -lopencv_fuzzy -lopencv_img_hash -lopencv_line_descriptor -lopencv_optflow -lopencv_reg -lopencv_rgbd -lopencv_saliency -lopencv_stereo -lopencv_structured_light -lopencv_phase_unwrapping -lopencv_surface_matching -lopencv_tracking -lopencv_datasets -lopencv_text -lopencv_dnn -lopencv_plot -lopencv_xfeatures2d -lopencv_shape -lopencv_video -lopencv_ml -lopencv_ximgproc -lopencv_calib3d -lopencv_features2d -lopencv_highgui -lopencv_videoio -lopencv_flann -lopencv_xobjdetect -lopencv_imgcodecs -lopencv_objdetect -lopencv_xphoto -lopencv_imgproc -lopencv_coreLibs.private: -ldl -lm -lpthread -lrtCflags: -I${includedir_old} -I${includedir_new} 将文件中的Libs.private:删除 sudo make install sudo updatedb sudo ldconfig 运行写一段测试程序，可以使用命令行的方式或者 CMake 进行编译 测试程序12345678910111213141516171819202122232425262728293031323334353637#include \"opencv2/highgui/highgui.hpp\"#include \"opencv2/imgproc/imgproc.hpp\"#include \"opencv2/core/core.hpp\"#include \"opencv2/video/video.hpp\"#include &lt;iostream&gt;using namespace cv;int main(int argc, char **argv){ // 从命令行参数读取图片路径 char *imageName = argv[1]; Mat image; image = imread(imageName, IMREAD_COLOR); if (argc != 2 || !image.data) { std::cout &lt;&lt; \"No image data\" &lt;&lt; std::endl; return -1; } Mat gray_image; cvtColor(image, gray_image, COLOR_BGR2GRAY); // 保存转换之后的灰度图片 imwrite(\"Gray_Image.jpg\", gray_image); namedWindow(imageName, WINDOW_AUTOSIZE); namedWindow(\"Gray image\", WINDOW_AUTOSIZE); imshow(imageName, image); imshow(\"Gray image\", gray_image); waitKey(0); return 0;} 命令行方式编译 g++ ModifyImage.cpp pkg-config --cflags --libs opencv -o ModifyImage CMake 方式编译新建一个CMakeLists.txt 123456cmake_minimum_required(VERSION 2.8)project( ModifyImage )find_package( OpenCV REQUIRED )include_directories( ${OpenCV_INCLUDE_DIRS} )add_executable( ModifyImage ModifyImage.cpp )target_link_libraries( ModifyImage ${OpenCV_LIBS} ) 输入以下命令 cmake . make 通过以上两种方式都会生成一个可执行文件，我们可以执行它 ./ModifyImage","link":"/post/5359e313.html"},{"title":"OpenCV-选取图像的感兴趣区域","text":"Mat 类提供了多种方便的方法来选择图像的局部区域。使用这些方法时需要注意,这些方法并不进行内存的复制操作。如果将局部区域赋值给新的 Mat 对象,新对象与原始对象共用相同的数据区域,不新申请内存,因此这些方法的执行速度都比较快。 单行或者单列选择提取矩阵的一行或者一列可以使用函数 row()或 col()。函数的声明如下: 12Mat Mat::row(int i) constMat Mat::col(int j) const 参数 i 和 j 分别是行标和列标。例如取出 A 矩阵的第 i 行可以使用如下代码: 1Mat line = A.row(i); 例如取出 A 矩阵的第 i 行,将这一行的所有元素都乘以 2,然后赋值给第 j 行,可以这样写: 1A.row(j) = A.row(i)*2; 用 Range 选择多行或多列Range 是 OpenCV 中新增的类,该类有两个关键变量 star 和 end。Range 对象可以用来表示矩阵的多个连续的行或者多个连续的列。其表示的范围为从 start到 end,包含 start,但不包含 end。Range 类的定义如下: 123456class Range{ public: ... int start, end;}; Range 类还提供了一个静态方法 all(),这个方法的作用如同 Matlab 中的“:”,表示所有的行或者所有的列。 1234567//创建一个单位阵Mat A = Mat::eye(10, 10, CV_32S);//提取第 1 到 3 列(不包括 3)Mat B = A(Range::all(), Range(1, 3));//提取 B 的第 5 至 9 行(不包括 9)//其实等价于 C = A(Range(5, 9), Range(1, 3))Mat C = B(Range(5, 9), Range::all()); 感兴趣区域从图像中提取感兴趣区域(Region of interest)有两种方法,一种是使用构造函数,如下例所示: 1234//创建宽度为 320,高度为 240 的 3 通道图像Mat img(Size(320,240),CV_8UC3);//roi 是表示 img 中 Rect(10,10,100,100)区域的对象Mat roi(img, Rect(10,10,100,100)); 除了使用构造函数,还可以使用括号运算符,如下: 1Mat roi2 = img(Rect(10,10,100,100)); 当然也可以使用 Range 对象来定义感兴趣区域,如下: 1234//使用括号运算符Mat roi3 = img(Range(10,100),Range(10,100));//使用构造函数Mat roi4(img, Range(10,100),Range(10,100)); 取对角线元素矩阵的对角线元素可以使用 Mat 类的 diag()函数获取,该函数的定义如下: 1Mat Mat::diag(int d) const 参数 d=0 时,表示取主对角线;当参数 d&gt;0 是,表示取主对角线下方的次对角线,如 d=1 时,表示取主对角线下方,且紧贴主多角线的元素;当参数 d&lt;0 时,表示取主对角线上方的次对角线。 如同 row()和 col()函数, diag()函数也不进行内存复制操作,其复杂度也是 O(1)。","link":"/post/d4c8e253.html"},{"title":"Numpy 小结","text":"NumPy 是 Python 语言的一个扩充程序库。支持高级大量的维度数组与矩阵运算，此外也针对数组运算提供大量的数学函数库，也是学习 python 必学的一个库。 1. 读取文件numpy.genfromtxt() 用于读取 txt 文件，其中传入的参数依次为： 需要读取的 txt 文件位置，此处文件与程序位于同一目录下 分割的标记 转换类型，如果文件中既有文本类型也有数字类型，就先转成文本类型 help(numpy.genfromtxt)用于查看帮助文档：如果不想看 API 可以启动一个程序用 help 查看指令的详细用法 123456import numpyworld_alcohol = numpy.genfromtxt(\"world_alcohol.txt\", delimiter=\",\",dtype=str)print(type(world_alcohol))print(world_alcohol)print(help(numpy.genfromtxt)) 2. 构造 ndarraynumpy.array()构造 ndarraynumpy.array()中传入数组参数，可以是一维的也可以是二维三维的。numpy 会将其转变成 ndarray 的结构。 12vector = numpy.array([1,2,3,4])matrix = numpy.array([[1,2,3],[4,5,6]]) 传入的参数必须是同一结构,不是同一结构将发生转换。 123vector = numpy.array([1,2,3,4])array([1, 2, 3, 4]) 均为 int 类型 123vector = numpy.array([1,2,3,4.0])array([ 1., 2., 3., 4.]) 转为浮点数类型 123vector = numpy.array([1,2,'3',4])array(['1', '2', '3', '4'],dtype='&lt;U21') 转为字符类型 利用 .shape 查看结构能够了解 array 的结构，debug 时通过查看结构能够更好地了解程序运行的过程。 1234print(vector.shape)print(matrix.shape)(4,)(2, 3) 利用 dtype 查看类型1234vector = numpy.array([1,2,3,4])vector.dtypedtype('int64') ndim 查看维度一维 1234vector = numpy.array([1,2,3,4])vector.ndim1 二维 123456matrix = numpy.array([[1,2,3], [4,5,6], [7,8,9]])matrix.ndim2 size 查看元素数量12matrix.size9 3. 获取与计算numpy 能使用切片获取数据123matrix = numpy.array([[1,2,3], [4,5,6], [7,8,9]]) 根据条件获取numpy 能够依次比较 vector 和元素之间是否相同 1234vector = numpy.array([5, 10, 15, 20])vector == 10array([False, True, False, False], dtype=bool) 根据返回值获取元素 1234567vector = numpy.array([5, 10, 15, 20])equal_to_ten = (vector == 10)print(equal_to_ten)print(vector[equal_to_ten])[False True False False][10] 进行运算之后获取 12vector = numpy.array([5, 10, 15, 20])equal_to_ten_and_five = (vector == 10) &amp; (vector == 5) 12vector = numpy.array([5, 10, 15, 20])equal_to_ten_or_five = (vector == 10) | (vector == 5) 类型转换将整体类型进行转换 1234567vector = numpy.array([5, 10, 15, 20])print(vector.dtype)vector = vector.astype(str)print(vector.dtype)int64&lt;U21 求和sum() 能够对 ndarray 进行各种求和操作，比如分别按行按列进行求和 12345678910matrix = numpy.array([[1,2,3], [4,5,6], [7,8,9]])print(matrix.sum())print(matrix.sum(1))print(matrix.sum(0))45[ 6 15 24][12 15 18] sum(1) 是 sum(axis=1)) 的缩写，1表示按照 x轴方向求和，0表示按照y轴方向求和 4. 常用函数reshape生成从 0-14 的 15 个数字，使用 reshape(3,5) 将其构造成一个三行五列的 array。 1234567import numpy as nparr = np.arange(15).reshape(3, 5)arrarray([[ 0, 1, 2, 3, 4], [ 5, 6, 7, 8, 9], [10, 11, 12, 13, 14]]) zeros生成指定结构的默认为 0. 的 array 12345np.zeros ((3,4))array([[ 0., 0., 0., 0.], [ 0., 0., 0., 0.], [ 0., 0., 0., 0.]]) ones生成一个三维的 array,通过 dtype 指定类型 123456789np.ones( (2,3,4), dtype=np.int32 )array([[[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]], [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]]) range指定范围和数值间的间隔生成 array，注意范围包左不包右 123np.arange(0,10,2)array([0, 2, 4, 6, 8]) random 随机数生成指定结构的随机数，可以用于生成随机权重 1234np.random.random((2,3))array([[ 0.86166627, 0.37756207, 0.94265883], [ 0.9768257 , 0.96915312, 0.33495431]]) 5. ndarray 运算元素之间依次相减相减 12345a = np.array([10,20,30,40])b = np.array(4)a - barray([ 6, 16, 26, 36]) 乘方12a**2array([ 100, 400, 900, 1600]) 开根号 1234np.sqrt(B)array([[ 1.41421356, 0. ], [ 1.73205081, 2. ]]) e 求方 1234np.exp(B)array([[ 7.3890561 , 1. ], [ 20.08553692, 54.59815003]]) 向下取整 12345a = np.floor(10*np.random.random((2,2)))aarray([[ 0., 0.], [ 3., 6.]]) 行列变换 1234a.Tarray([[ 0., 3.], [ 0., 6.]]) 变换结构 1234a.resize(1,4)aarray([[ 0., 0., 3., 6.]]) 6. 矩阵运算矩阵之间的运算 1234A = np.array( [[1,1], [0,1]] )B = np.array( [[2,0], [3,4]] ) 对应位置一次相乘 1234A*Barray([[2, 0], [0, 4]]) 矩阵乘法 12345print (A.dot(B))print(np.dot(A,B))[[5 4] [3 4]] 横向相加 12345678910111213a = np.floor(10*np.random.random((2,2)))b = np.floor(10*np.random.random((2,2)))print(a)print(b)print(np.hstack((a,b)))[[ 2. 3.] [ 9. 3.]][[ 8. 1.] [ 0. 0.]][[ 2. 3. 8. 1.] [ 9. 3. 0. 0.]] 纵向相加 123456print(np.vstack((a,b)))[[ 2. 3.] [ 9. 3.] [ 8. 1.] [ 0. 0.]] 矩阵分割 1234#横向分割print( np.hsplit(a,3))#纵向风格print(np.vsplit(a,3)) 7. 复制的区别地址复制通过 b = a 复制 a 的值，b 与 a 指向同一地址，改变 b 同时也改变 a。 123456789101112131415a = np.arange(12)b = aprint(a is b)print(a.shape)print(b.shape)b.shape = (3,4)print(a.shape)print(b.shape)True(12,)(12,)(3, 4)(3, 4) 复制值通过 a.view() 仅复制值，当对 c 值进行改变会改变 a 的对应的值，而改变 c 的 shape 不改变 a 的 shape 1234567891011121314a = np.arange(12)c = a.view()print(c is a)c.shape = 2,6c[0,0] = 9999print(a)print(c)False[9999 1 2 3 4 5 6 7 8 9 10 11][[9999 1 2 3 4 5] [ 6 7 8 9 10 11]] 完整拷贝a.copy() 进行的完整的拷贝，产生一份完全相同的独立的复制 1234567891011121314a = np.arange(12)c = a.copy()print(c is a)c.shape = 2,6c[0,0] = 9999print(a)print(c)False[ 0 1 2 3 4 5 6 7 8 9 10 11][[9999 1 2 3 4 5] [ 6 7 8 9 10 11]]","link":"/post/a404f4e2.html"},{"title":"zookeeper 的安装和配置","text":"ZooKeeper 是一个分布式协调服务。其本身就是一个高可用的分布式程序，只需半数以上节点存活即可继续使用，所以使用中往往配置奇数台主机。他主要能提供主从协调、服务器节点动态上下线、统一配置管理、分布式共享锁、统一名称服务等。 本文演示在 CentOS 7 虚拟机部署和配置 zookeeper。 下载首先需要下载安装包。前去下载地址下载安装包，本文使用的 zookeeper 版本是zookeeper-3.4.10。 下载完成之后将安装包传到服务器，我将其传到 apps 目录下： scp zookeeper-3.4.10.tar.gz root@192.168.2.222:/apps/ 解压安装包 sudo tar -zxvf zookeeper-3.4.10.tar.gz -C /apps/ 重命名解压文件 sudo mv zookeeper-3.4.10 zookeeper 配置环境变量修改配置文件 vi /etc/profile添加如下内容：# zookeeperexport ZOOKEEPER_HOME=/apps/zookeeperexport PATH=\\$PATH:$ZOOKEEPER_HOME/bin 注：ZOOKEEPER_HOME 为你自己的文件位置。 手动加载配置文件： source /etc/profile 修改 zookeeper 配置文件配置文件放置在 zookeeper/conf 目录下，查看目录文件有三个，其中zoo_sample.cfg是范例配置文件： 12$lsconfiguration.xsl log4j.properties zoo_sample.cfg 复制zoo_sample.cfg并重命名zoo.cfg,zoo.cfg就是需要的配置文件： cp zoo_sample.cfg zoo.cfgvi zoo.cfg 配置文件中添加或修改如下内容： 12345678# 数据目录dataDir=/home/hadoop/zookeeper/data# 日志目录dataLogDir=/home/hadoop/zookeeper/log# 包括自己在内的所有主机名称server.1=slave1:2888:3888 (主机名, 心跳端口、数据端口)server.2=slave2:2888:3888server.3=slave3:2888:3888 注意：slave1、slave2、slave3 是主机名即 hostname。所以需要配置主机名和 ip 的映射。 新建对应的文件夹: mkdir -m 755 zookeeper/datamkdir -m 755 zookeeper/log 配置 myid： echo 1 &gt; zookeeper/data/myid 给三台主机的名称分别配置为1,2,3。 最后：在另外两台主机上使用任意方法重复如上配置并修改主机名配置完成 启动 zookeeper进入启动目录 cd /apps/zookeeper/bin 启动 zkServer.sh start 查看状态 zkServer.sh status 12345Using config: /apps/zookeeper/bin/../conf/zoo.cfgMode: leader----Using config: /apps/zookeeper/bin/../conf/zoo.cfgMode: follower 以上，zookeeper 的基本安装配置完毕。","link":"/post/530b5399.html"},{"title":"3分钟找书指南","text":"3分钟找书指南v1.0 Jiumo Search 鸠摩搜书 - 文档搜索引擎 http://mebook.cc/ 万千合集站 ePUBee电子书库，最大的电子书库，在线电子书管理 书伴-Kindle Lore Free-去中心化知识共享社区 http://www.iamtxt.com/ SoBooks - kindle 超星发现 OpenStax|免费大学教科书数据库) 中国国家图书馆 周读 熊猫搜书 亿年书海 - 电子书 wiki 网 中國哲學書電子化計劃 书格 古籍館-中國最大的古籍圖書館","link":"/post/c5829ae7.html"},{"title":"更多搜索引擎","text":"善用搜索引擎，程序员提升的一大步。 谷歌 全球最大搜索引擎公司。 必应 微软旗下，比较出名了，国内可访问。 Bird.so 技术问题的聚合，国内也可访问，是我谷歌替代方案。 DuckDuckGo 注重隐私安全，不记录用户数据是卖点，注重隐私的人的上好选择。 Wikipedia 维基百科就像是一本参考书，有很高的权威性。 SemanticScholar Semantic Scholar 是由微软联合创始人 Paul Allen 做的免费学术搜索引擎，其检索结果来自于期刊、学术会议资料或者是学术机构的文献。 MEZW MEZW 搜索服务可以汇集国内外网页的搜索结果，登录帐号，更可自定义的屏蔽掉不希望展示在搜索结果中的网站。","link":"/post/9a276542.html"},{"title":"Markdown 记要","text":"Markdown 是一种轻量级的’「标记语言」，支持插入图片、图表、超链接、数学公式，用简单的语法能够形成一篇形式丰富的文章。 Markdown 编辑器有很多，我使用的是 typora。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# 一级标题## 二级标题### 三级标题个人不建议使用三级以上的标题生成目录：[TOC]锚点：(能够链接到某个一级标题)[想要显示的名称](#锚点的名称)**粗体***斜体*`行内代码`&gt; 在一段话后面加上 ——某名人，这就是一句名言&lt;u&gt;下划线&lt;/u&gt;~~删除线~~[超链接名称](超链接路径)![图片名称](图片链接)有序列表1. 选项一2. 选项二3. 选项三无序列表- 列表一- 列表二- 列表三复选框* [ ] 第一件事* [x] 第二件事* [ ] 第三件事表格name | age---- | ---LearnShare | 12Mike | 32邮箱：&lt;123456@qq.com&gt;分隔线***","link":"/post/c002250d.html"},{"title":"chrome食用指南","text":"Google Chrome 浏览器（后面简称 Chrome）是全球市场占有率最高的浏览器，全球范围内有超过 10 亿人在使用 Chrome。 1、登录 Google 账号。登录 Google 账号之后可以同步书签，历史记录等。同步书签是非常便利的一个功能，这样即使换了一台电脑也能快速找到自己收藏的实用网站。 2、自定义搜索引擎。在设置(S)中可以选择默认的搜索引擎，建议换成 Google。在地址栏中输入想要搜索的内容，可以直接用 Google 搜索。 3、设置为默认浏览器。必须设置为默认浏览器呀！ Chrome 中各类好用的插件让它如虎添翼，介绍几个我最常用的插件。 印象笔记「裁藏」「裁藏」需要配合印象笔记来使用。它的作用是将网页中你感兴趣的部分保存到印象笔记中。 广告屏蔽插件 AdGuard屏蔽广告弹窗，侧边栏的小广告，保持浏览网页时的专注度。 脚本管理插 TampermonkeyTampermonkey 可以管理各类脚本，而脚本可以辅助我们做更多事情。比如，百度云盘高速下载、豆瓣搜索电影的时候显示资源链接等。 可以搜索油猴脚本了解更多内容。 Explain and Send Screenshots可以滚动将整个网页的内容生成一张长图。 防追踪插件 GHOSTERY打开网页之后会有许多后台程序开始追踪你的个人信息，ghostery会告诉你哪些人在追踪你的信息，并帮助你屏蔽他们。","link":"/post/1e186084.html"},{"title":"矢量素材&图片素材","text":"免费矢量素材 高清无版权限制大图特供网站 免费矢量素材http://www.vecteezy.com/ http://www.vectorportal.com/ http://vector4free.com/ http://www.freepik.com/ http://vectorart.org/ http://sxc.hu/ http://www.stockvault.net/ http://www.squidfingers.com/patterns/ http://lostandtaken.com/ http://www.cgtextures.com/ http://www.textureking.com/ http://subtlepatterns.com/ 12个高清无版权限制大图特供网站http://pixabay.com/ https://unsplash.com/ http://www.gratisography.com/ http://picjumbo.com/page/5/ http://www.lifeofpix.com/ http://www.imcreator.com/free http://www.freeimages.com/home http://deathtothestockphoto.com http://publicdomainarchive.com/ http://snapographic.com/ 20个下载免费矢量素材的最佳网站http://www.vectorportal.com/ http://www.vectorss.com/ http://www.vectorstock.com/ http://www.vecteezy.com/ http://qvectors.net/ http://www.freevectors.com/ http://www.uberpiglet.com/ http://dezignus.com/category/vector/ http://www.123freevectors.com/ http://coolvectors.com/ http://vector.t","link":"/post/4b821db7.html"},{"title":"【TensorFlow2.0】手撕前向传播算法","text":"本文介绍如何使用 TensorFlow2.0 实现前向传播,先介绍用 TensorFlow 普通的 API 来实现前向传播,将会介绍:如何加载数据集,如何完成参数初始化和构建前向传播网络,如何计算 accuracy. 由于神经网络的训练流程大同小异,就可以使用 tf.keras 封装的 API 来简化模型训练和测试的流程.本文第二部分将会介绍如何使用 tf.keras 来定义神经网络以及优化器,如何用tf.keras.metrics来计算 accuracy 和 loss. 安装 TensorFlow2.0本文的开发环境是 Ubuntu16.04 + CUDA10 + Anaconda + TensorFlow2.0，目前 conda 不支持安装 TensorFlow2.0 的包，所以需要用 pip 来安装 TensorFlow2.0。 1pip install tensorflow-gpu==2.0.0-rc0 numpy matplotlib pandas -i https://pypi.tuna.tsinghua.edu.cn/simple 截止到现在，TensorFlow 发布了最新的 rc 版本，与以后的正式发行版差别不大了。 完成一次前向传播 如何加载数据集 第1步: 使用 keras.datasets 加载 mnist 数据集,将会返回两组数据 第2步: 将 Numpy 类型的数据转换为 tensor 第3步: 将 tensor 转换为 datasets 123456789101112131415161718192021222324252627282930313233343536373839# 需要引入的包import tensorflow as tffrom tensorflow import kerasfrom tensorflow.keras import datasetsimport os# 设置 TensorFlow 的日志级别,避免输出过多提示信息os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'# 第1步: 使用 keras.datasets 加载 mnist 数据集,将会返回两组数据# x: [60000,28,28], x_test:[10000,28,28]# y: [60000], y_test:[10000](x, y), (x_text, y_text) = datasets.mnist.load_data()# 第2步: 将 Numpy 类型的数据转换为 tensor# keras.datasets 加载到的是 Numpy 类型的数据,将其转换为 tensor# convert to tensor# x:[0~255] =&gt; [0~1]x = tf.convert_to_tensor(x, dtype=tf.float32) / 255.y = tf.convert_to_tensor(y, dtype=tf.int32)x_text = tf.convert_to_tensor(x_text, dtype=tf.float32) / 255.y_text = tf.convert_to_tensor(y_text, dtype=tf.int32)# 查看数据分布情况,shape,dype,min,maxprint(x.shape, y.shape, x.dtype, y.dtype)print(tf.reduce_min(x), tf.reduce_max(y))print(tf.reduce_min(y), tf.reduce_max(y))# 第3步: 将 tensor 转换为 datasets# tensorflow 推荐使用 tf.data.Dataset 来加载数据集# tensor =&gt; datasets# 128个为一个batch返回datasetstrain_db = tf.data.Dataset.from_tensor_slices((x,y)).batch(128)test_db = tf.data.Dataset.from_tensor_slices((x_text,y_text)).batch(128)train_iter = iter(train_db)sample = next(train_iter)print(\"batch:\", sample[0].shape, sample[1].shape) 前向传播参数初始化前面创建的 train_db 是 shape = [128, 28, 28],表示 128 张 28x28 的灰度图像.在输入的时候我将其展开成 shape = [128, 28*28],接着用全连接层降维到 shape = 10 的 tensor,对应 mnist 共 10 类的标签. 12345678# [b, 784] =&gt; [b, 256] =&gt; [b, 128] =&gt; [b, 10]# w:[dim_in, dim_out]; b:[dim_out]w1 = tf.Variable(tf.random.truncated_normal([784, 256], stddev=0.1))b1 = tf.Variable(tf.zeros([256]))w2 = tf.Variable(tf.random.truncated_normal([256, 128], stddev=0.1))b2 = tf.Variable(tf.zeros([128]))w3 = tf.Variable(tf.random.truncated_normal([128, 10], stddev=0.1))b3 = tf.Variable(tf.zeros([10])) 前向传播 &amp; 自动求导1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# 学习率lr = 1e-3# train_db 将会被计算 10 次for epoch in range(10): # iterate db for 10 # 遍历 train_db for step, (x, y) in enumerate(train_db, 1): # x:[128,28,28] # y:[128] # 将28x28的张量展开成784 # x:[128,28,28] =&gt; [128,784] x = tf.reshape(x, [-1,28*28]) # 使用 tf.GradientTape() 自动求导 with tf.GradientTape() as tape: # 构建前向传播的网络 # x:[b,28*28] # h1 = x@w1+b1 # [b,784]@[784,256]+[256] =&gt; [b,256] + [256] =&gt; [] h1 = tf.nn.relu(x@w1 + b1) h2 = tf.nn.relu(h1@w2 + b2) out = h2@w3 + b3 # y 使用 one_hot 编码,与神经网络的输出对应 # y: [b] =&gt; [b, 10] y_onehot = tf.one_hot(y, depth=10) # 计算均方误差 mse = mean(sum(y-out)^2) # loss:[b,10] loss = tf.square(y_onehot-out) # 求误差的请平均值 # loss:[b,10] =&gt; scalar loss = tf.reduce_mean(loss) # 借助于 tensorflow 自动求导 grads = tape.gradient(loss, [w1, b1, w2, b2, w3, b3]) # 根据梯度更新参数 # w1 = w1 - lr * w1_grad w1.assign_sub(lr * grads[0]) b1.assign_sub(lr * grads[1]) w2.assign_sub(lr * grads[2]) b2.assign_sub(lr * grads[3]) w3.assign_sub(lr * grads[4]) b3.assign_sub(lr * grads[5]) # 每迭代100次输出一次loss if step % 100 == 0: print(epoch+1, (epoch+1)*step, 'loss:', float(loss)) 计算准确率 accuracy我们需要通过模型的准确率来评估模型,模型评估需要在 test_db 上进行. 12345678910111213141516171819202122232425262728293031323334total_number = 0 total_correct = 0 # 遍历 test_db for step, (x, y) in enumerate(test_db): # [b, 28, 28] =&gt; [b, 28*28] x = tf.reshape(x,[-1,28*28]) # 利用最新的参数完成一次前向传播 # [b, 784] =&gt; [b, 256] =&gt; [b, 128] =&gt; [b, 10] h1 = tf.nn.relu(x@w1 + b1) h2 = tf.nn.relu(h1@w2 + b2) out = h2@w3 + b3 # 使用 softmax() 输出每个分类的概率值 # [b, 10] ~ R # [b, 10] ~ [0,1] prob = tf.nn.softmax(out, axis=1) # 概率最大的值就是模型的预测值 # [b, 10] =&gt; [b] preb = tf.argmax(prob, axis=1) preb = tf.cast(preb, dtype=tf.int32) # 预测值与真实值比较 # [b] int32 # print(y.dtype, preb.dtype) correct = tf.cast(tf.equal(y, preb), dtype=tf.int32) correct = tf.reduce_sum(correct) total_correct += int(correct) total_number += x.shape[0] acc = total_correct / total_number print(\"accuracy:\", acc) 前向传播过程优化 构建数据集时添加数据预处理Tensorflow 鼓励使用 tf.data.Dataset加载数据集,它给我封装了许多处理数据集的方法,比如train_db = train_db.map(preprocess).shuffle(60000).batch(128) 在preprocess(x,y)中进行数据预处理,利用map(preprocess)调用预处理函数,再用shuffle()随机成对打乱数据集,最后用batch()将数据集按照 128 一份来分隔. 12345678910111213141516def preprocess(x, y): # 数据预处理,归一化,类型转换 x = tf.cast(x, dtype=tf.float32) / 255. y = tf.cast(y, dtype=tf.int32) return x,y# x: [60000,28,28], x_test:[10000,28,28]# y: [60000], y_test:[10000](x, y), (x_text, y_text) = datasets.mnist.load_data()# tensor =&gt; datasetstrain_db = tf.data.Dataset.from_tensor_slices((x,y))train_db = train_db.map(preprocess).shuffle(60000).batch(128)test_db = tf.data.Dataset.from_tensor_slices((x_text,y_text))test_db = test_db.map(preprocess).shuffle(10000).batch(128) 使用 tf.keras 来构建模型TensorFlow2.0 降低了使用者的门槛,利用 tf.keras 可以直接使用 Keras 的一系列 API,这样就可以更加方便地定义模型,比如说前面定义参数 [w,b] 的过程就可以简化成下面这样 12345678910111213# 用 Sequential 构建 3 层的全连接network = Sequential([layers.Dense(256, activation='relu'), layers.Dense(128, activation='relu'), layers.Dense(10) ])# build 并制定 inputnetwork.build(input_shape=[None, 28*28])# 查看模型参数network.summary()# 指定优化器optimizer = optimizers.Adam(lr=0.01) 使用 metrics 自动计算 loss 和 accuracy12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364# Step1.Build a meteracc_meter = metrics.Accuracy()loss_meter = metrics.Mean()for epoch in range(10): # iterate db for 10 for step, (x, y) in enumerate(train_db, 1): x = tf.reshape(x, [-1,28*28]) with tf.GradientTape() as tape: # [b,784] =&gt; [b,10] out = network(x) y_onehot = tf.one_hot(y, depth=10) loss = tf.reduce_mean(tf.losses.categorical_crossentropy(y_onehot, out, from_logits=True)) # Step2.Update data loss_meter.update_state(loss) # compute gradients # grads = tape.gradient(loss, [w1, b1, w2, b2, w3, b3]) grads = tape.gradient(loss, network.trainable_variables) optimizer.apply_gradients(zip(grads, network.trainable_variables)) if step % 100 == 0: # Step3.Get Average data print(step, 'loss:', loss_meter.result().numpy()) # Clear buffer loss_meter.reset_states() total_number = 0 total_correct = 0 for step, (x, y) in enumerate(test_db): acc_meter.reset_states() # [b, 28, 28] =&gt; [b, 28*28] x = tf.reshape(x,[-1,28*28]) # [b, 784] =&gt; [b, 256] =&gt; [b, 128] =&gt; [b, 10] # h1 = tf.nn.relu(x@w1 + b1) # h2 = tf.nn.relu(h1@w2 + b2) # out = h2@w3 + b3 # 输出调用 network 就可以获得 out = network(x) # [b, 10] ~ R # [b, 10] ~ [0,1] prob = tf.nn.softmax(out, axis=1) # [b, 10] =&gt; [b] pred = tf.argmax(prob, axis=1) pred = tf.cast(pred, dtype=tf.int32) # [b] int32 # print(y.dtype, preb.dtype) # correct = tf.cast(tf.equal(y, pred), dtype=tf.int32) # correct = tf.reduce_sum(correct) # total_correct += int(correct) # total_number += x.shape[0] # metrics 能快速计算 acc 和 loss acc_meter.update_state(y, pred) # acc = total_correct / total_number print(step, 'Evaluate Acc:', acc_meter.result().numpy()) tf.keras 版12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455import tensorflow as tffrom tensorflow import kerasfrom tensorflow.keras import datasets, layers, optimizers, Sequential, metricsimport osos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'def preprocess(x, y): \"\"\" x is a simple image, not a batch \"\"\" x = tf.cast(x, dtype=tf.float32) / 255. x = tf.reshape(x, [28*28]) y = tf.cast(y, dtype=tf.int32) y = tf.one_hot(y, depth=10) return x,y# x: [60000,28,28], x_test:[10000,28,28]# y: [60000], y_test:[10000](x, y), (x_text, y_text) = datasets.mnist.load_data()# tensor =&gt; datasetstrain_db = tf.data.Dataset.from_tensor_slices((x,y))train_db = train_db.map(preprocess).shuffle(60000).batch(128)test_db = tf.data.Dataset.from_tensor_slices((x_text,y_text))test_db = test_db.map(preprocess).shuffle(10000).batch(128)# 使用 tf.Sequential 定义上面的这些参数network = Sequential([layers.Dense(256, activation='relu'), layers.Dense(128, activation='relu'), layers.Dense(10) ])network.build(input_shape=(None, 28*28))network.summary()network.compile(optimizer=optimizers.Adam(lr=0.01), loss=tf.losses.CategoricalCrossentropy(from_logits=True), metrics=['accuracy'])network.fit(train_db, epochs=10, validation_data=test_db, validation_freq=2)network.evaluate(test_db)sample = next(iter(ds_val))x = sample[0]y = sample[1] # one-hotpred = network.predict(x) # [b, 10]# convert back to numbery = tf.argmax(y, axis=1)pred = tf.argmax(pred, axis=1)print(pred)print(y)","link":"/post/c6ed1613.html"},{"title":"如何自建数据集","text":"(1) 学会使用爬虫爬取图像和视频,从视频中提取图片。 (2) 对获得的图片数据进行整理,包括重命名,格式统一,去重。 爬取图片有些任务没有直接对应的开源数据集,或者开源数据集中的数据比较少,这就需要我们通过搜索引擎自行爬取图片。 百度图片爬虫 Download images from Google, Bing, Baidu. 谷歌、百度、必应图片下载 Google, Naver multiprocess image web crawler (Selenium) 数据集整理爬取的如果是视频需要先转换成图片，如果是图片就要做好统一格式、数据清洗的工作。 视频转换成图片使用爬虫爬取数据,如果是视频可以使用 python getimagefromvideo.py &lt;video_path&gt; 将视频转换为图片 1234567891011121314151617181920#coding:utf8import cv2import dlibimport numpy as npimport sysimport osvideo_capture = cv2.VideoCapture(sys.argv[1])video_id = sys.argv[1].split('.')[0]os.mkdir(video_id)count = 0while True: is_sucessfully_read, im = video_capture.read() if is_sucessfully_read == False: break cv2.imwrite(os.path.join(video_id,str(count)+'.jpg'),im) print \"image shape=\",im.shape count = count + 1 print count 统一图片后缀格式统一后缀格式可以减少以后写数据 API 时的压力,也可以测试图片是不是可以正常的读取,及时防止未知问题的出现,这很重要。 使用 python reformat_image.py &lt;images_folder_path&gt; 将图片全部转换为 jpg 格式,这也是所有框架支持的格式。 12345678910111213141516171819202122232425import osimport sysimport cv2import numpy as npdef listfiles(rootDir): list_dirs = os.walk(rootDir) for root, dirs, files in list_dirs: for d in dirs: print os.path.join(root,d) for f in files: fileid = f.split('.')[0] filepath = os.path.join(root,f) try: src = cv2.imread(filepath,1) print \"src=\",filepath,src.shape os.remove(filepath) cv2.imwrite(os.path.join(root,fileid+\".jpg\"),src) except: os.remove(filepath) continuelistfiles(sys.argv[1]) 按格式重命名图片统一格式的命名有利于区分和整理数据 12mkdir tmp./rename_files_function.sh &lt;images_folder_path&gt; ./tmp/ &lt;label&gt; 12345678910111213141516171819202122232425262728293031323334353637383940i=0dir=$1resultdir=$2app=$3for file in $dir\"\"* do arr=$(echo $file | tr \"/\" \"\\n\") for x in $arr do filename=$x done brr=$(echo $filename | tr \".\" \"\\n\") brrs=( $brr ) fileid=${brrs[0]} num=${#brrs[@]} index=$(expr $num - 1) fileformat=${brrs[index]} echo file=\"\"$file echo fileid=\"\"$fileid echo fileformat=\"\"$fileformat if [ $fileformat == jpeg -o $fileformat == png -o $fileformat == jpg -o $fileformat == bmp ] ; then #echo \"good\" i=$(expr $i + 1) resultfile=$resultdir\"\"$app\"\"$i\"\".$fileformat echo file=\"\"$file\"\",resultfile=\"\"$resultfile mv \"$file\" \"$resultfile\" else echo $file\"\"not good fidoneecho 执行删除\"\"$dir\"\"*#rm $dir\"\"*echo 执行mv\"\"$resultdir\"\"*mv $resultdir\"\"* $dir 去重如果你使用多个关键词或者使用不同的搜索引擎同样的关键词,或者从视频中提取图片,那么爬取回来的图片很可能有重复或者非常的相似,这样的样本应该被去除。 去除有很多种方法,比如直接比较两幅图像是不是完全相同,通过 hash 等相似度方法来进行相似度,这里我们提供一个方法,利用相似度来进行去重。 12345# sudo pip install python-Levenshteinconda install -c conda-forge python-levenshtein python remove_repeat.py &lt;image_path&gt;https://anaconda.org/conda-forge/python-levenshtein 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270#!/usr/bin/env python#coding:utf8import mathfrom PIL import Imageimport Levenshteinclass BWImageCompare(object): \"\"\"Compares two images (b/w).\"\"\" _pixel = 255 _colour = False def __init__(self, imga, imgb, maxsize=64): \"\"\"Save a copy of the image objects.\"\"\" sizea, sizeb = imga.size, imgb.size newx = min(sizea[0], sizeb[0], maxsize) newy = min(sizea[1], sizeb[1], maxsize) # Rescale to a common size: imga = imga.resize((newx, newy), Image.BICUBIC) imgb = imgb.resize((newx, newy), Image.BICUBIC) if not self._colour: # Store the images in B/W Int format imga = imga.convert('I') imgb = imgb.convert('I') self._imga = imga self._imgb = imgb # Store the common image size self.x, self.y = newx, newy def _img_int(self, img): \"\"\"Convert an image to a list of pixels.\"\"\" x, y = img.size for i in xrange(x): for j in xrange(y): yield img.getpixel((i, j)) @property def imga_int(self): \"\"\"Return a tuple representing the first image.\"\"\" if not hasattr(self, '_imga_int'): self._imga_int = tuple(self._img_int(self._imga)) return self._imga_int @property def imgb_int(self): \"\"\"Return a tuple representing the second image.\"\"\" if not hasattr(self, '_imgb_int'): self._imgb_int = tuple(self._img_int(self._imgb)) return self._imgb_int @property def mse(self): \"\"\"Return the mean square error between the two images.\"\"\" if not hasattr(self, '_mse'): tmp = sum((a-b)**2 for a, b in zip(self.imga_int, self.imgb_int)) self._mse = float(tmp) / self.x / self.y return self._mse @property def psnr(self): \"\"\"Calculate the peak signal-to-noise ratio.\"\"\" if not hasattr(self, '_psnr'): self._psnr = 20 * math.log(self._pixel / math.sqrt(self.mse), 10) return self._psnr @property def nrmsd(self): \"\"\"Calculate the normalized root mean square deviation.\"\"\" if not hasattr(self, '_nrmsd'): self._nrmsd = math.sqrt(self.mse) / self._pixel return self._nrmsd @property def levenshtein(self): \"\"\"Calculate the Levenshtein distance.\"\"\" if not hasattr(self, '_lv'): stra = ''.join((chr(x) for x in self.imga_int)) strb = ''.join((chr(x) for x in self.imgb_int)) lv = Levenshtein.distance(stra, strb) self._lv = float(lv) / self.x / self.y return self._lvclass ImageCompare(BWImageCompare): \"\"\"Compares two images (colour).\"\"\" _pixel = 255 ** 3 _colour = True def _img_int(self, img): \"\"\"Convert an image to a list of pixels.\"\"\" x, y = img.size for i in xrange(x): for j in xrange(y): pixel = img.getpixel((i, j)) yield pixel[0] | (pixel[1]&lt;&lt;8) | (pixel[2]&lt;&lt;16) @property def levenshtein(self): \"\"\"Calculate the Levenshtein distance.\"\"\" if not hasattr(self, '_lv'): stra_r = ''.join((chr(x&gt;&gt;16) for x in self.imga_int)) strb_r = ''.join((chr(x&gt;&gt;16) for x in self.imgb_int)) lv_r = Levenshtein.distance(stra_r, strb_r) stra_g = ''.join((chr((x&gt;&gt;8)&amp;0xff) for x in self.imga_int)) strb_g = ''.join((chr((x&gt;&gt;8)&amp;0xff) for x in self.imgb_int)) lv_g = Levenshtein.distance(stra_g, strb_g) stra_b = ''.join((chr(x&amp;0xff) for x in self.imga_int)) strb_b = ''.join((chr(x&amp;0xff) for x in self.imgb_int)) lv_b = Levenshtein.distance(stra_b, strb_b) self._lv = (lv_r + lv_g + lv_b) / 3. / self.x / self.y return self._lvclass FuzzyImageCompare(object): \"\"\"Compares two images based on the previous comparison values.\"\"\" def __init__(self, imga, imgb, lb=1, tol=15): \"\"\"Store the images in the instance.\"\"\" self._imga, self._imgb, self._lb, self._tol = imga, imgb, lb, tol def compare(self): \"\"\"Run all the comparisons.\"\"\" if hasattr(self, '_compare'): return self._compare lb, i = self._lb, 2 diffs = { 'levenshtein': [], 'nrmsd': [], 'psnr': [], } stop = { 'levenshtein': False, 'nrmsd': False, 'psnr': False, } while not all(stop.values()): cmp = ImageCompare(self._imga, self._imgb, i) diff = diffs['levenshtein'] if len(diff) &gt;= lb+2 and \\ abs(diff[-1] - diff[-lb-1]) &lt;= abs(diff[-lb-1] - diff[-lb-2]): stop['levenshtein'] = True else: diff.append(cmp.levenshtein) diff = diffs['nrmsd'] if len(diff) &gt;= lb+2 and \\ abs(diff[-1] - diff[-lb-1]) &lt;= abs(diff[-lb-1] - diff[-lb-2]): stop['nrmsd'] = True else: diff.append(cmp.nrmsd) diff = diffs['psnr'] if len(diff) &gt;= lb+2 and \\ abs(diff[-1] - diff[-lb-1]) &lt;= abs(diff[-lb-1] - diff[-lb-2]): stop['psnr'] = True else: try: diff.append(cmp.psnr) except ZeroDivisionError: diff.append(-1) # to indicate that the images are identical i *= 2 self._compare = { 'levenshtein': 100 - diffs['levenshtein'][-1] * 100, 'nrmsd': 100 - diffs['nrmsd'][-1] * 100, 'psnr': diffs['psnr'][-1] == -1 and 100.0 or diffs['psnr'][-1], } return self._compare def similarity(self): \"\"\"Try to calculate the image similarity.\"\"\" cmp = self.compare() lnrmsd = (cmp['levenshtein'] + cmp['nrmsd']) / 2 return lnrmsd return min(lnrmsd * cmp['psnr'] / self._tol, 100.0) # TODO: fix psnr!if __name__ == '__main__': import sys import os srcimages = os.listdir(sys.argv[1]) srcimages.sort() tot = len(srcimages) tot = (tot ** 2 - tot) / 2 print 'Comparing %d images:' % tot images = {} ###向后删除图片 similarity_thresh = 0.5 ##相似度阈值，超过即判断为相同图片 i = 0 while(i &lt; len(srcimages)-1): print \"i=\", i,\"num of srcimages\",len(srcimages) imga = Image.open(os.path.join(sys.argv[1],srcimages[i])) imgb = Image.open(os.path.join(sys.argv[1],srcimages[i+1])) cmp = FuzzyImageCompare(imga, imgb) sim = cmp.similarity() / 100 print \"image \",os.path.join(sys.argv[1],srcimages[i]),\" and image\",os.path.join(sys.argv[1],srcimages[i+1]),\" sim=\",sim if sim &gt; similarity_thresh: print \"delete \",os.path.join(sys.argv[1],srcimages[i+1]) os.remove(os.path.join(sys.argv[1],srcimages[i+1])) srcimages.pop(i+1) else: i = i+1 ''' results, i = {}, 1 for namea, imga in images.items(): for nameb, imgb in images.items(): if namea == nameb or (nameb, namea) in results: continue print ' * %2d / %2d:' % (i, tot), print namea, nameb, '...', cmp = FuzzyImageCompare(imga, imgb) sim = cmp.similarity() results[(namea, nameb)] = sim print '%.2f %%' % sim i += 1 res = max(results.values()) imgs = [k for k, v in results.iteritems() if v == res][0] print 'Most similar images: %s %s (%.2f %%)' % (imgs[0], imgs[1], res) ''' 在此之后还需要自己手动筛选图片，工作量其实也不小，不过经过去重还是可以减少不少工作量的。 数据集标注爬取的图片需要自己标注，可以使用下面这些标注工具。 https://github.com/tzutalin/labelImg LabelImg is a graphical image annotation tool and label object bounding boxes in images https://youtu.be/p0nR2YsCY_U https://github.com/wkentaro/labelme Image Polygonal Annotation with Python (polygon, rectangle, circle, line, point and image-level flag annotation). https://github.com/Microsoft/VoTT Visual Object Tagging Tool: An electron app for building end to end Object Detection Models from Images and Videos. 数据集划分一般会按照 8:1:1 将数据集划分为训练集、验证集、测试集。这个要根据自己的情况编写 shell 脚本，下面是我用 darknet 训练 yolov3 模型时划分数据的脚本。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#!/bin/shif [ $# != 1 ];then echo \"Usage: $0 &lt;full path&gt;\" exit -1fipath=$1for sub_dir in `ls $path` do # 获取子文件夹的全路径 sub_dir_path=$path/$sub_dir if [ -d $sub_dir_path ] then # 将子目录下所有文件移动到父目录中 `mv $sub_dir_path/* $path` # 删除子目录 `rm -rf $sub_dir_path` fi # 给所有文件添加前缀 done`rm tmp.txt`# 将文件夹下指定类型的文件写到文件中# ***** 问题：最后会有个空行 *****# 图片文件存在对应的 txt 文件,则将图片路径追加到 tmp.txt 文件中for image in `find $path | grep -E 'jpg|png|JPEG|JPG|PNG'`do txt=${image%.*}\".txt\" if [ -f $txt ] then echo ${image} `echo ${image} &gt;&gt; tmp.txt` fi done# 将路径 8:1:1 放到 train.txt,val.txt,test.txt# 1. 计算 tmp,txt 文件行数# 2. 计算得出分配到各个文件的行号# 3. 将对应行数的内容写到对应文件夹中line=`cat tmp.txt | wc -l`line1=$(($line/10*8))line2=$(($line/10*8+line/10+1))`sed -n 1,${line1}p tmp.txt &gt;&gt; train.txt``sed -n $((${line1}+1)),${line2}p tmp.txt &gt;&gt; val.txt``sed -n $((${line2}+1)),$((${line}-1))p tmp.txt &gt;&gt; test.txt` yolov3 的标注格式如下所示 19 0.732955 0.591102 0.270317 0.193503 统计标签的时候可以使用 1awk '{print $1}' *.txt | sort -g | uniq -c 以上就是自己建立一个数据集的流程：爬取图片-&gt;整理图片-&gt;标注图片-&gt;训练。","link":"/post/b64b0362.html"},{"title":"Java 反射和动态代理","text":"反射提供了一种机制——用来检测可用的方法，并返回方法名。通过类名我们就能获取 Class 对象，并通过 Class 对象获取对象相关的一些属性和方法等。 最常见到的地方就是在各种配置文件中的应用，它的使用就像传入一个字符串，然后字符串去获取了相应的对象。 反射在了解反射之前要知道组成 Java 程序的是一个个类，每一个类都有一个 Class 对象，他对应一个.class文件。 所有的类都是在被第一次被调用的时候加载到 JVM 中的，并且一个类的也不是一次性加载完成，是在用到某一部分的时候才加载的。比如一个类被加载的时候一定会先加载静态变量，所以我们把常量定义为静态的。 注：以上内容整理自《Java 编程思想》。 我们用反射的第一步就是要获取Class 对象，再去获取他的其他属性。可以使用Class.forName()方法获取。 123456789101112131415161718public class MyReflect { public String className = null; @SuppressWarnings(\"rawtypes\") public Class dogClass = null; /** * 反射获取 Dog 类 * * @throws ClassNotFoundException */ @Before public void init() throws ClassNotFoundException { className = \"com.shuiyujie.reflection.Dog\"; dogClass = Class.forName(className); } 获取Class 对象之后，我们可以通过它创建一个实例对象 12345678910/** * 获得对象实例，调用无参构造 * * @throws IllegalAccessException * @throws InstantiationException */ @Test public void newInstance() throws IllegalAccessException, InstantiationException { System.out.println(dogClass.newInstance()); } 还可以通过它获取对象的构造方法、成员变量、成员方法等，方法又有公有和非公有之分，非公有的如果我们要强制获取要消除他的类型校验，这就是反射 API 要知道的大部分内容了，示例代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/** * 获取公共的成员变量 * @throws Exception */ @SuppressWarnings({ \"rawtypes\", \"unchecked\" }) @Test public void getPublicParams() throws Exception { Constructor constructor = dogClass.getConstructor(Long.class,String.class); Object obj = constructor.newInstance(1L, \"Lucky\"); Field field = dogClass.getField(\"name\"); field.set(obj,\"Lucy\"); System.out.println(field.get(obj)); } /** * 获取非公共的成员变量 * @throws Exception */ @SuppressWarnings({ \"rawtypes\", \"unchecked\" }) @Test public void getUnPublicParams() throws Exception { Constructor constructor = dogClass.getConstructor(Long.class,String.class); Object obj = constructor.newInstance(1L, \"Lucky\"); Field field = dogClass.getDeclaredField(\"id\"); field.setAccessible(true); field.set(obj,3L); System.out.println(field.get(obj)); } /** * 获取公共的成员方法 * @throws Exception */ @SuppressWarnings({ \"rawtypes\", \"unchecked\" }) @Test public void getPublicMethod() throws Exception { System.out.println(dogClass.getMethod(\"toString\")); Object obj = dogClass.newInstance(); Method method = dogClass.getMethod(\"brak\"); method.invoke(obj); } /** * 获取非公共的成员方法 * @throws Exception */ @SuppressWarnings({ \"rawtypes\", \"unchecked\" }) @Test public void getUnPublicMethod() throws Exception { Object obj = dogClass.newInstance(); Method method = dogClass.getDeclaredMethod(\"dogBrak\"); method.setAccessible(true); method.invoke(obj); } 此外他还有一些其他方法示例，更多可以参考 Class 类的 API 123456789101112131415161718192021@Test public void otherMethod() throws ClassNotFoundException { //当前加载这个class文件的那个类加载器对象 System.out.println(dogClass.getClassLoader()); //获取某个类实现的所有接口 Class[] interfaces = dogClass.getInterfaces(); for (Class class1 : interfaces) { System.out.println(class1); } //反射当前这个类的直接父类 System.out.println(dogClass.getGenericSuperclass()); //判断当前的Class对象表示是否是数组 System.out.println(dogClass.isArray()); System.out.println(new String[3].getClass().isArray()); //判断当前的Class对象表示是否是枚举类 System.out.println(dogClass.isEnum()); System.out.println(Class.forName(\"com.shuiyujie.reflection.Animal\").isEnum()); //判断当前的Class对象表示是否是接口 System.out.println(dogClass.isInterface()); System.out.println(Class.forName(\"com.shuiyujie.reflection.AnimalInterface\").isInterface()); } 动态代理动态代理指的是在不修改原业务的基础上，基于原业务方法，进行重新的扩展，实现新的业务。实现动态代理的核心就是反射机制。 用一个场景来描述动态代理。比如一个订单系统，有一个生成订单的 service，当我们要搞活动进行促销的时候，生成订单的价格根据活动降低价格。 修改原有的生成订单的方法无疑是不可行的，因为系统的其他模块可能也调用了这个方法，甚至活动有多种的优惠方式只改一个也不够。这里就可以用动态代理来代理订单生成的方法。 代理我们也可以叫他中介，比如房产中介就是在客户之间起桥梁作用，动态代理就是在调用发和被调用方中间介入。 首先要有订单的接口和实现： 123456789101112public interface IOrderService { int getClothOrder(String size);}public class OrderServiceImpl implements IOrderService { private int clothPrize = 500; @Override public int getClothOrder(String size) { System.out.println(\"衣服的尺码为\" + size); return clothPrize; }} 用一个 Controller 调用他获得价格： 1234567public class OrderController { @Test public void getOrder(){ IOrderService orderService = new OrderServiceImpl(); int price = orderService.getClothOrder(\"L\"); System.out.println(\"价格为\" + price + \"元\"); } 输出： 12衣服的尺码为L价格为500元 在IOrderService和OrderServiceImpl不变的情况下通过IOrderService来实现打折的效果，就要用到动态代理了。 动态代理类： 123456789101112public class ProxyCharge { public static &lt;T&gt; T getProxy(final int discountCoupon, final Class&lt;?&gt; interfaceClass, final Class&lt;?&gt; implementsClass) throws Exception { return (T) Proxy.newProxyInstance(interfaceClass.getClassLoader(), new Class[]{interfaceClass}, (proxy, method, args) -&gt; { Integer returnValue = (Integer) method.invoke( implementsClass.newInstance(), args); return returnValue - discountCoupon; }); }} 关键是通过Proxy.newProxyInstance()获取一个原来OrderServiceImpl的代理对象。我们需要传入借口对象和实现对象。 获取代理对象之后可以使用反射中的invoke()调用原先方法，也能进行自己扩展。 代理方法调用： 123456@Testpublic void getChargeOrder() throws Exception { IOrderService proxyService = ProxyCharge.getProxy(200,IOrderService.class,OrderServiceImpl.class); int price = proxyService.getClothOrder(\"L\"); System.out.println(\"价格为\" + price + \"元\");} 输出： 12衣服的尺码为L价格为300元 总结：反射允许更加动态的编程风格，动态代理可以动态地获取代理对象并动态地处理对所代理对象的调用。 动态代理听上去很复杂但是他的实现方式是基本固定的，以上的示例代码是最简单的实现。同时动态代理是实现 RPC 框架不可或缺的一部分，现在温习一下为实现一个 RPC 框架做准备。","link":"/post/e0acc964.html"},{"title":"mybatis 配置和使用","text":"MyBatis 是一款一流的支持自定义 SQL、存储过程和高级映射的持久化框架。MyBatis 几乎消除了所有的 JDBC 代码，也基本不需要手工去设置参数和获取检索结果。MyBatis 能够使用简单的 XML 格式或者注解进行来配置，能够映射基本数据元素、Map 接口和 POJOs（普通 java 对象）到数据库中的记录。 简而言之：Mybatis 是一个半自动化的持久化框架，帮助我们简化对数据库的操作。 封装 SqlSessionMybatis 使用 SqlSession 调用他封装的一系列方法，而 SqlSession 则交由 SqlSessionFactory 进行管理。 注入 SqlSession第一步就是配置 SqlSessionFactory 和 SqlSession。用 spring 和容易就能实现，在 spring 的配置文件mybatis-spring.xml中注入 bean: 123456789&lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt; &lt;property name=&quot;configLocation&quot; value=&quot;classpath:mybatis-config.xml&quot; /&gt; &lt;property name=&quot;mapperLocations&quot; value=&quot;classpath*:mapper/*.xml&quot; /&gt; &lt;/bean&gt; &lt;bean id=&quot;sqlSession&quot; class=&quot;org.mybatis.spring.SqlSessionTemplate&quot;&gt; &lt;constructor-arg index=&quot;0&quot; ref=&quot;sqlSessionFactory&quot; /&gt; &lt;/bean&gt; 其中configLocation指向 mybatis 的配置文件，我们使用配置文件可以配置别名，别名可以用来指向一个实体类： 123456&lt;configuration&gt; &lt;typeAliases&gt; &lt;!-- 指定包名 --&gt; &lt;package name=&quot;com.shuiyujie.persist&quot;/&gt; &lt;/typeAliases&gt;&lt;/configuration&gt; 12345&lt;configuration&gt; &lt;typeAliases&gt; &lt;!-- 指定类名 --&gt; &lt;typeAlias alias=&quot;city&quot; type=&quot;com.shuiyujie.persist.City&quot;/&gt;&lt;/configuration&gt; 其中mapperLocations指定了 mybatis 的 Mapper 文件，配置之后会扫描指定包下的 XML 文件。dataSource指向配置的数据源。 封装 SqlSessionSqlSession 可以调用 mybatis 为我们封装的一系列增删改查操作，具体可以看参考文档。 我们可以将它封装一下变得更加友好。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101@Componentpublic class DaoRouter implements IDaoRouter{ /** * 普通查询 * @param statement sql语句定义的id * @param parameters 参数 * @return */ public &lt;T&gt; List&lt;T&gt; query(String statement, Object parameters) { return sqlSession.selectList(statement, parameters); } /** * 分页查询，注意此处不需要在sql语句中定义startRow和endRow，如果定义，那就用上面的普通查询即可。 * @param statement * @param parameters * @param offset * @param limit * @return */ public &lt;T&gt; List&lt;T&gt; query(String statement, Object parameters, int offset, int limit) { return sqlSession.selectList(statement, parameters,new RowBounds(offset,limit)); } /** * 返回第一条记录查询结果，如果没有就返回null * @param statementName * @param parameters * @return */ public &lt;T&gt; T queryForObject(String statementName, Object parameters) { return sqlSession.selectOne(statementName, parameters); } /** * 更新数据 * @param statement * @param parameters * @return */ public int update(String statement, Object parameters) { return sqlSession.update(statement, parameters); } /** * 删除 * @param statement * @param parameters * @return */ public int delete(String statement, Object parameters) { return sqlSession.delete(statement, parameters); } /** * 新增数据，建议在定义sql语句的时候，使用selectKey保证可以返回新增后的主键 * @param statement * @param parameters * @return */ public int insert(String statement, Object parameters) { return sqlSession.insert(statement, parameters); } /** * 批量删除 * @param statementName * @param dataList */ public void deleteBatch(String statementName, Collection&lt;?&gt; dataList) { for (Object data : dataList) { this.delete(statementName, data); } } /** * 批量新增 * @param statementName * @param dataList */ public void insertBatch(String statementName, Collection&lt;?&gt; dataList) { for (Object data : dataList) { this.insert(statementName, data); } } /** * 批量修改 * @param statementName * @param dataList */ public void updateBatch(String statementName, Collection&lt;?&gt; dataList) { for (Object data : dataList) { this.update(statementName, data); } } @Autowired private SqlSession sqlSession;} 查询首先创建两个实体类省和市，他们之间为一对多的关系。 123456789public class Province implements Serializable{ private Long id; private String name; private String description; private List&lt;City&gt; cityList; 1234567891011public class City implements Serializable{ private Long id; private Long provinceId; private String cityName; private String description; private Province province; 一对一查询现在要查询一个城市，同时查询出该城市所在的省。也就是获取 City 对象的时候，同时返回他的 province 成员变量。我们要使用resultMap中的association元素。 采用关联查询的方式，sql 语句如下： 123select * from city c LEFT JOIN province p ON c.province_id = p.id 这种情况下有可能是关联查询一整个对象，比如 province 的所有变量；也有可能只想查询 province 的少数变量，比如说查个名字。 提供有两种解决方案。 association 关联一个对象查询关联查询时在查出 city 表中的结果集时也会查出 province 表的结果集，得到两个结果集之后要做的事情就是将他们各自映射到各自的对象中，mybatis 采用在resultMap中指定association的方式来实现以上效果。 注：字段名出现重复的现象可以为其指定唯一的别名 City.java 123456789101112131415public class City implements Serializable { @Id @GeneratedValue private Long id; @Column(nullable = false) private Long provinceId; @Column(nullable = false) private String cityName; private String description; private Province province; private Province province;在 Ctiy 中加一个 Province 对象，查询 City 时也查询 Province。 CityMapper.xml 123456789101112131415 &lt;resultMap id=\"BaseResultMap\" type=\"city\"&gt; &lt;result column=\"id\" property=\"id\" /&gt; &lt;result column=\"province_id\" property=\"provinceId\" /&gt; &lt;result column=\"city_name\" property=\"cityName\" /&gt; &lt;result column=\"description\" property=\"description\" /&gt; &lt;association property=\"province\" column=\"province_id\" javaType=\"province\" resultMap=\"Province.provinceResult\"/&gt; &lt;/resultMap&gt;&lt;select id=\"loadCity\" resultMap=\"BaseResultMap\" &gt; select * from city c LEFT JOIN province p ON c.province_id = p.id &lt;/select&gt; ProvinceMapper.xml 1234&lt;select id=\"loadProvinceAndCity\" resultMap=\"provinceResult\" parameterType=\"Long\"&gt; SELECT * FROM province WHERE id = #{id} &lt;/select&gt; 重点来看CityMapper.xml的association property：表示变零名称，即 City 对象中的 province 属性 column：关联的字段 javaType:关联对象的类型 resultMap:关联对象的结果集 扩展 ResultMap 来扩展字段这次不查整个 Province 只是查询 Province 的一个 name，可以不用association。 CityVO.java 12public class CityVO extends City { private String provinceName; 给City.java一个包装类，添加成员变量 provinceName。 扩展 ResultMap: 12345678910&lt;resultMap id=\"cityResultMap\" type=\"city\"&gt; &lt;result column=\"id\" property=\"id\" /&gt; &lt;result column=\"province_id\" property=\"provinceId\" /&gt; &lt;result column=\"city_name\" property=\"cityName\" /&gt; &lt;result column=\"description\" property=\"description\" /&gt; &lt;/resultMap&gt; &lt;resultMap id=\"cityProvinceResultMap\" extends=\"cityResultMap\" type=\"cityVO\"&gt; &lt;result column=\"name\" property=\"provinceName\" /&gt; &lt;/resultMap&gt; 注意cityProvinceResultMap: extends:表示继承关系，是被继承 ResultMap 的扩展 column: sql 语句查询出来的需要映射的字段名称 property: 实体类中对应的成员变量的名称 XML 查询语句: 12345&lt;select id=\"loadCityAndProvinceName\" resultMap=\"cityProvinceResultMap\" &gt; select c.*,p.name from city c LEFT JOIN province p ON c.province_id = p.id &lt;/select&gt; 集合嵌套查询现在要在查询省的时候，返回该省下市的信息。也就是获取 Province 对象的时候，同时返回他的 cityList 成员变量。我们要使用resultMap中的collection元素。 ProvinceMapper.xml 1234567891011121314151617&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" &gt;&lt;mapper namespace=\"Province\"&gt; &lt;resultMap id=\"provinceResult\" type=\"province\"&gt; &lt;result column=\"id\" property=\"id\"/&gt; &lt;result column=\"name\" property=\"name\"/&gt; &lt;result column=\"description\" property=\"description\"/&gt; &lt;collection property=\"cityList\" javaType=\"ArrayList\" column=\"id\" ofType=\"city\" select=\"City.loadCityForProvince\"/&gt; &lt;/resultMap&gt; &lt;select id=\"loadProvinceAndCity\" resultMap=\"provinceResult\" parameterType=\"Long\"&gt; SELECT * FROM province WHERE id = #{id} &lt;/select&gt;&lt;/mapper&gt; CityMapper.xml 12345&lt;mapper namespace=\"City\"&gt; &lt;select id=\"loadCityForProvince\" resultType=\"city\"&gt; select * from city WHERE province_id = #{id}; &lt;/select&gt; 重点关注ProvinceMapper.xml的collection部分，他表示返回集合类型 12&lt;collection property=\"cityList\" javaType=\"ArrayList\" column=\"id\" ofType=\"city\" select=\"City.loadCityForProvince\"/&gt; property:匹配的属性名称，也就是Province中的cityList成员变量 javaType：集合的类型(可以省略) column:关联的字段 ofType:集合中包含元素的类型，这里用了别名 select：关联查询的方法 集合迭代器查询比如想查询几个省中的市，可以传入一个包含省数据的 list，然后使用 mybatis 迭代遍历这个 list 集合查询获取所有下属的市。 要用到一个动态 sql 的标签&lt;foreach&gt;,XML 如下： 12345678&lt;select id=\"loadCityByProvinceList\" resultType=\"city\"&gt; select * from city WHERE province_id IN &lt;foreach item=\"item\" index=\"index\" collection=\"list\" open=\"(\" separator=\",\" close=\")\"&gt; #{item} &lt;/foreach&gt; &lt;/select&gt; 插入插入设置主键自增12345678&lt;insert id=&quot;insertXXX&quot; parameterType=&quot;fileNameVO&quot; useGeneratedKeys=&quot;true&quot; keyProperty=&quot;id&quot;&gt; INSERT INTO file_name ( ... )VALUES( ... ) &lt;/insert&gt; useGeneratedKeys：是否自增 keyProperty：主键名称 注解方式调用 sql注解方式开发 12345package org.mybatis.example;public interface BlogMapper { @Select(\"SELECT * FROM blog WHERE id = #{id}”) Blog selectBlog(int id); } 简单的 sql 语句可以用注解，但是复杂的不适宜用注解开发的方式。一般采用 XML 方式进行开发，有必要知道有注解开发这种方式。","link":"/post/5ed7ab06.html"},{"title":"认识 Docker","text":"Docker 是一种虚拟化容器技术。他主要解决了配置环境问题。软件部署环节的第一步就是配置环境，使软件能够在机器上流畅地运行。常常听到的一句话是：“我的电脑上能运行啊。”可是换到生产环境就不行了，又需要重新配置环境。最好的解决方式是能够将原始环境的配置一模一样地复制一份，大家就能够时刻保持在相同的环境下运行软件。 认识 DockerDocker 是一种虚拟化容器技术。当我听到虚拟化容器最先想到的是虚拟机，docker 和虚拟机又有很大差别。 虚拟机可以在一种操作系统里面运行另一种操作系统，看上去跟真实系统一模一样，而对于底层系统来说，虚拟机就是一个普通文件可以随时删除。通过虚拟机我们可以在硬件上运行多个不同的操作系统，但是他有几个缺点： 资源占用多:虚拟机会独占一部分内存和硬盘空间。它运行的时候，其他程序就不能使用这些资源了; 冗余步骤多:虚拟机是完整的操作系统，一些系统级别的操作步骤，往往无法跳过，比如用户登录; 启动慢：启动操作系统需要多久，启动虚拟机就需要多久。 Docker 最初基于 Linux 中的一种容器轻量级虚拟化技术：Linux 容器（Linux Containers，缩写为 LXC）。LXC 则基于 Linux 内核调用 CGroups 和 Namespaces，同时提供用户态 API 接口。用户则可以通过 LXC 提供的资源限制和隔离功能，创建一套完整并且相互隔离的虚拟应用运行环境。 Linux 容器不是模拟一个完整的操作系统，而是对进程进行隔离。或者说，在正常进程的外面套了一个保护层。对于容器里面的进程来说，它接触到的各种资源都是虚拟的，从而实现与底层系统的隔离。所以 Docker 是进程级别的管理，相对于虚拟机他就有以下几个优点： 启动快:容器里面的应用，直接就是底层系统的一个进程，而不是虚拟机内部的进程。 资源占用少:容器只占用需要的资源，不占用那些没有用到的资源；虚拟机由于是完整的操作系统，不可避免要占用所有资源。另外，多个容器可以共享资源，虚拟机都是独享资源。 体积小:容器只要包含用到的组件即可，而虚拟机是整个操作系统的打包，所以容器文件比虚拟机文件要小很多。 Docker 的历史Docker 最初是 dotCloud 公司创始人 Solomon Hykes 在法国期间发起的一个公司内部项目， 它是基于 dotCloud 公司多年云服务技术的一次革新，并于 2013 年 3 月以 Apache 2.0 授权 协议开源，主要项目代码在 GitHub 上进行维护。Docker 项目后来还加入了 Linux 基金会， 并成立推动 开放容器联盟（OCI）。 Docker 自开源后受到广泛的关注和讨论，至今其 GitHub 项目已经超过 4 万 6 千个星标和一 万多个 fork。甚至由于 Docker 项目的火爆，在 2013 年底，dotCloud 公司决定改名为 Docker。Docker 最初是在 Ubuntu 12.04 上开发实现的；Red Hat 则从 RHEL 6.5 开始对 Docker 进行支持；Google 也在其 PaaS 产品中广泛应用 Docker。 Docker 使用 Google 公司推出的 Go 语言 进行开发实现，基于 Linux 内核的 cgroup，namespace，以及 AUFS 类的 Union FS 等技术，对进程进行封装隔离，属于操作系统层面的虚拟化技术。由于隔离的进程独立于宿主和其它的隔离的进程，因此也称其为容 器。最初实现是基于 LXC，从 0.7 版本以后开始去除 LXC，转而使用自行开发的 libcontainer，从 1.11 开始，则进一步演进为使用 runC 和 containerd。 Docker 的作用Docker 带来了行业的变革。首先是解决了云平台之间标准规范不统一，无法相互兼容对接的问题，有了 Docker 屏蔽了硬件层的差异，提供了统一的用户应用层；其次推进了软件开发的流程，各个部门采用相同的数据镜像之后可以将精力进一步集中在产品本身；也简化了软件运行生命周期中软件的日志管理和监控管理，因为 Docker 拥有统一的数据规范和接口规范，不需要对每一款产品进行定制化开发。 具体来说 Docker 的作用归纳为以下几点： 简化配置。将运行环境和配置放在代码中然后部署，同一个Docker的配置可以在不同的环境中使用，这样就降低了硬件要求和应用环境之间耦合度； 提供一次性的环境。通过作用一可以做到本地测试他人的软件、持续集成的时候提供单元测试和构建的环境； 代码流水线管理（Code Pipeline）。通过作用一，Docker给应用提供了一个从开发到上线均一致的环境，让代码的流水线变得简单不少； 快速部署。在虚拟机之前，引入新的硬件资源需要消耗几天的时间。虚拟化技术（Virtualization）将这个时间缩短到了分钟级别。Docker通过为进程创建一个容器而无需启动一个操作系统，将这个过程缩短到了秒级； 调试能力。Docker提供了很多的工具，包括可以为容器设置检查点、设置版本和查看两个容器之间的差别，这些特性可以帮助调试Bug； 隔离应用，组建微服务架构。通过多个容器，一台机器可以跑多个服务，因此在本机就可以模拟出微服务架构； 提供弹性的云服务。因为 Docker 容器可以随开随关，很适合动态扩容和缩容。 Docker 三个基本概念镜像相比于传统的虚拟化中的 ISO 镜像，Docker 镜像要轻量化很多，它只是一个可定制的 rootfs。用户可以使用其他人创建的镜像，也可以通过 docker commit 这样的命令自己来创建镜像。 Docker 镜像是通过 Dockerfile 来创建，除了提供容器运行时所需的程序、库、资源、配置等文 件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。镜像不包含任何动态数据，其内容在构建之后也不会被改变。 镜像基于联合文件系统的一种层式结构。镜像构建时，会一层层构建，前一层是后一层的基础。每一层构建完就不会再发生改变，后 一层上的任何改变只发生在自己这一层。比如，删除前一层文件的操作，实际不是真的删除 前一层的文件，而是仅在当前层标记为该文件已删除。在最终容器运行的时候，虽然不会看 到这个文件，但是实际上该文件会一直跟随镜像。因此，在构建镜像的时候，需要额外小心，每一层尽量只包含该层需要添加的东西，任何额外的东西应该在该层构建结束前清理掉。 容器Docker 可以帮助我们构建和部署容器，只需要把应用程序或者服务打包放进容器即可，他们可以是 Web 服务器、数据库或者应用程序服务器等，docker 都用同样的方式将内容装载进容器中。我们就可以针对容器进行创建、启动、停止、删除、暂停等操作。 容器和镜像可以这样区别。镜像是 docker 生命周期中的构建和打包阶段，而容器则是启动和执行阶段。每个容器都包含一个软件镜像，而容器可以共享底层的只读镜像，通过写入自己特有的内容后添加新的镜像层，新增的镜像层和下层镜像一起又可以作为基础镜像被更上层的镜像使用。 容器的实质是进程，但与直接在宿主执行的进程不同，容器进程运行于属于自己的独立的命名空间。因此容器可以拥有自己的 root 文件系统、自己的网络配置、自己的进程空间，甚至自己的用户 ID 空间。容器内的进程是运行在一个隔离的环境里，使用起来就好像是在一 个独立于宿主的系统下操作一样。这种特性使得容器封装的应用比直接在宿主运行更加安 全。也因为这种隔离的特性，很多人初学 Docker 时常常会混淆容器和虚拟机。 按照 Docker 最佳实践的要求，容器不应该向其存储层内写入任何数据，容器存储层要保持无状态化。所有的文件写入操作，都应该使用数据卷（Volume）、或者绑定宿主目录，在这些位置的读写会跳过容器存储层，直接对宿主（或网络存储）发生读写，其性能和稳定性更高。 数据卷的生存周期独立于容器，容器消亡，数据卷不会消亡。因此，使用数据卷后，容器删除或者重新运行之后，数据却不会丢失。 仓库Docker Registry 用于存储和分发用户构建的镜像，可以分成公有私有两种。将镜像存储在仓库之中，就可以在其他服务器上使用这些镜像。 一个 Docker Registry 中可以包含多个仓库（ （ Tag ）；每个标签对应一个镜像。Repository）；每个仓库可以包含多个标签通常，一个仓库会包含同一个软件不同版本的镜像，而标签就常用于对应该软件的各个版 本。我们可以通过 &lt;仓库名&gt;:&lt;标签&gt; 的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签，将以 latest 作为默认标签。 国外的仓库镜像官方、默认、高质量镜像 CoreOS 的 Quay.io Google 的镜像，Kubernetes 的镜像即此 国内的仓库镜像阿里云加速器 DaoCloud 加速器 时速云镜像仓库 网易镜像仓库 DaoCloud 镜像市场 阿里云镜像库 参考资料《Docker全攻略》《第一本Docker书》《Docker技术入门与实战》《Docker进阶与实战》Docker 入门教程八个Docker的真实应用场景","link":"/post/2a772a2b.html"},{"title":"如何使用Anaconda","text":"Anaconda 能让你轻松安装在数据科学工作中经常使用的包。你还将使用它创建虚拟环境，以便更轻松地处理多个项目。Anaconda 简化了我的工作流程，并且解决了我在处理包和多个 Python 版本时遇到的大量问题。 Anaconda 实际上是一个软件发行版，它附带了 conda、Python 和 150 多个科学包及其依赖项。应用程序 conda 是包和环境管理器。Anaconda 的下载文件比较大（约 500 MB），因为它附带了 Python 中最常用的数据科学包。 conda 是一种只能通过命令行来使用的程序。conda 与 pip 相似，不同之处是可用的包以数据科学包为主，而 pip 适合一般用途。但是，conda 并非像 pip 那样专门适用于 Python，它也可以安装非 Python 的包。它是适用于任何软件堆栈的包管理器。也就是说，并非所有的 Python 库都能通过 Anaconda 发行版和 conda 获得。在使用 conda 的同时，你仍可以并且仍将使用 pip 来安装包。 Conda 安装了预编译的包。例如，Anaconda 发行版附带了使用 MKL 库编译的 Numpy、Scipy 和 Scikit-learn，从而加快了各种数学运算的速度。这些包由发行版的贡献者维护，这意味着它们通常滞后于新版本。但是，由于有人需要为许多系统构建这些包，因此，它们往往更为稳定，而且更便于你使用。 除了管理包之外，conda 还是虚拟环境管理器。它类似于另外两个很流行的环境管理器，即 virtualenv 和 pyenv。 环境能让你分隔你要用于不同项目的包。你常常要使用依赖于某个库的不同版本的代码。例如，你的代码可能使用了 Numpy 中的新功能，或者使用了已删除的旧功能。实际上，不可能同时安装两个 Numpy 版本。你要做的应该是，为每个 Numpy 版本创建一个环境，然后在适用于项目的环境中工作。 安装 AnacondaAnaconda 可用于 Windows、Mac OS X 和 Linux。可以在 https://docs.anaconda.com/anaconda/install/ 上找到安装程序和安装说明。 此外，和我一样使用 Ubuntu 的朋友参考这两篇优秀的文章：How To Install the Anaconda Python Distribution on Ubuntu 16.04 和 How to Install Anaconda on Ubuntu 18.04。 完成安装后，会自动进入默认的 conda 环境，而且所有包均已安装完毕，如下面所示。可以在终端或命令提示符中键入 conda list，以查看你安装的内容。 初次安装下的软件包版本一般都比较老旧，因此提前更新可以避免未来不必要的问题，初次安装可以键入以下命令更新所有的软件包： conda upgrade –all Anaconda 可以使用命令行的方式使用，也可以使用 GUI，下面将介绍用命令行的方式使用。 conda 切换为国内源1234567conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/main/conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/free/conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/conda-forge/conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/msys2/conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/bioconda/conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/menpo/conda config --set show_channel_urls yes 123456channels: - https://mirrors.ustc.edu.cn/anaconda/pkgs/main/ - https://mirrors.ustc.edu.cn/anaconda/cloud/conda-forge/ - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ - defaultsshow_channel_urls: true 关于停止Anaconda镜像服务的通知。 管理包安装了 Anaconda 之后，管理包是相当简单的。要安装包，请在终端中键入 conda install package_name。例如，要安装 numpy，请键入 conda install numpy。 你还可以同时安装多个包。类似 conda install numpy scipy pandas 的命令会同时安装所有这些包。还可以通过添加版本号（例如 conda install numpy=1.10）来指定所需的包版本。 Conda 还会自动为你安装依赖项。例如，scipy 依赖于 numpy，因为它使用并需要 numpy。如果你只安装 scipy (conda install scipy)，则 conda 还会安装 numpy（如果尚未安装的话）。 大多数命令都是很直观的。要卸载包，请使用 conda remove package_name。要更新包，请使用 conda update package_name。如果想更新环境中的所有包（这样做常常很有用），请使用 conda update --all。最后，要列出已安装的包，请使用前面提过的 conda list。 如果不知道要找的包的确切名称，可以尝试使用 conda search search_term 进行搜索。例如，我知道我想安装 Beautiful Soup，但我不清楚确切的包名称。因此，我尝试执行 conda search beautifulsoup。 它返回可用的 Beautiful Soup 包的列表，并列出了相应的包名称 beautifulsoup4。 管理环境列出环境可以使用 conda env list 列出你创建的所有环境。你会看到环境的列表，而且你当前所在环境的旁边会有一个星号。默认的环境名为 root。 创建环境如前所述，conda 是虚拟环境管理器，可以使用 conda 创建环境以隔离项目。 要创建环境，请在终端中使用 conda create -n env_name list of packages。在这里，-n env_name 设置环境的名称（-n 是指名称），而 list of packages 是要安装在环境中的包的列表。例如，要创建名为 my_env 的环境并在其中安装 numpy，请键入 conda create -n my_env numpy。 创建环境时，可以指定要安装在环境中的 Python 版本。这在你同时使用 Python 2.x 和 Python 3.x 中的代码时很有用。要创建具有特定 Python 版本的环境，请键入类似于 conda create -n py3 python=3 或 conda create -n py2 python=2 的命令。实际上，我在我的个人计算机上创建了这两个环境。我将它们用作与任何特定项目均无关的通用环境，以处理普通的工作（可轻松使用每个 Python 版本）。这些命令将分别安装 Python 3 和 2 的最新版本。要安装特定版本（例如 Python 3.3），请使用 conda create -n py python=3.3。 进入环境创建了环境后，在 OSX/Linux 上使用 source activate my_env 进入环境。在 Windows 上，请使用 activate my_env。 进入环境后，你会在终端提示符中看到环境名称，它类似于 (my_env) ~ $。环境中只安装了几个默认的包，以及你在创建它时安装的包。可以使用 conda list 检查这一点。在环境中安装包的命令与前面一样：conda install package_name。不过，这次你安装的特定包仅在你进入环境后才可用。要离开环境，请键入 source deactivate（在 OSX/Linux 上）。在 Windows 上，请使用 deactivate。 保存和加载环境共享环境这项功能确实很有用，它能让其他人安装你的代码中使用的所有包，并确保这些包的版本正确。可以使用 conda env export &gt; environment.yaml 将包保存为 YAML。第一部分 conda env export 输出环境中的所有包的名称（包括 Python 版本）。 上图可以看到列出了环境的名称和所有依赖项及其版本。导出命令的第二部分 &gt; environment.yaml 将导出的文本写入到 YAML 文件 environment.yaml 中。现在可以共享此文件，而且其他人能够创建和你用于项目相同的环境。 要通过环境文件创建环境，请使用 conda env create -f environment.yaml。这会创建一个新环境，而且它具有在 environment.yaml 中列出的同样的库。 删除环境如果你不再使用某些环境，可以使用 conda env remove -n env_name 删除指定的环境（在这里名为 env_name）。 最佳实践使用环境对我帮助很大的一点是，我的 Python 2 和 Python 3 具有独立的环境。我使用了 conda create -n py2 python=2 和 conda create -n py3 python=3 创建两个独立的环境，即 py2 和 py3。现在，我的每个 Python 版本都有一个通用环境。在所有这些环境中，我都安装了大多数标准的数据科学包（numpy、scipy、pandas 等）。 我还发现，为我从事的每个项目创建环境很有用。这对于与数据不相关的项目（例如使用 Flask 开发的 Web 应用）也很有用 共享环境在 GitHub 上共享代码时，最好同样创建环境文件并将其包括在代码库中。这能让其他人更轻松地安装你的代码的所有依赖项。对于不使用 conda 的人，我通常还会使用 pip freeze（在此处了解详情）将一个 pip requirements.txt 文件包括在内。 了解更多信息要详细了解 conda 和它如何融入到 Python 生态系统中，请查看这篇由 Jake Vanderplas 撰写的文章：Conda myths and misconceptions（有关 conda 的迷思和误解）。此外，有空也可以参考这篇 conda 文档。","link":"/post/9d29b615.html"},{"title":"如何使用Jupyter notebook","text":"Notebook 已迅速成为处理数据的必备工具。其已知用途包括数据清理和探索、可视化、机器学习和大数据分析。GitHub 上面也会自动提供 notebook。借助此出色的功能，你可以轻松共享工作。http://nbviewer.jupyter.org/ 也会提供 GitHub 代码库中的 notebook 或存储在其他地方的 notebook。 Notebook 运行的核心是 notebook 服务器。你通过浏览器连接到该服务器，而 notebook 呈现为 Web 应用。你在 Web 应用中编写的代码通过该服务器发送给内核。内核运行代码并将代码发送回该服务器，之后，任何输出都会返回到浏览器中。保存 notebook 时，它作为 JSON 文件（文件扩展名为 .ipynb）写入到该服务器中。 使用 Jupyter notebook安装 notebook安装 Jupyter 的最简单方法是使用 Anaconda。该发行版自动附带了 Jupyter notebook。你能够在默认环境下使用 notebook。 要在 conda 环境中安装 Jupyter notebook，请使用 conda install jupyter notebook。 也可以通过 pip 使用 pip install jupyter notebook 来获得 Jupyter notebook。 查看如何使用Anaconda了解如何使用Anaconda。 启动 notebook 服务器要启动 notebook 服务器，请在终端或控制台中输入 jupyter notebook。服务器会在你运行此命令的目录中启动。这意味着任何 notebook 文件都会保存在该目录中。你通常希望在 notebook 所在的目录中启动服务器。不过，你可以在文件系统中导航到 notebook 所在的位置。 运行此命令时（请自己试一下！），服务器主页会在浏览器中打开。默认情况下，notebook 服务器的运行地址是 http://localhost:8888。如果启动其他服务器，新服务器会尝试使用端口 8888，但由于此端口已被占用，因此新服务器会在端口 8889 上运行。之后，可以通过 http://localhost:8889 连接到新服务器。每台额外的 notebook 服务器都会像这样增大端口号。 在右侧，你可以点击“New”（新建），创建新的 notebook、文本文件、文件夹或终端。“Notebooks”下的列表显示了你已安装的内核。由于我在 Python 3 环境中运行服务器，因此列出了 Python 3 内核。 顶部的选项卡是 Files（文件）、Running（运行）和 Cluster（聚类）。Files（文件）显示当前目录中的所有文件和文件夹。点击 Running（运行）选项卡会列出所有正在运行的 notebook。可以在该选项卡中管理这些 notebook。 关闭 notebook通过在服务器主页上选中 notebook 旁边的复选框，然后点击“Shutdown”（关闭），你可以关闭各个 notebook。但是，在这样做之前，请确保你保存了工作！否则，在你上次保存后所做的任何更改都会丢失。下次运行 notebook 时，你还需要重新运行代码。 通过在终端中按两次 Ctrl + C，可以关闭整个服务器。再次提醒，这会立即关闭所有运行中的 notebook，因此，请确保你保存了工作！ 远程运行 notebook如果你想在本地或者远程的机器上安装Jupyter Notebook，可以参考下面的两个文档。 安装：https://jupyter.org/install.html 运行：https://jupyter.readthedocs.io/en/latest/running.html#running 后台运行使用 jupyter notebook --allow-root &gt; jupyter.log 2&gt;&amp;1 &amp;或者 nohup jupyter notebook --allow-root &gt; jupyter.log 2&gt;&amp;1 &amp;。 用&amp;让命令后台运行, 并把标准输出写入 jupyter.log 中。nohup表示no hang up, 就是不挂起, 于是这个命令执行后即使终端退出, 也不会停止运行. Notebook 界面Cell新建的一个 notebook 之后，默认就会有一个 cell，也就是下图中蓝色的小框。 Cell 可以称为单元格。单元格是你编写和运行代码的地方。 工具栏从左侧开始，工具栏上的其他控件是： 落伍的软盘符号，表示“保存”。请记得保存 notebook！ + 按钮用于创建新的单元格 然后是用于剪切、复制和粘贴单元格的按钮。 运行、停止、重新启动内核 单元格类型：代码、Markdown、原始文本和标题 命令面板（见下文） 单元格工具栏，提供不同的单元格选项（例如将单元格用作幻灯片） 命令面板小键盘符号代表命令面板。点击它会弹出一个带有搜索栏的面板，供你搜索不同的命令。这能切实帮助你加快工作速度，因为你无需使用鼠标翻查各个菜单。你只需打开命令面板，然后键入要执行的操作。 生成目录 conda install -c conda-forge jupyter_contrib_nbextensions 在 Nbexyensions 选项卡中开启 Table of Contents(2) 选项，即可在侧边栏生成目录。 快捷键Notebook 提供了许多快捷键，我们可以使用shift + command + P呼出命令行面板，在输入keyboard就可以查看快捷键列表。 键入Esc进入命令模式，即可使用这些快捷键。 Magic 关键字Magic 关键字是可以在单元格中运行的特殊命令，能让你控制 notebook 本身或执行系统调用（例如更改目录）。例如，可以使用 %matplotlib 将 matplotlib 设置为以交互方式在 notebook 中工作。 Magic 命令的前面带有一个或两个百分号（% 或 %%），分别对应行 Magic 命令和单元格 Magic 命令。行 Magic 命令仅应用于编写 Magic 命令时所在的行，而单元格 Magic 命令应用于整个单元格。 注意：这些 Magic 关键字是特定于普通 Python 内核的关键字。如果使用其他内核，这些关键字很有可能无效。 代码计时有时候，你可能要花些精力优化代码，让代码运行得更快。在此优化过程中，必须对代码的运行速度进行计时。可以使用 Magic 命令 timeit 测算单元格中代买运行时间和函数的运行时间。 测试整个单元格代码运行时间的时候可以添加%%timeit 1234%%timeitsum = 0for i in range(100): sum += i就会输出 13.97 µs ± 150 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each) 测试整个某个函数代码运行时间的时候可以添加%timeit 1234def sum(): sum = 0 for i in range(100): sum += i 1%timeit sum() 14.06 µs ± 180 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each) 在 notebook 中进行调试对于 Python 内核，可以使用 Magic 命令 %pdb 开启交互式调试器。出错时，你能检查当前命名空间中的变量。 要详细了解 pdb，请阅读此文档。要退出调试器，在提示符中输入 q 即可。 补充读物Magic 命令还有很多，我只是介绍了你将会用得最多的一些命令。要了解更多信息，请查看此列表，它列出了所有可用的 Magic 命令。 转换 notebookNotebook 只是扩展名为 .ipynb 的大型 JSON 文件。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485{ \"cells\": [ { \"cell_type\": \"code\", \"execution_count\": 8, \"metadata\": {}, \"outputs\": [ { \"name\": \"stdout\", \"output_type\": \"stream\", \"text\": [ \"3.97 µs ± 150 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\\n\" ] } ], \"source\": [ \"%%timeit\\n\", \"sum = 0\\n\", \"for i in range(100):\\n\", \" sum += i\" ] }, { \"cell_type\": \"code\", \"execution_count\": 9, \"metadata\": { \"collapsed\": true }, \"outputs\": [], \"source\": [ \"def sum():\\n\", \" sum = 0\\n\", \" for i in range(100):\\n\", \" sum += i\" ] }, { \"cell_type\": \"code\", \"execution_count\": 10, \"metadata\": {}, \"outputs\": [ { \"name\": \"stdout\", \"output_type\": \"stream\", \"text\": [ \"4.06 µs ± 180 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\\n\" ] } ], \"source\": [ \"%timeit sum()\" ] }, { \"cell_type\": \"code\", \"execution_count\": null, \"metadata\": { \"collapsed\": true }, \"outputs\": [], \"source\": [] } ], \"metadata\": { \"kernelspec\": { \"display_name\": \"Python 3\", \"language\": \"python\", \"name\": \"python3\" }, \"language_info\": { \"codemirror_mode\": { \"name\": \"ipython\", \"version\": 3 }, \"file_extension\": \".py\", \"mimetype\": \"text/x-python\", \"name\": \"python\", \"nbconvert_exporter\": \"python\", \"pygments_lexer\": \"ipython3\", \"version\": \"3.6.5\" } }, \"nbformat\": 4, \"nbformat_minor\": 2} 由于 notebook 是 JSON 文件，因此，可以轻松将其转换为其他格式。Jupyter 附带了一个名为 nbconvert 的实用程序，可将 notebook 转换为 HTML、Markdown、幻灯片等格式。 例如，要将 notebook 转换为 HTML 文件，请在终端中使用 1jupyter nbconvert --to html notebook.ipynb 要将 notebook 与不使用 notebook 的其他人共享，转换为 HTML 很有用。而要在博客和其他接受 Markdown 格式化的文本编辑器中加入 notebook，Markdown 很合适。 像平常一样，要详细了解 nbconvert，请阅读相关文档。 更好地使用现在的技术趋势，则是彻底云端化了，例如Jupyter官方的Binder平台（介绍文 档：https://mybinder.readthedocs.io/en/latest/index.html）和Google提供的 Google Colab环境（介 绍：https://colab.research.google.com/notebooks/welcome.ipynb）。它们让Jupyter Notebook变得和石墨文档、Google Doc在线文档一样，在浏览器点开链接就能运行。 所以，现在当你用Binder打开一份GitHub上的Jupyter Notebook时，你不需要安装任何软件，直接在浏览器 打开一份代码，就能在云端运行。 比如这样一个GitHub文件。在Binder中，你只要输入其对应的GitHub Repository的名字或者URL，就能在 云端打开整个Repository，选择你需要的notebook。 另外，还有下面这些 Jupyter Notebook，可以作为实践的第一站。 第一个是Jupyter官方：https://mybinder.org/v2/gh/binder-examples/matplotlib-versions/mpl-v2.0/?filepath=matplotlib_versions_demo.ipynb 第二个是Google Research提供的Colab环境，尤其适合机器学习的实践应 用：https://colab.research.google.com/notebooks/basic_features_overview.ipynb","link":"/post/80ec4f16.html"},{"title":"FFMPEG使用说明","text":"通过Java调用FFMpeg命令的方式来对音视频进行处理（获取信息、截图等等）。 https://github.com/tonydeng/fmj 截图命令截取一张352x240尺寸大小，格式为jpg的图片1ffmpeg -i input_file -y -f image2 -t 0.001 -s 352x240 output.jpg 把视频的前30帧转换成一个Animated Gif1ffmpeg -i input_file -vframes 30 -y -f gif output.gif 在视频的第8.01秒出截取230x240的缩略图1ffmpeg -i input_file -y -f mjpeg -ss 8 -t 0.001 -s 320x240 output.jpg 每隔一秒截一张图1ffmpeg -i out.mp4 -f image2 -vf fps=fps=1 out%d.png 每隔20秒截一张图1ffmpeg -i out.mp4 -f image2 -vf fps=fps=1/20 out%d.png 多张截图合并到一个文件里（2x3）每隔一千帧(秒数=1000/fps25)即40s截一张图1ffmpeg -i out.mp4 -frames 3 -vf &quot;select=not(mod(n\\,1000)),scale=320:240,tile=2x3&quot; out.png 从视频中生成GIF图片1ffmpeg -i out.mp4 -t 10 -pix_fmt rgb24 out.gif 转换视频为图片（每帧一张图）1ffmpeg -i out.mp4 out%4d.png 图片转换为视频1ffmpeg -f image2 -i out%4d.png -r 25 video.mp4 切分视频并生成M3U8文件1ffmpeg -i input.mp4 -c:v libx264 -c:a aac -strict -2 -f hls -hls_time 20 -hls_list_size 0 -hls_wrap 0 output.m3u8 相关参数说明： 12345678-i 输入视频文件-c:v 输出视频格式-c:a 输出音频格式-strict-f hls 输出视频为HTTP Live Stream（M3U8）-hls_time 设置每片的长度，默认为2，单位为秒-hls_list_size 设置播放列表保存的最多条目，设置为0会保存所有信息，默认为5-hls_wrap 设置多少片之后开始覆盖，如果设置为0则不会覆盖，默认值为0。这个选项能够避免在磁盘上存储过多的片，而且能够限制写入磁盘的最多片的数量。 注意，播放列表的sequence number对每个segment来说都必须是唯一的，而且它不能和片的文件名（当使用wrap选项时，文件名可能会重复使用）混淆。 分离视频音频流12345# 分离视频流ffmpeg -i input_file -vcodec copy -an output_file_video# 分离音频流ffmpeg -i input_file -acodec copy -vn output_file_audio 视频解复用12ffmpeg -i test.mp4 -vcoder copy -an -f m4v test.264ffmpeg -i test.avi -vcoder copy -an -f m4v test.264 视频转码12345678# 转码为码流原始文件ffmpeg -i test.mp4 -vcoder h264 -s 352*278 -an -f m4v test.264# 转码为码流原始文件ffmpeg -i test.mp4 -vcoder h264 -bf 0 -g 25 -s 352-278 -an -f m4v test.264# 转码为封装文件 -bf B帧数目控制, -g 关键帧间隔控制, -s 分辨率控制ffmpeg -i test.avi -vcoder mpeg4 -vtag xvid -qsame test_xvid.avi 视频封装1ffmpeg -i video_file -i audio_file -vcoder copy -acodec copy output_file 视频剪切12345# 视频截图ffmpeg -i test.avi -r 1 -f image2 image.jpeg# 剪切视频 -r 提取图像频率， -ss 开始时间， -t 持续时间ffmpeg -i input.avi -ss 0:1:30 -t 0:0:20 -vcoder copy -acoder copy output.avi 视频录制1ffmpeg -i rtsp://hostname/test -vcoder copy out.avi YUV序列播放1ffplay -f rawvideo -video_size 1920x1080 input.yuv YUV序列转AVI1ffmpeg -s w*h -pix_fmt yuv420p -i input.yuv -vcoder mpeg4 output.avi 常用参数说明主要参数123-i 设定输入流-f 设定输出格式-ss 开始时间 视频参数12345-b 设定视频流量，默认是200Kbit/s-s 设定画面的宽和高-aspect 设定画面的比例-vn 不处理视频-vcoder 设定视频的编码器，未设定时则使用与输入流相同的编解码器 音频参数1234-ar 设定采样率-ac 设定声音的Channel数-acodec 设定沈阳的Channel数-an 不处理音频 使用ffmpeg合并MP4文件12345ffmpeg -i \"Apache Sqoop Tutorial Part 1.mp4\" -c copy -bsf:v h264_mp4toannexb -f mpegts intermediate1.tsffmpeg -i \"Apache Sqoop Tutorial Part 2.mp4\" -c copy -bsf:v h264_mp4toannexb -f mpegts intermediate2.tsffmpeg -i \"Apache Sqoop Tutorial Part 3.mp4\" -c copy -bsf:v h264_mp4toannexb -f mpegts intermediate3.tsffmpeg -i \"Apache Sqoop Tutorial Part 4.mp4\" -c copy -bsf:v h264_mp4toannexb -f mpegts intermediate4.tsffmpeg -i \"concat:intermediate1.ts|intermediate2.ts|intermediate3.ts|intermediate4.ts\" -c copy -bsf:a aac_adtstoasc \"Apache Sqoop Tutorial.mp4\" 使用ffmpeg转换flv到mp41ffmpeg -i out.flv -vcodec copy -acodec copy out.mp4 视频添加水印水印局中1ffmpeg -i out.mp4 -i sxyx2008@163.com.gif -filter_complex overlay=\"(main_w/2)-(overlay_w/2):(main_h/2)-(overlay_h)/2\" output.mp4 参数解释 -i out.mp4(视频源) -i sxyx2008@163.com.gif(水印图片) overlay 水印的位置 output.mp4 输出文件 视频翻转和旋转翻转水平翻转语法: -vf hflip1ffplay -i out.mp4 -vf hflip 垂直翻转语法：-vf vflip1ffplay -i out.mp4 -vf vflip 旋转语法：transpose={0,1,2,3} 0:逆时针旋转90°然后垂直翻转 1:顺时针旋转90° 2:逆时针旋转90° 3:顺时针旋转90°然后水平翻转 将视频顺时针旋转90度1ffplay -i out.mp4 -vf transpose=1 将视频水平翻转(左右翻转)1ffplay -i out.mp4 -vf hflip 顺时针旋转90度并水平翻转1ffplay -i out.mp4 -vf transpose=1,hflip 添加字幕有的时候你需要给视频加一个字幕(subtitle)，使用ffmpeg也可以做。一般我们见到的字幕以srt字幕为主，在ffmpeg里需要首先将srt字幕转化为ass字幕，然后就可以集成到视频中了(不是单独的字幕流，而是直接改写视频流)。 12ffmpeg -i my_subtitle.srt my_subtitle.assffmpeg -i inputfile.mp4 -vf ass=my_subtitle.ass outputfile.mp4 但是值得注意的是： my_subtitle.srt需要使用UTF8编码，老外不会注意到这一点，但是中文这是必须要考虑的； 将字幕直接写入视频流需要将每个字符渲染到画面上，因此有一个字体的问题，在ass文件中会指定一个缺省字体，例如Arial，但是我们首先需要让ffmpeg能找到字体文件，不然文字的渲染就无从谈起了。ffmpeg使用了fontconfig来设置字体配置。你需要首先设置一下FONTCONFIG_PATH或者FONTCONFIG_FILE环境变量，不然fontconfig是无法找到配置文件的，这一点请参看这篇文章，如果你设置的是FONTCONFIG_PATH，那把配置文件保存为%FONTCONFIG_PATH%/font.conf即可，然后你可以在font.conf文件中配置字体文件的路径之类的。 Windows下为fontconfig设置如下的环境变量 1234FC_CONFIG_DIR=C:\\ffmpegFONTCONFIG_FILE=font.confFONTCONFIG_PATH=C:\\ffmpegPATH=C:\\ffmpeg\\bin;%PATH% 下面是一个简单的Windows版font.conf文件。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162&lt;?xml version=\"1.0\"?&gt;&lt;fontconfig&gt;&lt;dir&gt;C:\\WINDOWS\\Fonts&lt;/dir&gt;&lt;match target=\"pattern\"&gt; &lt;test qual=\"any\" name=\"family\"&gt;&lt;string&gt;mono&lt;/string&gt;&lt;/test&gt; &lt;edit name=\"family\" mode=\"assign\"&gt;&lt;string&gt;monospace&lt;/string&gt;&lt;/edit&gt;&lt;/match&gt;&lt;match target=\"pattern\"&gt; &lt;test qual=\"all\" name=\"family\" mode=\"not_eq\"&gt;&lt;string&gt;sans-serif&lt;/string&gt;&lt;/test&gt; &lt;test qual=\"all\" name=\"family\" mode=\"not_eq\"&gt;&lt;string&gt;serif&lt;/string&gt;&lt;/test&gt; &lt;test qual=\"all\" name=\"family\" mode=\"not_eq\"&gt;&lt;string&gt;monospace&lt;/string&gt;&lt;/test&gt; &lt;edit name=\"family\" mode=\"append_last\"&gt;&lt;string&gt;sans-serif&lt;/string&gt;&lt;/edit&gt;&lt;/match&gt;&lt;alias&gt; &lt;family&gt;Times&lt;/family&gt; &lt;prefer&gt;&lt;family&gt;Times New Roman&lt;/family&gt;&lt;/prefer&gt; &lt;default&gt;&lt;family&gt;serif&lt;/family&gt;&lt;/default&gt;&lt;/alias&gt;&lt;alias&gt; &lt;family&gt;Helvetica&lt;/family&gt; &lt;prefer&gt;&lt;family&gt;Arial&lt;/family&gt;&lt;/prefer&gt; &lt;default&gt;&lt;family&gt;sans&lt;/family&gt;&lt;/default&gt;&lt;/alias&gt;&lt;alias&gt; &lt;family&gt;Courier&lt;/family&gt; &lt;prefer&gt;&lt;family&gt;Courier New&lt;/family&gt;&lt;/prefer&gt; &lt;default&gt;&lt;family&gt;monospace&lt;/family&gt;&lt;/default&gt;&lt;/alias&gt;&lt;alias&gt; &lt;family&gt;serif&lt;/family&gt; &lt;prefer&gt;&lt;family&gt;Times New Roman&lt;/family&gt;&lt;/prefer&gt;&lt;/alias&gt;&lt;alias&gt; &lt;family&gt;sans&lt;/family&gt; &lt;prefer&gt;&lt;family&gt;Arial&lt;/family&gt;&lt;/prefer&gt;&lt;/alias&gt;&lt;alias&gt; &lt;family&gt;monospace&lt;/family&gt; &lt;prefer&gt;&lt;family&gt;Andale Mono&lt;/family&gt;&lt;/prefer&gt;&lt;/alias&gt;&lt;match target=\"pattern\"&gt; &lt;test name=\"family\" mode=\"eq\"&gt; &lt;string&gt;Courier New&lt;/string&gt; &lt;/test&gt; &lt;edit name=\"family\" mode=\"prepend\"&gt; &lt;string&gt;monospace&lt;/string&gt; &lt;/edit&gt;&lt;/match&gt;&lt;match target=\"pattern\"&gt; &lt;test name=\"family\" mode=\"eq\"&gt; &lt;string&gt;Courier&lt;/string&gt; &lt;/test&gt; &lt;edit name=\"family\" mode=\"prepend\"&gt; &lt;string&gt;monospace&lt;/string&gt; &lt;/edit&gt;&lt;/match&gt;&lt;/fontconfig&gt; 下面这个是Linux系统下改版过来的 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071&lt;?xml version=\"1.0\"?&gt;&lt;!DOCTYPE fontconfig SYSTEM \"fonts.dtd\"&gt;&lt;!-- /etc/fonts/fonts.conf file to configure system font access --&gt;&lt;fontconfig&gt;&lt;!-- Find fonts in these directories--&gt;&lt;dir&gt;C:/Windows/Fonts&lt;/dir&gt;&lt;!--&lt;dir&gt;/usr/X11R6/lib/X11/fonts&lt;/dir&gt;--&gt;&lt;!-- Accept deprecated 'mono' alias, replacing it with 'monospace'--&gt;&lt;match target=\"pattern\"&gt; &lt;test qual=\"any\" name=\"family\"&gt;&lt;string&gt;mono&lt;/string&gt;&lt;/test&gt; &lt;edit name=\"family\" mode=\"assign\"&gt;&lt;string&gt;monospace&lt;/string&gt;&lt;/edit&gt;&lt;/match&gt;&lt;!-- Load per-user customization file, but don't complain if it doesn't exist--&gt;&lt;include ignore_missing=\"yes\" prefix=\"xdg\"&gt;fontconfig/fonts.conf&lt;/include&gt;&lt;!-- Load local customization files, but don't complain if there aren't any--&gt;&lt;include ignore_missing=\"yes\"&gt;conf.d&lt;/include&gt;&lt;include ignore_missing=\"yes\"&gt;local.conf&lt;/include&gt;&lt;!-- Alias well known font names to available TrueType fonts. These substitute TrueType faces for similar Type1 faces to improve screen appearance.--&gt;&lt;alias&gt; &lt;family&gt;Times&lt;/family&gt; &lt;prefer&gt;&lt;family&gt;Times New Roman&lt;/family&gt;&lt;/prefer&gt; &lt;default&gt;&lt;family&gt;serif&lt;/family&gt;&lt;/default&gt;&lt;/alias&gt;&lt;alias&gt; &lt;family&gt;Helvetica&lt;/family&gt; &lt;prefer&gt;&lt;family&gt;Arial&lt;/family&gt;&lt;/prefer&gt; &lt;default&gt;&lt;family&gt;sans&lt;/family&gt;&lt;/default&gt;&lt;/alias&gt;&lt;alias&gt; &lt;family&gt;Courier&lt;/family&gt; &lt;prefer&gt;&lt;family&gt;Courier New&lt;/family&gt;&lt;/prefer&gt; &lt;default&gt;&lt;family&gt;monospace&lt;/family&gt;&lt;/default&gt;&lt;/alias&gt;&lt;!-- Provide required aliases for standard names Do these after the users configuration file so that any aliases there are used preferentially--&gt;&lt;alias&gt; &lt;family&gt;serif&lt;/family&gt; &lt;prefer&gt;&lt;family&gt;Times New Roman&lt;/family&gt;&lt;/prefer&gt;&lt;/alias&gt;&lt;alias&gt; &lt;family&gt;sans&lt;/family&gt; &lt;prefer&gt;&lt;family&gt;Arial&lt;/family&gt;&lt;/prefer&gt;&lt;/alias&gt;&lt;alias&gt; &lt;family&gt;monospace&lt;/family&gt; &lt;prefer&gt;&lt;family&gt;Andale Mono&lt;/family&gt;&lt;/prefer&gt;&lt;/alias&gt;&lt;/fontconfig&gt; 参考： http://blog.raphaelzhang.com/2013/04/video-streaming-and-ffmpeg-transcoding/ 嵌入字幕在一个MP4文件里面添加字幕，不是把 .srt 字幕文件集成到 MP4 文件里，而是在播放器里选择字幕，这种集成字幕比较简单，速度也相当快 1ffmpeg -i input.mp4 -i subtitles.srt -c:s mov_text -c:v copy -c:a copy output.mp4 希望字幕直接显示出来，其实也不难 12ffmpeg -i subtitle.srt subtitle.assffmpeg -i input.mp4 -vf ass=subtitle.ass output.mp4 参考： http://blog.neten.de/posts/2013/10/06/use-ffmpeg-to-burn-subtitles-into-the-video/","link":"/post/20fed56f.html"},{"title":"图像处理——图像降噪","text":"数字图像在数字化和成像过程中会受到成像设备或外界环境的影响，受到干扰产生的图像叫做噪声图像。 按照噪声的引入方式分类，可以将噪声分成加性噪声和乘法性噪声。加性噪声的幅度与信号的幅度无关，是叠加在图像上的，比较容易去除。成性噪声的幅度与信号的幅度成正比，比较难去除。不过乘性噪声可以通过取对数的方式转化为加性噪声，实际上大部分去噪算法都会假设噪声为加性高斯白噪声。 按照噪声的性质分类，可以将噪声分成脉冲噪声(Impluse Noise))，椒盐噪声(Pepper-Salt noise)和⾼斯⽩噪声(Gaussian white noise)，莱斯噪声(Racian noise)等。 传统降噪算法根据降噪的原理不同可分为基于邻域像素特征的⽅法，基于频域变换的⽅法，和基于特定模型的⽅法。本文主要讲述基于邻域像素特征的方法，并用 OpenCV 实现相应算法。 基于邻域像素特征的⽅法，是通过分析在⼀定⼤⼩的窗口内，中⼼像素与其他相邻像素之间在灰度空间的直接联系，来获取新的中⼼像素值的⽅法，因此往往都会存在⼀个典型的输⼊参数，即滤波半径 r。此滤波半径可能被⽤于在该局部窗⼜内计算像素的相似性，也可能是⼀些⾼斯或拉普拉斯算⼦的计算窗口。在邻域滤波⽅法⾥⾯，最具有代表性的滤波⽅法有以下⼏种。 算数均值滤波 上图演示 6x6 的图片，采用边框补零的方式，与 3x3 的卷积核做步长为 1 的卷积操作。 原理：均值滤波用像素邻域的平均灰度来代替像素值，适用于脉冲噪声，因为脉冲噪声一般与周围像素的灰度级不相关，而且亮度高出其他像素很多。 缺点：均值滤波随着半径取值增大而变得越来越模糊，因为均值操作之后，噪声被分散到了周围像素点，但是噪声区域也不可避免地增大了。 解决：采用设定阈值的方式可以一定程度上避免这一问题。比较噪声和领域像素的灰度，只有当灰度差达到设定的阈值才判定为噪声。 实现：可以使用 OpenCV 中的 blur() 实现算数均值滤波的效果。 123456void cv::blur ( InputArray src, OutputArray dst, Size ksize, Point anchor = Point(-1,-1), int borderType = BORDER_DEFAULT ) src: 带有噪声的原图像，深度必须为 CV_8U, CV_16U, CV_16S, CV_32F or CV_64F 中的一种 dst: 去噪之后的图像，要求图像大小与噪声图像一样，可以使用 Mat::Clone 的方法实现 ksize: 卷积核的大小，比如说 Size(3, 3) 表示大小为 3x3 的矩阵 point: Point 类型的 anchor，采用默认值表示取卷积核的中心为锚点 borderType: 推断图像外包部像素的某种边界模式，一般用默认的即可 1cv::blur(src, meanFilter, cv::Size(6, 6)); 高斯滤波原理：用一个卷积核扫描图像中的每一个像素，确定领域内像素的加权平均灰度值去代替模板中心像素点的值。图像高斯模糊的过程就是图像与正态分布做卷积，正态分布也叫高斯分布，所以也叫高斯模糊技术。 优点：相比于均值滤波，高斯滤波矩阵的权值随着与中心像素点距离的增加呈现高斯衰减的特性，因此对距离算子越远的像素点作用越小，从⽽能在⼀定程度上保持图像的边缘特征。通过调节⾼斯平滑参数，可以在图像特征过分模糊和⽋平滑之间取得折中。 实现：可以使用 OpenCV 中的 GaussianBlur() 实现算数均值滤波的效果。 1234567void cv::GaussianBlur ( InputArray src, OutputArray dst, Size ksize, double sigmaX, double sigmaY = 0, int borderType = BORDER_DEFAULT ) src: 带有噪声的原图像，深度必须为 CV_8U, CV_16U, CV_16S, CV_32F or CV_64F 中的一种 dst: 去噪之后的图像，要求图像大小与噪声图像一样，可以使用 Mat::Clone 的方法实现 ksize: 高斯滤波矩阵的代销，ksize.width and ksize.height 可以不同，但必须为正数、奇数或零，它们是用过 signma 计算得到的。 sigmaX: 高斯核函数在 X 方向的标准偏差 sigmaY: 高斯核函数在 Y 方向的标准偏差。若 sigmaY 为 0 就将其设为 sigmaX；若 sigmaX 和 sigmaY 都为 0，则通过 ksize.width and ksize.height 计算得出。 borderType: 推断图像外包部像素的某种边界模式，一般用默认的即可 1cv::GaussianBlur(src, gaussianBlur, cv::Size(5, 5), 0, 0); 统计中值滤波原理：对窗口内的像素值进⾏排序，然后使⽤灰度值的中间值代替窗口中⼼位置像素的灰度，适⽤于椒盐噪声和脉冲噪声。 优点：中值滤波属于非线性滤波，当噪声是散粒噪声而不是高斯噪声时，即图像偶尔会出现很大的值时，用高斯滤波对图像进行模糊噪声像素不会被去除，而中值滤波⽐相同尺⼨的线性平滑滤波器引起的模糊更少，能较好的保持边缘。 缺点：中值滤波会使图像中的⼩⽬标丢失。当噪声像素个数⼤于窗口像素总数的⼀半时，由于灰度排序的中间值仍为噪声像素灰度值，会导致滤波效果很差，且中值滤波花费的时间是均值滤波的 5 倍以上。 实现：可以使用 OpenCV 中的 medianBlur() 实现中值滤波。 1234void cv::medianBlur ( InputArray src, OutputArray dst, int ksize) src: 带有噪声的原图像，深度必须为 CV_8U, CV_16U, CV_16S, CV_32F or CV_64F 中的一种 dst: 去噪之后的图像，要求图像大小与噪声图像一样，可以使用 Mat::Clone 的方法实现 ksize: aperture linear size，必须为大于 1 的奇数，比如：3、5、7、9…… 1cv::medianBlur(src, medianBlur, 3); 双边滤波原理：滤波器是由两个函数构成。⼀个函数是由⼏何空间距离决定滤波器系数，另⼀个由像素差值决定滤波器系数。双边滤波器中，输出像素的值依赖于邻域像素的值的加权组合，它同时考虑了空间域与值域的差别。 优点：可以做到边缘保存，在边缘附近，距离较远的像素不会对边缘上的像素造成太大影响。 缺点：由于保存了过多的高频信息，对于图像里的高频噪声，双边滤波器不能干净地过滤掉，只能对于低频信号进行较好的滤波。 实现：可以使用 OpenCV 中的 bilateralFilter() 实现双边滤波的效果。 1234567void cv::bilateralFilter ( InputArray src, OutputArray dst, int d, double sigmaColor, double sigmaSpace, int borderType = BORDER_DEFAULT ) src: 带有噪声的原图像，深度必须为 CV_8U, CV_16U, CV_16S, CV_32F or CV_64F 中的一种 dst: 去噪之后的图像，要求图像大小与噪声图像一样，可以使用 Mat::Clone 的方法实现 d: 表示在过滤过程中每个像素邻域的直径，如果这个值被设为非正数，那么 OpenCV 会从第 5 个参数 sigmaSpace 来计算出它 sigmaColor: 颜色空间滤波器 sigma 值，这个参数的值越大，就表名该像素邻域范围内有越宽广的颜色会被很合到一起，产生较大的半相等颜色区域 sigmaSpace: 做表空间中滤波器的 sigma 值，坐标空间的标注方差。它的数值越大，意味着越远的像素会相互影响，从而使更大的区域中足够相似的颜色获得相同的颜色。当 d&gt;0 时，d 指定了邻域大小且与 sigmaSpace 无关。否则，d 正比于 sigmaSpace。 borderType: 推断图像外包部像素的某种边界模式，一般用默认的即可 1cv::bilateralFilter(src,bilateralfilter,25,25*2,25/2); 代码与效果演示1234567891011121314151617181920212223242526272829303132333435363738/** * 使用 4 种空域滤波方法,对 noise 图进行降噪 * * 1. 算数均值滤波 * 2. 高斯滤波 * 3. 统计中值滤波 * 4. 双边滤波 * **/#include &lt;iostream&gt;#include \"opencv2/imgproc.hpp\"#include \"opencv2/highgui.hpp\"#include \"opencv2/imgcodecs.hpp\"int main(){ cv::Mat src = cv::imread(\"../images/noise.jpg\", cv::IMREAD_COLOR); cv::Mat meanFilter; cv::Mat medianBlur; cv::Mat gaussianBlur; cv::Mat bilateralfilter; cv::blur(src, meanFilter, cv::Size(6, 6)); cv::GaussianBlur(src, gaussianBlur, cv::Size(5, 5), 0, 0); cv::medianBlur(src, medianBlur, 3); cv::bilateralFilter(src,bilateralfilter,25,25*2,25/2); cv::imshow(\"1. src\", src); cv::imshow(\"2. meanFilter\", meanFilter); cv::imshow(\"3. gaussianBlur\", gaussianBlur); cv::imshow(\"4. medianBlur\", medianBlur); cv::imshow(\"5. bilateralfilter\", bilateralfilter); cv::waitKey(0); return 0;}","link":"/post/d966aba8.html"},{"title":"图像处理——边缘检测","text":"边缘检测是为了识别物体的边缘，而边缘是由数字图像中亮度变化明显的点连接而成的，主要可以通过基于图像强度的一阶和二阶导数来寻找到这些点。 边缘检测可以分成三个步骤： 滤波。由于导数对噪声敏感，所以在边缘检测之前可以先试着降低图片的噪声，常用的是高斯滤波。 增强。增强算法可以将图像灰度点邻域强度值有显著变化的点凸显出来，可以通过计算梯度幅值来确定。 检测。根据梯度幅值就可以检测出物体的边缘，由于经过图像增强，有些店并不是要找的边缘值，我们还可以通过阈值化的方式来筛选。 canny Canny边缘检测算子是澳洲计算机科学家约翰·坎尼（John F. Canny）于1986年开发出来的一个多级边缘检测算法。更为重要的是Canny创立了“边缘检测计算理论”（computational theory of edge detection）解释这项技术如何工作。 Canny的目标是找到一个最优的边缘检测算法，最优边缘检测的含义是： 好的检测 - 算法能够尽可能多地标识出图像中的实际边缘。 好的定位 - 标识出的边缘要与实际图像中的实际边缘尽可能接近。 最小响应 - 图像中的边缘只能标识一次，并且可能存在的图像噪声不应标识为边缘。 为了满足这些要求Canny使用了变分法，这是一种寻找满足特定功能的函数的方法。最优检测使用四个指数函数项的和表示，但是它非常近似于高斯函数的一阶导数。 —— 维基百科 我们可以使用 OpenCV 中的 Canny() 来做边缘检测。 1234567void cv::Canny ( InputArray image, OutputArray edges, double threshold1, double threshold2, int apertureSize = 3, bool L2gradient = false ) src: 源图像，8位即可 edges: 输出的边缘图，要求与源图像保持一样的尺寸和类型 threshold1: 第一个滞后性阈值 threshold2: 第二个滞后性阈值 apertureSize: 表示应该用 Sobel 算子的空间大小，默认为 3 L2gradient: 计算图像梯度幅值的标识，默认为 false 注：threshold1 和 threshold2 中较小的用于边缘连接，交大的用来控制强边缘的初始段，推荐的高低阈值比在 2:1 到 3:1 之间。 1234567891011121314151617181920212223242526272829#include &lt;iostream&gt;#include \"opencv2/highgui.hpp\"#include \"opencv2/imgcodecs.hpp\"#include \"opencv2/imgproc.hpp\"int main(){ cv::Mat src = cv::imread(\"../images/persimmon.jpg\", cv::IMREAD_COLOR); cv::Mat dst, edge, gray; // 【1】创建与src同类型和大小的矩阵(dst) dst.create(src.size(), src.type()); // 【2】将原图像转换为灰度图像 cv::cvtColor(src, gray, cv::COLOR_BGR2GRAY); // 【3】运行Canny算子 cv::Canny(gray, edge, 150, 50, 3); // 【4】显示效果图 cv::namedWindow(\"【原图】边缘检测\", cv::WINDOW_NORMAL); cv::namedWindow(\"【效果图】Canny边缘检测\", cv::WINDOW_NORMAL); imshow(\"【原图】边缘检测\", gray); imshow(\"【效果图】Canny边缘检测\", edge); cv::waitKey(0);} sobel 索伯算子(Sobel operator) 是图像处理中的算子之一，有时又称为索伯-费德曼算子或索贝滤波器，在影像处理及电脑视觉领域中常被用来做边缘检测。索伯算子最早是由美国计算机科学家艾尔文·索伯（Irwin Sobel）及盖瑞·费德曼（Gary Feldman）于1968年在史丹佛大学的人工智能实验室(SAIL)所提出，因此为了表扬他们的贡献，才用他们的名字命名。在技术上，它是一离散性差分算子，用来运算图像亮度函数的梯度之近似值。在图像的任何一点使用此算子，索伯算子的运算将会产生对应的梯度向量或是其范数。概念上，索伯算子就是一个小且是整数的滤波器对整张影像在水平及垂直方向上做卷积，因此它所需的运算资源相对较少，另一方面，对于影像中的频率变化较高的地方，它所得的梯度之近似值也比较粗糙。 —— 维基百科 Sobel 函数使用扩展的 Sobel 算子来计算一阶、二阶、三阶或者混合图像的差分，来看一下 OpenCV 中的 Sobel()。 12345678910void cv::Sobel ( InputArray src, OutputArray dst, int ddepth, int dx, int dy, int ksize = 3, double scale = 1, double delta = 0, int borderType = BORDER_DEFAULT ) src: 源图像，Mat 类型 dst: 输出图像，尺寸和类型需要与 src 相同 ddepth: 输出图像深度，支持如下 src.depth() 和 ddepth 的组合 dx: x 方向上的差分阶数 dy: y 方向上的差分阶数 ksize: Sobel 卷积核的代销，默认值为 3，必须取 1、3、5 或 7 scale: 计算导数值时可选的缩放因子，默认值是 1，表示默认情况下是没有应用缩放的，更多可以查看文档 delta: 表示结果存入输出图像之前可选的 delta 值，默认为 0 borderType: 推断图像外包部像素的某种边界模式，一般用默认的即可 注： 当内核大小为 3 时，Sobel 内核可能产生比较明显的误差。为此 OpenCV 提供了结果更加精确的 Scharr() ，它仅作用于大小为 3 的卷积核，运行速度与 Sobel() 一样快，当结果更精确。 计算图像 X 方向导数是可以取 xorder = 1, uorder = 0, ksize = 3 计算图像 Y 方向导数是可以取 xorder = 0, uorder = 1, ksize = 3 123456789101112131415161718192021222324252627282930313233343536373839//---------------【边缘检测】----------------// 描述：sobel 函数用法示例//------------------------------------------#include &lt;opencv2/opencv.hpp&gt;#include &lt;opencv2/core/core.hpp&gt;#include &lt;opencv2/imgproc/imgproc.hpp&gt;using namespace cv;int main(){ //【0】创建 grad_x 和 grad_y 矩阵 Mat grad_x, grad_y; Mat abs_grad_x, abs_grad_y,dst; //【1】载入原始图 Mat src = imread(\"images/2.jpg\"); //工程目录下应该有一张名为1.jpg的素材图 //【2】显示原始图 imshow(\"【原始图】sobel边缘检测\", src); //【3】求 X方向梯度 Sobel( src, grad_x, CV_16S, 1, 0, 3, 1, 1, BORDER_DEFAULT ); convertScaleAbs( grad_x, abs_grad_x ); imshow(\"【效果图】 X方向Sobel\", abs_grad_x); //【4】求Y方向梯度 Sobel( src, grad_y, CV_16S, 0, 1, 3, 1, 1, BORDER_DEFAULT ); convertScaleAbs( grad_y, abs_grad_y ); imshow(\"【效果图】Y方向Sobel\", abs_grad_y); //【5】合并梯度(近似) addWeighted( abs_grad_x, 0.5, abs_grad_y, 0.5, 0, dst ); imshow(\"【效果图】整体方向Sobel\", dst); waitKey(0); return 0; } Laplacian 在数学以及物理中，拉普拉斯算子或是拉普拉斯算符（英语：Laplace operator, Laplacian）是由欧几里得空间中的一个函数的梯度的散度给出的微分算子，通常写成 、 或。 这名字是为了纪念法国数学家皮埃尔-西蒙·拉普拉斯（1749–1827）而命名的。他在研究天体力学在数学中首次应用算子，当它被施加到一个给定的重力位（Gravitational potential）的时候，其中所述算子给出的质量密度的常数倍。经拉普拉斯算子运算为零∆f=0的函数称为调和函数，现在称为拉普拉斯方程，和代表了在自由空间中的可能的重力场。 拉普拉斯算子有许多用途，此外也是椭圆算子中的一个重要例子。 拉普拉斯算子出现描述许多物理现象的微分方程里。例如，常用于波方程的数学模型、热传导方程、流体力学以及亥姆霍兹方程。在静电学中，拉普拉斯方程和泊松方程的应用随处可见。在量子力学中，其代表薛定谔方程中的动能项。 拉普拉斯算子是最简单的椭圆算子，并且拉普拉斯算子是霍奇理论的核心，并且是德拉姆上同调的结果。在图像处理和计算机视觉中，拉普拉斯算子已经被用于诸如斑点检测和边缘检测等的各种任务。 Laplacian 使用了图像梯度，它内部的代码调用了 Sobel 算子。让一幅图像减去它的 Laplacian 算子可以增强对比度。 123456789void cv::Laplacian ( InputArray src, OutputArray dst, int ddepth, int ksize = 1, double scale = 1, double delta = 0, int borderType = BORDER_DEFAULT ) src: 源图像，Mat 类型，需要为单通道 8 位图像 dst: 输出图像，尺寸和类型需要与 src 相同 ddepth: 输出图像深度 ksize: 用于计算二阶大数的滤波器的孔径尺寸，大小必须正奇数，默认值为 1 scale: 计算拉普拉斯值的时候可选的比例因子，默认值为 1 delta: 在结果存入输出图像全可选的 delta 值，默认值为 0 borderType: 推断图像外包部像素的某种边界模式，一般用默认的即可 注：Laplacian() 函数使用 sobel 运算，加上 sobel 算子运算出图像 dx 和 dy，来得到载入图像的拉普拉斯变换的结果。 12345678910111213141516171819202122232425262728293031323334//---------------【边缘检测】----------------// 描述：laplacian 函数用法示例//------------------------------------------#include &lt;opencv2/opencv.hpp&gt;#include &lt;opencv2/core/core.hpp&gt;#include &lt;opencv2/imgproc/imgproc.hpp&gt;int main(){ cv::Mat src, src_gray, dst, abs_dst; // 载入原图像 src = cv::imread(\"images/3.jpg\", cv::IMREAD_COLOR);; cv::imshow(\"【原图】\", src); // 使用高斯滤波降噪 cv::GaussianBlur(src, src, cv::Size(3, 3), 0, 0, cv::BORDER_DEFAULT); // 转换为灰度图 cv::cvtColor(src, src_gray, cv::COLOR_BGR2GRAY); // 使用 Laplacian 函数 cv::Laplacian(src_gray, dst, CV_16S, 3, 1, 0, cv::BORDER_DEFAULT); //【6】计算绝对值，并将结果转换成8位 convertScaleAbs( dst, abs_dst ); //【7】显示效果图 cv::imshow( \"【效果图】图像Laplace变换\", abs_dst ); cv::waitKey(0); return 0;}","link":"/post/1d0f563b.html"},{"title":"JVM-双亲委派模型","text":"本文介绍 Java 中的类加载器，以及双亲委派机制。 Java 中的类加载器包括：启动类加载器，扩展类加载器，应用程序类加载器，自定义类加载器。 启动类加载器启动类加载器(Bootstrap ClassLoader)，主要负责加载Java目录下的核心类，即 Java 安装目录下的 lib 目录，其中就包含 Java 最核心的一类类库。 JVM一旦启动会首先依托启动类加载器，去加载${JAVA_HOME}/lib中的核心类库。 扩展类加载器扩展类加载器(Extension ClassLoader)，它将会加载 ${JAVA_HOME}/lib/ext 目录中的类。 应用程序类加载器应该程序类加载器Application ClassLoader，负责去加载“ClassPath”环境变量所指定的路径中的类。 可以将其理解为我们写好的 Java 代码，应用程序类加载器负责将我们写的Java代码加载到内存中。 自定义类加载器自定义类加载器，可以根据自己的需求加载类。 双亲委派机制 JVM类加载器具有如上所示的亲子层级结构，启动加载器在第一层，扩展加载器在第二层，应用类加载器在第三层，自定义类加载器在最后一层。 基于该亲子层级结构，就有一个双亲委派机制，具体来说是怎么样的呢？ 具体来说，现在有一个Manager类，它是我们自己写的Java代码，需要使用应用程序类加载器来加载。 此时，应该程序类加载器会先问它的上一级扩展类加载器，你能加载到这个类么？然后扩展类加载器继续问它的上一级启动类加载器，你能加载到这个类么？ 启动类加载器在${JAVA_HOME}/lib下找不到Manage这个类，就告诉扩展类加载器，我加载不到，你自己找去。扩展类加载器在 ${JAVA_HOME}/lib/ext 下也没有找到这个类，叫告诉应用程序类加载器自己去加载这个类。 终于，应该用程序类加载器在自己负责的范围内，比如说我们打成的 jar 包中，找到了这个类，就将其加载到内存中。 总的来说，双亲委派模型就是：先找父亲去加载，父亲加载不到再由儿子来加载。这样的话，可以避免多层级的加载器结构重复加载某些类。","link":"/post/5b2f68e0.html"},{"title":"JVM-JVM中内存区域划分","text":"在JVM-Java中的类加载机制一文中，我讲述了 Java 类加载的过程，它包含加载、验证、准备、解析、初始化、使用、卸载这几个步骤。我们在准备阶段会将类加载到内存中，为类变量分配内存并赋予初值；在初始化阶段则会正式执行初始化代码。 那么在准备阶段和初始化阶段，JVM 具体是怎么为类分配内存的呢？ 什么是 JVM 中的内存区域划分当 JVM 运行我们的代码时，它会使用多块不同的内存，不同的内存存放不同的数据，再配合代码的执行流程，这样就能把程序运行起来了。 概括来讲 JVM 中的内存空间可以分成三大块： 存放加载的类。保存 JVM 加载的类。 运行方法使用。保存程序时我们要执行一个个方法，即方法中的局部变量。 创建的对象。保存运行程序时创建的对象。 JVM 中的内存区域划分JVM 的内存划分可以分成三大块：存放加载的类，存放创建的对象，运行方法时使用。如果进一步细分，可以分成这样几个主要区域：方法区、程序计数器、Java虚拟机栈和 Java堆。 如果存在 main() 函数，JVM 会从 main() 函数开始完成整个类加载过程，所以上面这段代码会从 main() 开始加载。JVM 进行会启动，先加载 Kafka.java 到内存中，然后有一个 main 进程开始执行 main() 方法： 方法区：会加载 Kafka 和 ReplicaManager 这两个类 字节码执行引擎：class 文件是一个个字节码，JVM 将会使用字节码执行引擎执行代码指令。 程序计数器：用程序计数器来标记代码指令执行到哪一行。 多线程：JVM是支持多线程的，可能开启多个线程来执行代码指令，每一个线程都有自己的程序计数器 Java虚拟机栈：保存方法内的局部变量等数据，线程每执行一个方法，就会对这个方法调用创建对应的一个栈帧 Java 堆内存：new 出来的实例对象将会保存在 Java 堆内存中，栈帧中的局部变量将会指向 Java 堆中的实例对象。","link":"/post/3860d841.html"},{"title":"JVM-Java中的类加载机制","text":"在正式了解 Java 类加载机制的细节之前，我们有必要了解一下 JVM 整体的运行原理，对 JVM 运行机制的整体脉络进行一次梳理。 首先我们会有一系列以 .java 结尾的源文件。要把这些源文件发布到线上，我们需要将其打成 jar 包，或者打成 war 包。这个打包的过程就是将 .java 文件编译成 .class 文件。接着就可以使用 Tomcat 这样的容器，或者 java 命令来运行一个 jar 包中的文件。 这里有一个问题，编译好的 .class 字节码是怎么运行起来的呢？ JVM 在什么情况下会加载一个类？JVM 会通过类加载器来加载一个类，然后将类保存到内存中，并执行代码。一个类从加载到使用，一般会经历下面这样一个过程： 那么什么时候 JVM 会使用类加载器去加载一个类呢？答案很简单，就是在使用这个类的时候。 举例来说，如果有下面这样一段代码 12345public class Application { public static void main(){ MyConfig config = new MyConfig(); }} Application 类中有一个 main() 函数，main() 作为程序的入口一定会在 JVM 进行启动之后被加载到内存中。之后开始执行 main() 中的方法，遇到别的类就将这个类加载到内存中，情况如图所示： 验证、准备和解析的过程 验证阶段：验证 .class 文件是否符合 Java 虚拟机规范。这点比较容易理解，就像我们使用数据之前要先校验一下。 准备阶段：给加载到的类分配内存空间，比如说 MyConfig 类中有类变量，就要给它分配内存空间，给一个初始值。 解析阶段：将符号引用替换为直接引用 验证、准备和解析可以合称为准备阶段。在准备阶段，JVM 为加载进来的类分配了内存空间，为类变量分配了内存空间，并给类变量赋了初值。接下来的初始化阶段，就会正式执行类初始化的代码了。 核心阶段：初始化前面说了，在准备阶段，JVM 会给类分配内存，会给类变量分配内存并赋予初值。在初始化阶段，则会正式执行类初始化代码。 什么叫正式执行初始化代码呢？来看下面这样一段代码 准备阶段会为类变量 flushInterval 分配内存空间，并且将其初值赋为 0。在初始化阶段，flushInterval 执行赋值语句，获取一个配置参数。 此外，初始化阶段还会执行静态代码块，本例中完成数据的加载工作。 什么时候会初始化一个类呢？ new 一个实例化的对象，将会出发类加载到初始化的全过程，将这个类准备好，再实例化一个对象处理 包含 main() 的主类，将会立即初始化 初始化一个类的时候，如果其父类还未初始化，就必须先初始化他的父类","link":"/post/5e4eb5a4.html"},{"title":"JVM-垃圾回收算法与垃圾回收器","text":"本文记录一些垃圾回收算法和垃圾回收器。 复制算法Serial垃圾回收器 Serial 垃圾回收器用于新生代的垃圾回收。无论服务器是几核的，都只用单线程执行垃圾回收算法。 ParNew 垃圾回收器 ParNew 垃圾回收器用于新生代的垃圾回收。ParNew 垃圾回收器可以使用多个垃圾回收线程来执行垃圾回收算法。在启动系统时，可以使用 -XX:+UseParNewGC 参数来指定使用 ParNew 垃圾回收器。 ParNew 垃圾回收器默认使用的线程数量与机器的核数相同，比如我们线上机器假设用的是4核CPU，那默认就会使用 4 个线程。 线程数也可以通过 -XX:ParallelGCThreads 手动指定，但是不建议修改。 选择单线程还是选择多线程？ 到底是用单线程垃圾回收好，还是多线程垃圾回收好？ 到底是Serial垃圾回收器好还是ParNew垃圾回收器好？ 启动系统的时候是可以区分服务器模式和客户端模式的，如果你启动系统的时候加入 -server 就是服务器模式，如果加入 -cilent 就是客户端模式。 如果部署的是网站系统、业务系统等大型系统，一般都是多核 CPU。此时使用多线程，使用 ParNew 垃圾回收器更好。 如果是 Windows 客户端程序，如果是单核 CPU 使用 ParNew 垃圾回收器就会在一个 CPU 上启动多个垃圾回收线程，会有上下文切换的开销，反而不如单线程 Serial 垃圾回收器效率高。 标记清理算法老年代一般选择的垃圾回收器是 CMS，采用标记清理算法。简单来说，标记清理算法分成两步：标记出哪些对象是垃圾对象，再一次性把这些对象清理掉。 举例来说，当程序触发了Full GC 回收老年代的垃圾对象。 先通过追踪 GC Roots 的方法，看老年代中的各个对象是不是被 GC Roots 引用，如果被引用就是存活对象，否则就是垃圾对象。这些垃圾对象就会被标记出来。 然后再一次性清理被标记出来的垃圾对象。 但是由于 Full GC 的时间比 Minor GC 的时间差不多长 10 倍，如果和 Minor GC 一样，Full GC 采用先 Stop the World 再用标记清理算法回收垃圾，就会导致系统卡死时间过长，很多响应无法处理。 所以 CMS 让系统一边工作，一边进行垃圾回收。CMS 垃圾回收的过程一共分为 4 个阶段： 初始标记。Stop the World 停止所有工作线程，仅标记 GC Roots 直接引用的对象。这一步速度很快。 并发标记。此时允许系统线程创建对象，继续运行。垃圾回收线程则会追踪老年代中的对象是否从根源上被 GC Roots 引用。这一步是最耗时的，但是和系统程序并发运行，不会对系统运行造成影响。 重新标记。Stop the World 重新标记在第二阶段里新创建的对象，以及原本被引用现在失去引用的对象。由于支队第二阶段有变动的对象进行标记，速度也比较快。 并发清理。系统随意运行，同时清理之前被标记为垃圾的对象。这个阶段很耗时，但是由于和系统程序并发运行，并不影响系统程序的运行。 CMS 垃圾回收器Serial Old 垃圾回收器在并发清理期间，系统程序可能将某些对象分配在新生代，然后触发了一次 Minor GC，一些对象进入了老年代，但是短时间内又没有人引用它们。这些对象就被称为浮动垃圾。 浮动垃圾意味着虽然他们是垃圾，但是 CMS 在并发清理阶段只会清理这一次 Full GC 被标记出来的垃圾，这些浮动垃圾只有等到下一次 GC 的时候才会回收它们。 为了保证在 CMS 并发清理期间，还有一定的内存空间让一些对象可以进入老年代，一般会预留一些空间。CMS垃圾回收的触发时机，其中有一个就是当老年代内存占用达到一定比例了，就自动执行GC。 -XX:CMSInitiatingOccupancyFaction 参数可以用来设置老年代占用多少比例的时候触发CMS垃圾回收，JDK 1.6里面默认的值是92%。 也就是说，老年代占用了92%空间了，就自动进行CMS垃圾回收，预留8%的空间给并发回收期间，系统程序把一些新对象放入老年代中。 那么如果CMS垃圾回收期间，系统程序要放入老年代的对象大于了可用内存空间，此时会如何？ 这个时候，会发生 Concurrent Mode Failure，就是说并发垃圾回收失败了，我一边回收，你一边把对象放入老年代，内存都不够了。 此时就会自动用Serial Old垃圾回收器替代CMS，就是直接强行把系统程序 Stop the World，重新进行长时间的GC Roots追踪，标记出来全部垃圾对象，不允许新的对象产生。然后一次性把垃圾对象都回收掉，完事儿了再恢复系统线程。 所以在生产实践中，这个自动触发CMS垃圾回收的比例需要合理优化一下，避免“Concurrent Mode Failure”问题 G1 垃圾回收器ParNew 和 CMS 两个垃圾回收器分别来回收新生代和老年代的垃圾对象，有一个最大的痛点就是 Stop the World。后面对于垃圾回收器的优化都是朝着减少 Stop the World 的目标去的。 在这基础上 G1 垃圾回收器应用而生，它可以提供比 ParNew + CMS 组合更好的垃圾回收性能。 主要设计思想：G1 将内存拆分成一个个小的 Regin，新生代和老生代各自对应一些 Regin，回收的时候间可能挑选停顿时间最短，回收对象最多的 Regin，尽量控制垃圾回收导致的系统停顿时间小于我们的预设值。 ReginG1 垃圾回收器只有逻辑上的新生代和老年代的概念，它会将 Java 堆内存划分成一个个相同大小的 Regin，如下图所示： G1 垃圾回收器中的 Regin 是不区分新生代和老年的，刚开始 Regin 可能不属于任何一个年代，每一个 Regin 这一刻保存新生代对象，下一刻可能就保存老年代对象了。所以也就没有给新生代或者老年代分配多少内存这一说。 预期停顿时间G1另一个特点是可以让我们设置一个垃圾回收的预期停顿时间。我们可以指定一段时间内我们希望垃圾回收导致的系统停顿时间不能超过多久，后面的事情就由 G1 全权负责了。","link":"/post/e2ebbcff.html"},{"title":"【Java并发编程】Java内存模型","text":"我们知道 CPU 与内存、IO 设备之间的读写速度存在巨大差距，短板理论也告诉我们计算机的性能取决于其性能最差的部分。 为了使内存和 IO 设备能够充分利用 CPU 的性能，同时也要兼顾设备的成本，操作系统和编译器为了做了许多优化，主要有 3 个方面： CPU 增加缓存来平衡与内存之间速度的差异 操作系统使用进程与线程，通过分时复用 CPU 来平衡 CPU 和 IO 设备速度的差异 编译器通过优化指令执行次序，来合理利用 CPU 的缓存 当然，万事万物有利有弊，正式由于这些优化手段，也引入了并发编程的核心问题，即： 缓存引起的可见性问题 线程切换引起的原子性问题 编译优化引起的有序性问题 以上就是并发编程的 3 大核心问题。对于Java并发编程这个话题，我们主要研究的就是怎么解决这 3 个问题。 解决的思路说来也不难，就是按需禁用缓存和编译优化。在我们需要的时候，程序员指定程序禁用缓存和编译优化就可以提升程序的性能。 这就是我们本文的重点Java内存模型。 Java 内存模型规范了 JVM 实现按需禁用缓存和编译优化的方法。其主要包括volatile、synchronized 和 final 三个关键字，以及 6 项 Happens-Before 规则。 Happens-BeforeHappens-Before 是一种规则，它要求 JVM 按照这种规则来禁用内存和编译优化。简单来说 Happens-Before 规定了前一个操作结果对后一个操作是可见的。 举例来说现在有事件 A 和事件 B，且 A happens-before B，那就意味着事件 A 对于事件 B 是可见的，无论事件 A 和事件 B 发生在同一个线程还是不同线程，即使它们分别在两个不同的线程上发生，happens-before都会保证事件 A 对于事件 B 是可见的。具体包括以下 6 条规则： 程序的顺序性规则 volatile 变量规则 传递性规则 管程中锁的规则 线程的 start() 规则 线程的 join() 规则 程序的顺序性规则1234567891011121314public class VolatileExample { int x = 0; volatile boolean v = false; public void write(){ x = 42; v = true; } public void read(){ if(v){ System.out.println(x); } }} 程序的顺序性规则即，前面的操作 happens-before 后面的操作，比如 x=10 对于 v=true 是可见的。 volatile 规则volatile 在告诉编译器，对于这个变量的读写，不能使用 CPU 缓存，而是直接从内存执行读写操作。 volatile 规则规定，对于一个 volatile 变量的写操作，happens-before 于对这个变量的读操作，也就是上面这段代码的write()对于read()是可见的。 这条可以结合下面这条传递性规则来理解。 传递性规则如果 A happens-before B，B happens-before A，则 A happens-before C。这条也比较符合直觉，结合 volatile 规则来看一下。 从图中可以看出： 根据规则1，x=42 happens-before v=true 根据规则2，写变量 happens-before 读变量 再结合传递性规则，可得：x=42 happens-before 读变量v=true，这就意味着线程 B 可以看到x==42。 而在 JDK.5 之前，x 的值可能是 0，也可能是 42。因为共享变量 x，可能会缓存在 CPU 中。JDK1.5 对volatile 语义的增强，确保了线程 B 读取到的 x 肯定是 42。 管程中的锁的规则这条规则是指对一个锁的解锁 Happens-Before 于后续对这个锁的加锁。 123456synchronized(this) { // 此处自动加锁 // x 是共享变量，初始值 = 10 if(this.x &lt; 12) { this.x = 12; }}// 此处自动加锁 synchronized 是 Java 对于管程的实现，简单来说当代码进入同步块就会自动加锁，同步块执行完成就会释放锁。 将其与规则4结合是这样的：线程 A 执行代码块将 x 的值从 10 修改为 12；之后线程 B 进入代码块能够看到线程 A 对于 x 的写操作。 线程的 start() 规则主线程 A 启动子线程 B 之后，子线程 B 能够看到主线程在启动子线程 B 前的操作。具体来说，主线程调用子线程的start()方法前的操作，子线程都能看到。 线程的 join() 规则这条关于线程等待，在线程 A 中，调用线程 B 的 join() 并成功返回，那么线程 B 中的任意操作 Happens-Before 于该 join() 操作的返回。","link":"/post/f7a60bf6.html"},{"title":"【Java并发编程】Java 中如何创建线程？","text":"继承Thread实现线程创建 实现Runnable接口 实现Callable接口，结合 FutureTask使用 利用该线程池ExecutorService、Callable、Future来实现 继承 Thread 类123456789101112131415161718192021222324252627282930313233343536public class AddThread extends Thread { private int start, end; private int sum = 0; public AddThread(String name, int start, int end) { super(name); this.start = start; this.end = end; } public void run() { System.out.println(\"Thread-\" + getName() + \" 开始执行!\"); for (int i = start; i &lt;= end; i ++) { sum += i; } System.out.println(\"Thread-\" + getName() + \" 执行完毕! sum=\" + sum); } public static void main(String[] args) throws InterruptedException { int start = 0, mid = 5, end = 10; AddThread thread1 = new AddThread(\"线程1\", start, mid); AddThread thread2 = new AddThread(\"线程2\", mid + 1, end); thread1.start(); thread2.start(); // 确保两个线程执行完毕 thread1.join(); thread2.join(); int sum = thread1.sum + thread2.sum; System.out.println(\"sum: \" + sum); }} 输出结果 12345Thread-线程1 开始执行!Thread-线程1 执行完毕! sum=15Thread-线程2 开始执行!Thread-线程2 执行完毕! sum=40sum: 55 实现Runnable接口12345678910111213141516171819202122232425262728293031323334public class AddRun implements Runnable { private int start, end; private int sum = 0; public AddRun(int start, int end) { this.start = start; this.end = end; } public void run() { System.out.println(Thread.currentThread().getName() + \" 开始执行!\"); for(int i = start; i &lt;= end; i++) { sum += i; } System.out.println(Thread.currentThread().getName() + \" 执行完毕! sum=\" + sum); } public static void main(String[] args) throws InterruptedException { int start = 0, mid = 5, end = 10; AddRun run1 = new AddRun(start, mid); AddRun run2 = new AddRun(mid + 1, end); Thread thread1 = new Thread(run1, \"线程1\"); Thread thread2 = new Thread(run2, \"线程2\"); thread1.start(); thread2.start(); thread1.join(); thread2.join(); int sum = run1.sum + run2.sum; System.out.println(\"sum: \" + sum); }} 实现Callable接口，结合FutureTask创建线程12345678910111213141516171819202122232425262728293031323334353637383940public class AddCall implements Callable&lt;Integer&gt; { private int start, end; private int sum = 0; public AddCall(int start, int end) { this.start = start; this.end = end; } public Integer call() throws Exception { int sum = 0; System.out.println(Thread.currentThread().getName() + \" 开始执行!\"); for (int i = start; i &lt;= end; i++) { sum += i; } System.out.println(Thread.currentThread().getName() + \" 执行完毕! sum=\" + sum); return sum; } public static void main(String[] args) throws ExecutionException, InterruptedException { int start = 0, mid = 5, end = 10; FutureTask&lt;Integer&gt; future1 = new FutureTask&lt;Integer&gt;(new AddCall(start, mid)); FutureTask&lt;Integer&gt; future2 = new FutureTask&lt;Integer&gt;(new AddCall(mid + 1, end)); Thread thread1 = new Thread(future1, \"线程1\"); Thread thread2 = new Thread(future2, \"线程2\"); thread1.start(); thread2.start(); int sum1 = future1.get(); int sum2 = future2.get(); System.out.println(\"sum = \" + (sum1 + sum2)); }} 线程池方式创建12345678910111213141516171819202122232425262728293031public class AddPool implements Callable&lt;Integer&gt; { private int start, end; public AddPool(int start, int end) { this.start = start; this.end = end; } @Override public Integer call() throws Exception { int sum = 0; System.out.println(Thread.currentThread().getName() + \" 开始执行!\"); for (int i = start; i &lt;= end; i++) { sum += i; } System.out.println(Thread.currentThread().getName() + \" 执行完毕! sum=\" + sum); return sum; } public static void main(String[] arg) throws ExecutionException, InterruptedException { int start=0, mid=500, end=1000; ExecutorService executorService = Executors.newFixedThreadPool(2); Future&lt;Integer&gt; future1 = executorService.submit(new AddPool(start, mid)); Future&lt;Integer&gt; future2 = executorService.submit(new AddPool(mid+1, end)); int sum = future1.get() + future2.get(); System.out.println(\"sum: \" + sum); }} 参考资料Java并发学习之四种线程创建方式的实现与对比","link":"/post/714434fb.html"},{"title":"【Java并发编程】Java线程的生命周期","text":"在 Java 领域，实现并发程序的主要手段是多线程。线程是操作系统的概念，虽然不同语言对线程操作进行了不同的封装，但是万变不离其综。 通用的线程模型可以用「五态模型」来描述，它们分别是：初始状态，可运行状态，运行状态，休眠状态和终止状态。 这五种状态在不同编程语言里会有简化合并。例如，C 语言的 POSIX Threads 规范，就把初始状态和可运行状态合并了；Java 语言里则把可运行状态和运行状态合并了，这两个状态在操作系统调度层面有用，而 JVM 层面不关心这两个状态，因为 JVM 把线程调度交给操作系统处理了。 除了简化合并，这五种状态也有可能被细化，比如，Java 语言里就细化了休眠状态。 Java 线程的生命周期Java 语言中的线程有 6 种状态 NEW (初始状态) RUNNABLE (可运行/运行状态) BLOCKED (阻塞状态) WATTING (无限期等待) TIMED_WAITING (有时限等待) TERMINATED (终止状态) 其中 BLOCKED、WATTING 和 TIMED_WAITING 在操作系统层面同属于前面提高的休眠状态。简化的 Java 的生命周期图，如下所示： 那么些状态是如何产生，如何进行转换的呢？ 从 NEW 到 RUNNABLENEW 状态指的是在编程语言层面创建了线程，但是操作系统层面还未创建线程。Java 中刚创建出来的 Thread 对象就是 NEW 状态，创建 Thread 对象的方法有两种： 继承 Thread 对象，重写 run() 方法 实现 RUNNABLE 接口，重写 run() 方法 此时通过MyThread myThread = new MyThread()或者Thread thread = new Thread(new Runner())创建出来的线程就处在 NEW 状态。 如果想要将线程转换到 RUNNABLE 状态，只需要使用start()方法，即myThread.start() 或者 thread.start()。 从 RUNNABLE 到 BLOCKEDBLOCK 表示阻塞状态，在 Java 中只有一种情况会触发 RUNNABLE 到 BLOCKED 的转换，那就是线程等待 synchronized 锁。synchronized 修饰的代码块同一时刻只允许一个线程执行，其他线程就只能等待。当等待的线程拿到 synchronized 隐式锁的时，就会从 BLOCKED 切换到 RUNNABLE。 这里的 BLOCKED 和操作系统层面的阻塞有所区别。在操作系统层面，当线程调用阻塞时 API，比如说进行 IO 操作，那么该线程就会处于休眠状态。但是在 JVM 层面 Java 程序的状态并不会发生改变，任然会保持为了 RUNNABLE 状态。JVM 层面并不关系操作系统调度相关的状态。在 JVM 看来，等待 CPU 的使用权，与等待 I/O 没有区别，都是在等待某个资源，所以都归入到 RUNNABLE 状态。 从 RUNNBALE 到 WAITING总体来说，有三种场景会触发这种转换。 第一种场景，获得 synchronized 隐式锁的线程，调用无参数的 Object.wait() 方法。 第二种场景，调用无参数的 Thread.join() 方法。其中的 join() 是一种线程同步方法，例如有一个线程对象 thread A，当调用 A.join() 的时候，执行这条语句的线程会等待 thread A 执行完， 而等待中的这个线程，其状态会从 RUNNABLE 转换到 WAITING。当线程 thread A 执行完，原来等待它的线程又会从 WAITING 状态转换到 RUNNABLE。 第三种场景，调用 LockSupport.park() 方法。其中的 LockSupport 对象，也许你有点陌生，其实 Java 并发包中的锁，都是基于它实现的。调用 LockSupport.park() 方法，当前线程会阻塞， 线程的状态会从 RUNNABLE 转换到 WAITING。调用 LockSupport.unpark(Thread thread) 可 唤醒目标线程，目标线程的状态又会从 WAITING 状态转换到 RUNNABLE。 从 RUNNBALE 到 TIMED_WATING有五种场景会触发这种转换： 调用带超时参数的 Thread.sleep(long millis) 方法； 获得 synchronized 隐式锁的线程，调用带超时参数的 Object.wait(long timeout) 方法； 调用带超时参数的 Thread.join(long millis) 方法； 调用带超时参数的 LockSupport.parkNanos(Object blocker, long deadline) 方法； 调用带超时参数的 LockSupport.parkUntil(long deadline) 方法。 从 RUNNBALE 到 TERMINATED线程执行完 run() 方法后，会自动转换到 TERMINATED 状态，当然如果执行 run() 方法的时候异常抛出，也会导致线程终止。有时候我们需要强制中断 run() 方法的执行，例如 run() 方法访 问一个很慢的网络，我们等不下去了，想终止怎么办呢？Java 的 Thread 类里面倒是有个 stop() 方法，不过已经标记为 @Deprecated，所以不建议使用了。正确的姿势其实是调用 interrupt() 方法。 interrupt() 会通过异常或者主动监测的方式通知线程，线程有机会执行后续操作，也可以无视这个通知。","link":"/post/541ca933.html"},{"title":"JVM-如何设置JVM的参数","text":"新生代、老生代、永久代的概念 JVM内存相关核心参数图解 如何在启动系统的时候设置 JVM 参数 新生代、老生代、永久代的概念JVM-JVM中内存区域划分这一章中讲过，每执行一个方法，该方法都会有一个栈帧进入 Java 虚拟机栈，栈帧中保存着方法中的局部变量、返回值地址等信息。 栈帧中保存的局部变量如果是一个对象，它就会指向 Java 堆中某个具体的对象实例，如下图所示： 新生代：刚创建的对象都会在新生代，变量将会指向这个对象实例。如果没有任何变量指向这个对象，该对象就可能被回收。 老年代：新生代内存满了之后就会触发 Minor GC ，垃圾回收器会回收新生代中没有人引用的对象实例。如果一个对象实例经过10多次回收都没有被回收掉，就算它年龄有 10 多岁了，将会进入到老年代。 永久代：可以理解成方法区中的类和类信息 JVM内存相关核心参数图解在JVM内存分配中的核心参数，如下所示。 -Xms：Java堆内存的大小 -Xmx：Java堆内存的最大大小 -Xmn：Java堆内存中的新生代大小，扣除新生代剩下的就是老年代的内存大小了 -XX:PermSize：永久代大小 -XX:MaxPermSize：永久代最大大小 -Xss：每个线程的栈内存大小 启动时设置 JVM 参数IDEA 可以在 Run-edit configration.. 中设置参数，如下所示： 如果在线上部署系统，可以使用java -jar方式启动，如：java -Xms512M -Xmx512M -Xmn256M -Xss1M -XX:PermSize=128M -XX:MaxPermSize=128M -jar App.jar","link":"/post/1410ce3d.html"},{"title":"【Java并发编程】死锁","text":"我们来想象一个场景。现在你是清朝末年账房里的一个先生，张三要给李四转4两银子，你从柜台取过张三的账本，发现李四的账本不在了，于是你想先留着张三的账本，等会儿再去柜台看看李四的账本别人用完没。 没成想，李四想着给张三转5两银子，另一个账房先生和你同时取了李四的账本。你俩想法一样，他留着李四的账本，等着一会儿去拿张三的账本。 现在的局面正是俩人互相「死等」对方的账本，在代码的世界，这种局面就叫做「死锁」。死锁用书面点的方法来说就是：一组互相竞争的线程互相等待，导致「永久」阻塞的现象。 死锁的局面我们现在设法用代买来描述「死锁」的局面。 12345678910111213141516171819public class Account { private int balance; // 转账 void transfer(Account target, int amt){ // 锁定转出账户 synchronized (this){ // 锁定转入账户 synchronized (target){ if(this.balance &gt; amt){ this.balance -= amt; target.balance += amt; } } } }} 我们现在有一个账户类 Account，transfer()是一个转账的方法，它将当前对象的钱转到目标账户中。为了保证transfer()能够并发执行而不出现问题，我们给采用细粒度锁，即对资源this和target分别加上了锁，情况如下图所示： 当线程 T1 指向由账户 A 向账户 B 转账的操作，线程 T2 指向由账户 B 向账户 A 转账的操作。线程 T1 和 T2 同时执行到synchronized (this)，分别锁定了账户 A 和账户 B。当它们继续向下执行到synchronized (target)时会发现它们互相无法取得自己需要的锁，因为锁已经被对方持有，这就造成了「死锁的局面」。 死锁产生的 4 中条件及解决办法并发程序一旦死锁，我们一般只能重启程序。所以没有很好的办法直接解决死锁，我们能做的是规避死锁，也就是避免死锁产生的条件，有个叫 Coffman 的牛人已经总结过了，只有以下这四个条件都发生时才会出现死锁： 产生条件 解决办法 1. 互斥，共享资源 X 和 Y 只能被一个线程占用 用锁就是为了互斥，所以不会破坏这个条件 2. 占有且等待，线程 T1 已经取得共享资源 X，在等待共享资源 Y 的时候，不释放共享资源 X； 一次性申请所有资源 3. 不可抢占，其他线程不能强行抢占线程 T1 占有的资源； 线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源 4. 循环等待，线程 T1 等待线程 T2 占有的资源，线程 T2 等待线程 T1 占有的资源 按序申请资源 具体来说一下解决方案： 一次申请所有资源。用一个 List 保存所有被占用的资源，并用apply()和free()方法来维护这个 List。每次调用transfer()时，循环等待所有资源都不在 List 中，并一次申请所有资源。 主动释放资源。synchronized采用阻塞等待的方式申请资源，如果想实现主动释放资源可以使用java.util.concurrent 这个包 下面提供的Lock 按序申请。Accout 类中维护一个变量叫 id，每个对象都有自己的 id 序号。每次申请资源都比较两个对象的 id 大小，每次申请资源时，按照先大后小，或者先小后大的固定顺序。这样就保证先申请资源 A，再申请资源 B，不会出现先申请资源 B 再申请资源 A 的情况发生。","link":"/post/3d624a82.html"},{"title":"SpringBoot 模板 Thymeleaf 的使用","text":"Java 开发行业有三种常用显示模板 FreeMarker Velocity Thymeleaf（推荐使用） 本项目是使用 Thymeleaf 模板的简单 Demo 点击查看源码 SpringBoot 模板 Thymeleaf 的使用pom.xml 中添加依赖 12345&lt;!-- 配置使用 thymeleaf 模板--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;&lt;/dependency&gt; 控制层进行信息显示 12345678910111213@Controllerpublic class MessageController extends AbstractBaseController { @RequestMapping(value = \"/show\", method = RequestMethod.GET) public String show(String mid, Model model) { // request属性传递包装 model.addAttribute(\"url\", \"www.shuiyujie.com\"); // request属性传递包装 model.addAttribute(\"mid\", mid); // 此处只返回一个路径， 该路径没有设置后缀，后缀默认是*.html return \"message/message_show\"; }} 由于我们使用的是@Controller注解，所以此时return &quot;message/message_show&quot;将进行一次路由，路由到的文件就是 Thymeleaf 模板文件。 Thymeleaf 模板文件位置配置文件位置的配置很重要，要按照规范进行配置。 首先我们要建立一个Resources类型目录，Resources目录就是源代码目录，这个是可以通过 IDE 进行设置。 我是这样设置的： src/main/view 目录下存放页面 src/main/view/static 目录下存放 js,css,images 等文件 src/main/view/templates 目录下存放 html 页面 注: static 静态目录下的文件可以直接访问，而不需要通过控制器进行路由。 http://localhost:8080/show通过路由访问 message_show.html 页面 http://localhost:8080/message_index.html直接访问 message_index.html 页面","link":"/post/41479a53.html"},{"title":"【Java并发编程】线程本地存储模式ThreadLocal","text":"我们知道多个线程同时读写同一共享变量会导致并发问题。 一种解决方案是使用 Immutability 模式，如果共享变量在初始化之后就不会改变，只能读取，那么无论多少个线程同时读这个共享变量都不会出现并发问题。比如说 Java 中的 Long、Integer、Short、Byte 等基本数据类型的包装类的实现。 另一种解决方案是突破共享变量，没有共享变量就不会有并发问题。那么如何避免共享呢？思路其实很简单，就是每个线程拥有自己的变量，彼此不共享，就不会有共享问题。 具体来说有两种方法：线程封闭和线程本地存储(ThreadLocal)。 线程封闭方法里的局部变量，因为不会和其他线程共享，所以没有并发问题，叫做线程封闭，比较官方的解释是：仅在单线程内访问数据。由于不存在共享，所以即便不同步也不会有并发问题，性能杠杠的。 如上图所示，JVM 中每一个线程都会有一个 Java 虚拟机栈。Java 程序每调用一个方法都会入栈，每执行完一个方法都会出栈，且每一个方法都有一个栈帧。栈帧中存储了参数、局部变量和返回地址。由此可见，方法的局部变量是不可能和其它线程共享的。 局部变量可以避免线程共享，此外还有什么方法能避免线程共享么？有，那就是 Java 语言提供的线程本地存储(ThreadLocal)。 ThreadLockSimpleDateFormat 不是线程安全的，如果想在并发场景下使用它可以将其设置为一个方法的局部变量，这样就会创建许多对象占用内存。或者使用 ThreadLock，不同线程调用 SafeDateFormat 会返回不同的 SimpleDateFormat 对象，但是由于在线程之间不共享，就和局部变量一样是安全的。 1234567891011static class SafeDateFormat { // 定义 ThreadLocal 变量 static final ThreadLocal&lt;DateFormat&gt; tl=ThreadLocal.withInitial( ()-&gt; new SimpleDateFormat( \"yyyy-MM-dd HH:mm:ss\")); static DateFormat get(){ return tl.get(); }} 接下来再看一下 ThreadLock 的代码实现。 1234567891011121314151617181920212223242526272829303132class Thread { // 内部持有 ThreadLocalMap ThreadLocal.ThreadLocalMap threadLocals;}class ThreadLocal&lt;T&gt;{ public T get() { // 首先获取线程持有的 //ThreadLocalMap ThreadLocalMap map = Thread.currentThread() .threadLocals; // 在 ThreadLocalMap 中 // 查找变量 Entry e = map.getEntry(this); return e.value; } static class ThreadLocalMap{ // 内部是数组而不是 Map Entry[] table; // 根据 ThreadLocal 查找 Entry Entry getEntry(ThreadLocal key){ // 省略查找逻辑 } //Entry 定义 static class Entry extends WeakReference&lt;ThreadLocal&gt;{ Object value; } }} 在 Java 的实现方案中，ThreadLocal 仅仅是一个工具类，内部并不持有和线程有关的数据，所有和线程有关的数据都存储在 Thread 中，比如 Thread 内部持有当前线程的 ThreadLocalMap。 这样设计有一个好处就是能够避免内存泄露。 SimpleDateFormat 的线程安全问题与 ThreadLocal 手撕面试题ThreadLocal！！！","link":"/post/790a1fa3.html"},{"title":"SpringBoot 系列文章","text":"SpringBoot 配置文件及其读取 SpringBoot 错误处理页 SpringBoot 模板 Thymeleaf 的使用 SpringBoot 文件上传 SpringBoot 基础拦截器 SpringBoot 整合 MyBatis SpringBoot 整合消息服务 SpringBoot 整合Redis数据库 SpringBoot 整合Restful SpringBoot 整合Shiro验证框架","link":"/post/ee9b8bc4.html"},{"title":"SpringBoot 配置文件及其读取","text":"在配置文件中统一管理配置信息，使用配置文件 SpringBoot 有规范的方式。 src/main/resources 的 classpath 路径之中，创建application.properties配置文件。 配置文件也可以用 YAML 语言来写，创建application.yml配置文件 两个文件同时存在都会起作用，但当配置项冲突时，优先使用application.properties文件 点击获取项目源码 资源文件的设置 资源文件统一放在src/main/resources/i18n目录中 建立 Messages.properties 12welcome.url=www.shuiyujie.comwelcome.msg=shuiyujie 建立 Pages.properties 12member.add.page=/pages/back/admin/member/member_add.jspmember.add.action=/pages/back/admin/member/member_add.action 配置文件 application.yml 中指定资源文件目录 12345spring: # 表示该配置直接为Spring容器负责处理 messages: # 表示进行资源配置 basename: i18n/Messages,i18n/Pages # 资源文件的名称server: port: 80 # 此处设置的服务的访问端口配置 资源文件的读取经过以上配置就会自动生成一个MessageSource资源文件对象，我们只要注入这个对象就能使用资源文件中配置的属性了。 我会建立一个控制器的父类在其中注入MessageSource，然后子类继承父类就能很方便地读取资源文件了 1234567public abstract class AbstractBaseController { @Resource private MessageSource messageSource; // 自动注入此资源对象 public String getMessage(String key, String... args) { return this.messageSource.getMessage(key, args, Locale.getDefault()); }} 12345678@RestControllerpublic class MessageController extends AbstractBaseController { @RequestMapping(value = \"/echo\", method = RequestMethod.GET) public String echo(String mid) { System.out.println(\"【*** 访问地址 ***】\" + super.getMessage(\"member.add.action\")); return super.getMessage(\"welcome.msg\", mid); }}","link":"/post/f0ba9e07.html"},{"title":"SpringBoot 错误处理页","text":"SpringBoot 错误处理有三种情况 数据验证错误 错误页指派 全局异常处理 比如说在提交表单信息的时候，有些信息没填，有些信息有规范的格式，如果不符合要求就是数据校验错误。 我们需要对这些数据的格式进行校验，不符合要求不能接受且要提示错误信息。 点击查看源码 springboot 错误处理，数据校验错误SpringBoot 有数据校验的默认支持，该支持由 Hibernate 开发框架提供。 错误信息统一配置在ValidationMessages.properties文件中。 这种方式每个 VO 类在ValidationMessages.properties文件中配置对应的错误信息，并且在 VO 类的属性上添加上错误注解，过程繁琐。不推荐使用，更推荐使用反射和拦截器的方式处理错误信息。 但是我们还是要会使用这种方式处理数据验证错误，写了一个小 Demo，再接下来简单记录一下使用过程。 添加错误信息配置文件src/main/resources目录中建立ValidationMessages.properties文件。文件中配置错误信息 12345678member.mid.notnull.error=邮箱不允许为空member.mid.email.error=邮箱格式错误member.mid.length.error=邮箱长度错误member.age.notnull.error=年龄不允许为空member.age.digits.error=年龄格式错误member.salary.notnull.error=工资不允许为空member.salary.digits.error=工资格式错误member.birthday.notnull.error=生日不允许为空 VO 类添加注解12345678910111213141516SuppressWarnings(\"serial\")public class Member implements Serializable { @NotNull(message=\"{member.mid.notnull.error}\") @Email(message=\"{member.mid.email.error}\") @Length(min=6,message=\"{member.mid.length.error}\") private String mid ; @NotNull(message=\"{member.age.notnull.error}\") @Digits(integer=3,fraction=0,message=\"{member.age.digits.error}\") private Integer age ; @NotNull(message=\"{member.salary.notnull.error}\") @Digits(integer=20,fraction=2,message=\"{member.salary.digits.error}\") private Double salary ; @NotNull(message=\"{member.birthday.notnull.error}\") private Date birthday ;} 控制器配置校验1234567891011121314@RequestMapping(value = \"/add\", method = RequestMethod.POST)@ResponseBodypublic Object add(@Valid Member vo, BindingResult result) { if (result.hasErrors()) { Iterator&lt;ObjectError&gt; iterator = result.getAllErrors().iterator(); while (iterator.hasNext()) { ObjectError error = iterator.next(); System.out.println(\"【错误信息】code = \" + error.getCode() + \"，message = \" + error.getDefaultMessage()); } return result.getAllErrors(); } else { return vo; }} springboot 错误处理，配置错误页面错误页面配置在src/main/view/static目录下，比如叫 error-404.html SringBoot 1.x 这样处理12345678910111213141516171819202122232425262728293031323334package com.shuiyujie.config;import org.springframework.boot.context.embedded.ConfigurableEmbeddedServletContainer;import org.springframework.boot.context.embedded.EmbeddedServletContainerCustomizer;import org.springframework.boot.web.servlet.ErrorPage;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.http.HttpStatus;/** * @author shui * @create 2019-02-12 **/@Configurationpublic class ErrorPageConfig { @Bean public EmbeddedServletContainerCustomizer containerCustomizer() { return new EmbeddedServletContainerCustomizer() { @Override public void customize( ConfigurableEmbeddedServletContainer container) { ErrorPage errorPage400 = new ErrorPage(HttpStatus.BAD_REQUEST, \"/error-400.html\"); ErrorPage errorPage404 = new ErrorPage(HttpStatus.NOT_FOUND, \"/error-404.html\"); ErrorPage errorPage500 = new ErrorPage( HttpStatus.INTERNAL_SERVER_ERROR, \"/error-500.html\"); container.addErrorPages(errorPage400, errorPage404, errorPage500); } }; }} SringBoot 2.x 这样处理在SpringBoot2中没有EmbeddedServletContainerCustomizer这个类了，要这样处理 1234567891011121314151617181920212223ackage com.shuiyujie.config;import org.springframework.boot.web.server.ErrorPage;import org.springframework.boot.web.server.ErrorPageRegistrar;import org.springframework.boot.web.server.ErrorPageRegistry;import org.springframework.http.HttpStatus;import org.springframework.stereotype.Component;/** * @author shui * @create 2019-02-12 **/@Componentpublic class ErrorPageConfig implements ErrorPageRegistrar { @Override public void registerErrorPages(ErrorPageRegistry registry) { ErrorPage[] errorPages = new ErrorPage[3]; errorPages[0] = new ErrorPage(HttpStatus.NOT_FOUND, \"/error-400.html\"); errorPages[1] = new ErrorPage(HttpStatus.NOT_FOUND, \"/error-404.html\"); errorPages[2] = new ErrorPage(HttpStatus.INTERNAL_SERVER_ERROR, \"/error-500.html\"); registry.addErrorPages(errorPages); }} SpringBoot 全局错误处理之前设置了错误页面，发生错误将会跳转到错误页面。 1234567891011/** * 演示 500 错误 * * @return */@RequestMapping(value=\"/get\")@ResponseBodypublic String get() { System.out.println(\"除法计算：\" + (10 / 0)); return \"hello world\" ;} 比如这样一个 10/0 的错误控制器跳转到 500 页面，这样就看不到详细的报错信息了。我们想看到类似控制台里面更加详细的报错信息。 定义一个错误信息处理的页面新建一个错误界面src/main/view/templates/error.html 123456789101112!DOCTYPE HTML&gt;&lt;html xmlns:th=\"http://www.thymeleaf.org\"&gt;&lt;head&gt; &lt;title&gt;SpringBoot模版渲染&lt;/title&gt; &lt;link rel=\"icon\" type=\"image/x-icon\" href=\"/images/mldn.ico\"/&gt; &lt;meta http-equiv=\"Content-Type\" content=\"text/html;charset=UTF-8\"/&gt;&lt;/head&gt;&lt;body&gt; &lt;p th:text=\"${url}\"/&gt; &lt;p th:text=\"${exception.message}\"/&gt;&lt;/body&gt;&lt;/html&gt; 定义全局异常处理类123456789101112131415161718192021222324252627282930313233343536373839404142434445@RestControllerAdvicepublic class GlobalExceptionHandler { // 定义错误显示页，error.html public static final String DEFAULT_ERROR_VIEW = \"error\"; // 所有的异常都是Exception子类 @ExceptionHandler(Exception.class) public Object defaultErrorHandler(HttpServletRequest request, Exception e) { class ErrorInfo { private Integer code; private String message; private String url; public Integer getCode() { return code; } public void setCode(Integer code) { this.code = code; } public String getMessage() { return message; } public void setMessage(String message) { this.message = message; } public String getUrl() { return url; } public void setUrl(String url) { this.url = url; } } ErrorInfo info = new ErrorInfo(); // 标记一个错误信息类型 info.setCode(100); info.setMessage(e.getMessage()); info.setUrl(request.getRequestURL().toString()); return info; }}","link":"/post/3c98ab20.html"},{"title":"【Java并发编程】Lock&Condition","text":"在并发编程中有两个核心问题:一个是互斥,即同一时刻只允许一个线程访问共享资源;另一个是同步,即线程之间如何通信和协作。解决这两个问题的方法前人已经替我们总结出来理论模型,分别是管程模型和信号量模型. Java中实现管程有两种方式 一是使用synchronized关键字给代码块添加隐式锁实现互斥,同时使用notify()和notifyAll()实现同步 二是使用 Java SDK 并发包下的 Lock 和 Condition 两个接口,来实现管程. Lock 的特性包括:能够响应中断、支持超时和非阻塞地获取锁 Condition 实现了管程模型里面的条件变量。 注：Java 参考了 MESA 模型，语言内置的管程（synchronized）对 MESA 模型进行了精简。MESA 模型中，条件变量可以有多个，Java 语言内置的管程里只有一个条件变量。Java 并发包下的 Lock&amp;Condition则则支持多个条件变量。 为什么要用 lock&amp;condition 再次实现管程Java 已经通过synchronized实现了管程,那么为什么 jdk1.5 还要在并发包中用 lock&amp;condition 来实现管程? 这两种实现方式存在什么区别么? 它们各自有什么样的应用场景? 在之前的死锁问题一文中提到了死锁的产生必须同时具备 4 个条件,我们只需要破坏其中任意一个条件都能够预防死锁的发生.其中有一个条件是不可抢占,也就是线程 T1 持有某一个资源,其他线程不能强行抢占它持有的资源. 当我们使用synchronized加锁时,当它持有锁A,但是无法持有到锁 B, 时线程就会直接进入阻塞状态,此时一旦发生死锁就没有办法唤醒这个线程了.Lock&amp;Condition的出现就是为了做到破坏不可抢占条件. 具体来说,怎么才能破坏不可抢占条件呢?有这样 3 个思路: 能够响应中断.当线程进入阻塞状态之后,我们能够发送一个中断信号给这个阻塞的线程.该线程能够响应中断信号,就有机会释放持有的锁 A,就能破坏不可抢占的条件. 超时机制.线程在一段时间内无法获取到锁,它不会进入阻塞状态,而是返回错误,那么这个线程也有机会释放持有的锁. 非阻塞地获取锁.如果尝试获取锁失败，并不进入阻塞状态，而是直接返回. 这三种方案可以弥补 synchronized 实现的管程无法破坏不可抢占条件的问题,具体来说 Lock 接口实现这里这样 3 个方法: 123456// 支持中断的 APIvoid lockInterruptibly() throws InterruptedException;// 支持超时的 APIboolean tryLock(long time, TimeUnit unit) throws InterruptedException;// 支持非阻塞获取锁的 APIboolean tryLock(); 用两个条件变量实现阻塞队列 Java 语言内置的管程里只有一个条件变量，而 Lock&amp;Condition 实现的管程是支持多个条件变量的，这是二者的一个重要区别。 在很多并发场景下，支持多个条件变量能够让我们的并发程序可读性更好，实现起来也更容易。例如，实现一个阻塞队列，就需要两个条件变量。 一个阻塞队列，需要两个条件变量，一个是队列不空（空队列不允许出队），另一个是队列不满（队列已满不允许入队）。 123456789101112131415161718192021222324252627282930313233343536373839public class BlockedQueue&lt;T&gt; { final Lock lock = new ReentrantLock(); // 条件变量,队列不满 final Condition notFull = lock.newCondition(); // 条件变量.队列不空 final Condition notEmpty = lock.newCondition(); // 入队 void enq(T x) { lock.lock(); try { while(队列已满){ // 等待队列不满 notFull.await(); } // 省略入队操作 // 入队后,通知可出队 notEmpty.signal(); }finally { lock.unlock(); } } // 出队 void deq(){ lock.lock(); try{ while(队列已空){ // 等待队列不空 notEmpty.await(); } // 省略出队操作 // 出队后,通知可入队 notFull.signal(); }finally { lock.unlock(); } }}","link":"/post/3e6f77c3.html"},{"title":"并发编程的优缺点","text":"Java 程序从 main() 函数开始开始执行，就是启动一个名称为 main 的线程。在程序顺序执行的过程中，看似没有其他线程参与，实际上有许多线程和 main 线程一起执行着。 Java 天生就是多线程的，为什么 Java 会设计成多线程的呢？并发编程是不是有它优点？然而事物都是有两面性的，并发编程的缺点是什么？应该怎么避免？ 1. 为什么要使用并发？（优点）1.1 更好地利用计算机处理器现在 CPU 都是多核的，而且核心越来越多。如果一个程序是单线程的，无论如何只能使用一个核心，CPU 的核心再多也无法提升机器的性能。 如果一个程序是多线程的，那么它就可以利用 CPU 的多个核心进行运算，CPU 的核心变得越多，运行速度也能越快。 1.2 更快的响应速度多线程可以让一系列的操作并发地执行，这样就可以提高程序响应的速度。比如用户下单，它包括插入订单数据、生成订单快照、发送邮件通知卖家和记录货品销售数量等。 等这些业务操作做完，用户要等 1 秒。把生成订单快照、发送邮件这样的操作给其他线程处理，用户可能就等 0.5 s。 1.3 更简单地进行开发Java 设计之初就考虑了并发编程，提供了一致的编程模型，使用 Java 的程序员可以把更多精力放在业务上，而不用考虑怎么使用多线程。 2. 并发编程的缺点及解决方案2.1 增加上下文切换，影响执行速度我们在阅读英文书籍的时候碰到了一个不认识的单词，这时候就去字典里查一下这个单词是什么意思，查完再回过头继续往下看书。这个一来一回的过程就相当于是上下文切换的过程。 线程之间上下文切换的过程是这样的。CPU 个每个线程分配一个时间片，一个时间片就表示一段很短的时间。CPU 执行线程时，时间片用完了就会换一个线程执行，就这样在各个线程之间切换。 查完字典再回过头继续阅读，这样会影响我们的阅读效率。上下文切换自然也会影响执行速度。 减少上下文切换的方法有无锁并发编程、CAS算法、使用最少线程和使用协程。 无锁并发编程。多线程竞争锁时，会引起上下文切换，所以多线程处理数据时，可以用一些办法来避免使用锁，如将数据的ID按照Hash算法取模分段，不同的线程处理不同段的数据。 CAS算法。Java的Atomic包使用CAS算法来更新数据，而不需要加锁。 使用最少线程。避免创建不需要的线程，比如任务很少，但是创建了很多线程来处理，这样会造成大量线程都处于等待状态。 协程：在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换。 2.2 出现死锁，导致系统不可用1234567891011121314151617181920212223242526272829303132333435public class DeadLockDemo { privat static String A = \"A\"; private static String B = \"B\"; public static void main(String[] args) { new DeadLockDemo().deadLock(); } private void deadLock() { Thread t1 = new Thread(new Runnable() { @Override publicvoid run() { synchronized (A) { try { Thread.currentThread().sleep(2000); } catch (InterruptedException e) { e.printStackTrace(); } synchronized (B) { System.out.println(\"1\"); } } } }); Thread t2 = new Thread(new Runnable() { @Override publicvoid run() { synchronized (B) { synchronized (A) { System.out.println(\"2\"); } } } }); t1.start(); t2.start(); }} 比如t1拿到锁之后，因为一些异常情况没有释放锁（死循环）。又或者是t1拿到一个数据库锁，释放锁的时候抛出了异常，没释放掉。 一旦出现死锁，系统功能就不可用了，需要花许多精力去排查错误。 避免死锁的几个常见方法有： 避免一个线程同时获取多个锁。 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源。 尝试使用定时锁，使用lock.tryLock（timeout）来替代使用内部锁机制。 对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况。 2.3 资源限制影响性能资源限制是指在进行并发编程时，程序的执行速度受限于计算机硬件资源或软件资源。 比如带宽受限的情况下及时启动多个线程进行下载，下载速度永远无法超过带宽。 在并发编程中，将代码执行速度加快的原则是将代码中串行执行的部分变成并发执行。 但是如果将某段串行的代码并发执行，因为受限于资源，仍然在串行执行，这时候程序不仅不会加快执行，反而会更慢，因为增加了上下文切换和资源调度的时间。 对于硬件资源的限制，可以采用集群的方式，一台机器的资源有限那就用多台，比如部署 hadoop 集群。 对于软件资源限制可以采用连接池，提高资源的复用率。","link":"/post/579f9aa4.html"},{"title":"消息队列的连环炮","text":"1. 引子消息队列分布式系统中重要的组件，一种存放消息的容器，主要作用有解耦、异步、削锋，是大型分布式系统不可缺少的中间件。 常见的消息队列有 ActiveMQ，RabbitMQ，RocketMQ，Kafka。 简历中涉及到了消息队列，面试官先问了这样几个问题： 你们系统里为什么要使用消息队列？ 既然使用了消息队列，说说他还有什么使用场景？ 消息队列的优缺点是什么？ 2. 为什么使用消息队列？我的回答：甲方提供 EOS 充值服务，我方进行调用。出于解耦的目的，引入了消息队列。 一个类似应试的回答方法，就是思考面试官问这个问题是出于什么目的，想获得的是什么样的答案？ 当问到为什么使用消息队列时，面试官期望的回答是公司的 xxx 业务遇到了挑战，不用 MQ 会有麻烦，使用 MQ 之后带来了好处。 通过一个问题就能看出是为了用而用，还是经过思考之后使用。 3. 消息队列的使用场景？问消息队列的使用场景，和问消息队列有什么优点，消息队列有什么作用是等价的。 消息队列的作用主要有三个解耦、异步、削峰。 解耦 B,C,D 系统需要使用 A 系统产生的关键数据。 无消息队列时 系统 A 为系统 B、C、D 等提供各自的接口，导致系统 A 与它们紧密耦合 添加系统 E 又需要接口，删除 B 系统原接口又没用了 有消息队列时 系统 A 作为生产者，将消息发送到消息队列 系统 B、C、D 作为消费者订阅消息 新增消费者只需订阅消息，对原系统和业务没有影响 异步 用户请求数据时，系统的响应时间是保证用户体验很重要的一部分。 无消息队列时 用户请求 A 系统，A 系统需要等待 BCD 执行完成之后响应 用户收到响应用时近 1 秒 用消息队列时 用户请求 A 系统，A 系统将请求推到消息队列中，B、C、D 异步执行 用户收到响应用时 200 毫秒 削峰 秒杀场景下，每秒有 5000 个请求，Mysql 每秒最大处理 2000 条 sql。 无消息队列时 用户请求数据直接写入数据库，高并发时数据库压力剧增，甚至奔溃 Mysql 宕机，整个系统都不能用了 有消息队列时系统 B、C、D 用户请求数据先存入 MQ 中 系统 A 每秒读取 2000 条数据进行处理 每秒多出 3000 条未处理数据按场景稍后处理 4. 消息队列有什么缺点？优点前面已经说过了，还需要讨论一下缺点。 为什么要问缺点是什么？凡事都有两面性，如果只是考虑到消息队列的优点，而没有考虑缺点，这就是一个潘多拉的魔盒。打开魔盒，接踵而来的会是一系列的意外。 推广到引入其他技术亦然，只有考虑到缺点之后才可以采取额外的技术方案或者架构来规避这些缺点。 系统可用性降低 系统引入的外部依赖越多，宕机的可能性就越大 系统引入消息队列，就要考虑消息队列的可靠性 比如原本只需要考虑 A,B,C,D 四个系统 引入消息队列之后就需要考虑 A,B,C,D 四个系统外加消息队列 系统复杂度提高 消息重复消费问题 消息丢失问题 消息传递顺序问题 一致性问题 A 系统处理完返回成功，即认为请求成功 但是也存在 BC 系统写入成功，而 D 系统写入失败的情况 这样的情况就是数据不一致 总结面试官问到 MQ 的时候，希望考察我们在使用 MQ 的时候是否有过自己的思考。没有完美的技术，任何技术都具有两面性，要考虑它的使用场景，并且对可能遇到的风险做到心中有数，提前预防。 思考引入消息队列之后： 如何保证高可用？ 如何避免消息的重复消费和消息丢失？ 如何保证消息的顺序执行？ 下一篇文章一起讨论。","link":"/post/b63a0941.html"},{"title":"maven 实战","text":"Maven 是跨平台的项目管理工具，主要服务于基于Java平台的项目构建、依赖管理和项目信息管理。Maven 的主要思想是约定优于配置。通过将约定项目的目录结构，抽象项目的生命周期的方式，将程序员从繁琐的项目构建中解放出来。 本文是《Maven 实战》的笔记归纳，找到一本好书就像发现一座宝藏，让人获益匪浅。 注：本文用的是 maven-3.5.0 版本。 Maven 优点和作用日常工作除了编写源代码，每天有相当一部分时间花在了项目构建中，他们包括项目的编译、运行单元测试、生成文档、打包和部署等烦琐且不起眼的工作。 项目自动化构建。Maven 提供一套规范以及一系列脚本，从清理、编译、测试到生成报告，再到打包和部署实现自动化构建。还提供了插件扩展的方式，进一步简化构建的过程。Maven 还能对项目进行编译、测试、打包，并且将项目生成的构建部署到仓库中。 Maven 是跨平台的。对外提供了一致的操作接口，无论在 windows 平台、Linux 平台还是 Mac 上都能用相同的命令进行操作。同时，Maven 项目目录结构、测试用例命名方式等内容都有既定的规则，只要遵循了这些成熟的规则，用户在项目间切换的时候就免去了额外的学习成本。 Maven 是依赖管理工具。Java 项目需要依赖许多的 jar 包，随着依赖的增多，版本不一致、版本冲突、依赖臃肿等问题都会接踵而来。Maven 通过仓库统一存储这些 jar 包，并通过 pom 文件来管理这些依赖。 Maven 是项目配置工具。Maven能帮助我们管理原本分散在项目中各个角落的项目信息，包括项目描述、开发者列表、版本控制系统地址、许可证、缺陷管理系统地址等。 Maven 的仓库 以上是 Maven 的概念模型，前面说过 Maven 能管理众多的 jar 包，并且梳理他们之间的依赖关系。Maven 通过 pom 文件和仓库进行实现。 仓库的作用如果没有 maven 我们要使用一个 jar 包要从项目的官网寻找下载 jar 到本地，然后再将 jar 包导入到项目中。这样存在几个问题： 去相应的网站寻找 jar 包费精力 下载之后当需要用到某一个 jar 包的时候还要在本地找 jar 包 依赖的 jar 包有多个版本要怎么管理… 最好的解决方式就是将这些 jar 包统一管理，每次只要去一个地方找就可以了。 Maven 就帮我们做了这样一件事情，他提供一个免费的中央仓库http://repo1.maven.org/maven2,该中央仓库包含了世界上大部分流行的开源项目。 我们可以从中央仓库下载需要的 jar 包，从中央仓库下载的 jar 包会统一保存在 maven 的本地仓库中。本地仓库在本机的.m2文件夹中。 本地仓库更多相关信息可以去搜索 maven 的安装教程。 更多种类的仓库 远程仓库除了中央仓库还有私服和其他公共仓库。 私服私服是一种特殊的远程仓库，它是架设在局域网内的仓库服务，私服代理广域网上的远程仓库，供局域网内的Maven用户使用。 上图是搭建私服的示意图。私服会将其他公共仓库的 jar 缓存到搭建的服务器上，局域网内的用户还可以将构建的项目直接放到私服上供其他开发人员使用。 架设私服是 Maven 推荐的做法，私服减少中央服务器的压力。如果没有私服，每次请求都需要向中央服务器请求，有了私服之后通过私服的服务器向中央仓库请求，局域网内的用户只需要向私服请求即可。 其他公共仓库比如 Maven 的中央仓库部署在国外，国内访问外网速度不够，我们可以在国内架设 Maven 的公共仓库。 如果仓库 X 可以提供仓库 Y 存储的所有内容，那么就可以认为 X 是 Y 的一个镜像，显然在国内我们需要一个中央仓库的镜像。http://maven.net.cn/content/groups/public/是中央仓库，http://repo1.maven.org/maven2/在中国的镜像。 Maven 默认是从中央仓库下载文件的，想要让其从其他地方下载文件就要进行配置，这里就需要操作 maven 的 setting.xml 文件了。 setting 文件在安装好 maven 的基础上，进入 maven 的安装目录，可以看到如下的目录结构： bin : mvn 的一些脚本文件 boot : 含有 plexus-classworlds 类加载器框架 conf : 配置文件 lib : maven 所使用的 jar 包（maven 基于 java 开发） setting.xml 文件就在conf目录中。这里的setting.xml是 maven 全局的配置文件，不建议修改。修改之后会影响 maven 的升级等操作。常用的做法是拷贝一份setting.xml到 maven 本地仓库的同一目录下，而本地仓库配置在用户目录的.m2文件夹中，此时的setting.xml就是用户级别的配置文件。 强烈建议遵循以上规范，避免不必要的麻烦。 自定义本地仓库位置接下来就来看setting.xml的一些配置了。 首先localRepository定义本地仓库位置，默认在用户目录下的.m2/repository中。 12345Default: ${user.home}/.m2/repository&lt;localRepository&gt; /path/to/local/repo&lt;/localRepository&gt; 配置多个远程仓库前面讲过有中央仓库和其他远程仓库，配置远程仓库就在repositories中配置。 12345678910111213141516&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;jboss&lt;/id&gt; &lt;name&gt;JBoss Repository&lt;/name&gt; &lt;url&gt;http://repository.jboss.com/maven2/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;updatePolicy&gt;daily&lt;/updatePolicy&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;checksumPolicy&gt;warn&lt;/checksumPolicy&gt; &lt;/snapshots&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;/repository&gt;&lt;/repositories&gt; 在repositories元素下，可以使用repository子 元素声明一个或者多个远程仓库。 配置中央仓库镜像12345678＜settings＞ …… ＜mirrors＞ ＜mirror＞ ＜id＞maven.net.cn＜/id＞ ＜name＞one of the central mirrors in China ＜/name＞＜url＞ http://maven.net.cn/content/groups/public/ ＜/url＞ ＜mirrorOf＞central＜/mirrorOf＞ ＜/mirror＞ ＜/mirrors＞ …… ＜/settings＞ 配置私服作为镜像12345678&lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;maven.oschina.net&lt;/id&gt; &lt;name&gt;maven mirror in China&lt;/name&gt; &lt;url&gt;http://maven.oschina.net/content/groups/public/&lt;/url&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;/mirror&gt;&lt;/mirrors&gt; 仓库搜索服务以下网站提供 Maven 仓库搜索功能。 Sonatype Nexus地址：http://repository.sonatype.org/ MVNrepository地址：http://mvnrepository.com/ 一般我就用最后一个搜索。 Maven 坐标现在有了仓库统一保管这些 jar 包，剩下的问题就是怎么取了。 不知道你有没有取快递的经验。我们可以这些 jar 包想象成是快递，仓库中保管着这些快递。我们去认领快递需要依靠快递单来确定，一张快递单上会有单号、我们的姓名、手机号等信息。依靠这些信息就不会领错快递了。 这里的快递单就像 Maven 中的 pom 文件，单子上的信息就像是 pom 文件中的坐标系。 Maven 项目规定的项目结构是这样的： src/main/java —— 存放项目的.java文件 src/main/resources —— 存放项目资源文件，如spring, hibernate配置文件 src/test/java —— 存放所有测试.java文件，如JUnit测试类 src/test/resources —— 测试资源文件 target —— 项目输出位置 pom.xml——maven项目核心配置文件 每个 maven 项目都有 pom.xml 文件。Maven坐标为各种构件引入了秩序，任何一个构件都必须明确定义自己的坐标。 一组 Maven坐标是通过一些元素定义的，它们是 groupId、artifactId、version、packaging、 classifier： groupId：定义当前Maven项目隶属的实际项目，通常为域名反写 artifactId：该元素定义实际项目中的一个 Maven项目（模块），推荐的做法是使用实际项目名称作为artifactId的前缀。 version：该元素定义Maven项目当前所处的 版本， packaging：该元素定义Maven项目的打包方 式。当不定义packaging的时候，Maven会使用默认值jar。 classifier：该元素用来帮助定义构建输出的一些附属构件。 通过坐标系我们来保证项目在 Maven 仓库中的唯一性，每次取也不会取错了。 Maven 依赖我们自己项目需要用别人的 jar 包，比如 spring。这就是我们的项目依赖于 spring，因此我们通过 pom 来配置这样的依赖关系，这样就能让项目有清晰的结构。 依赖的关系用用&lt;dependecy&gt;标签来表示依赖： 上图说明该项目依赖了 hibernate 等 依赖范围现在来考虑一种情况，我们在项目开发的过程中用到了 junit 进行测试，也就是说我们的项目依赖于 junit。在项目构建的过程中我们会把 junit 也打包在项目中。但是在生产环境中完全没有必要用到 junit，我们并不想将它发布到生产环境中。 我们可以每次在发布项目之前把他删除了对么？那如果依赖 servlet-api，我们只有在编译和测试项目的时候需要该依赖，但在运行项目的时候，由于容器已经提供，也不需要 Maven 重复地引入一遍。 所以最好是在编译、测试、运行的过程中需要用到什么 jar 包，就让 Maven 去打包什么。 maven 为此提供了scope标签表示依赖范围，表示该 jar 包在什么时候需要被使用。 compile：编译依赖范围，使用此依赖范围对于编译、测试、运行三种classpath都有效，即在编译、测试和运行时都要使用该依赖jar包； test：测试依赖范围，只对测试有效，表明只在测试的时候需要，在编译和运行时将无法使用该类依赖，如 junit； provided：已提供依赖范围。编译和测试有效，运行无效。如servlet-api，在项目运行时，tomcat等容器已经提供，无需Maven重复引入； runtime：运行时依赖范围。测试和运行有效，编译无效。如 jdbc 驱动实现，编译时只需接口，测试或运行时才需要具体的 jdbc 驱动实现； system：系统依赖范围，使用system范围的依赖时必须通过systemPath元素显示地指定依赖文件的路径，不依赖Maven仓库解析，所以可能会造成建构的不可移植，谨慎使用。 依赖传递依赖范围除了控制classpath，还会对依赖传递产生影响。如果A依赖B，B依赖C，则A对于B是第一直接依赖。B对于C是第二直接依赖。A对于C是传递性依赖。结论是：第一直接依赖的范围和第二直接依赖的范围决定了传递性依赖的范围。 第一列是第一直接依赖，第一行是第二直接依赖，中间表示传递性依赖范围。 此外 maven 还提供了option和exclusions来进一步管理依赖，分别称为可选依赖和排除依赖。 在依赖中添加 true/false 表示是否向下传递。 如上图所示，B 依赖于 X,Y 而 A 依赖于 B，如果 B 不希望将依赖传递给 A 则可以配置 B 中的 X,Y 依赖的optional为 true 来阻止依赖的传递。 再来看一种情况，A 依赖于 B，且 B 将他的依赖 C 传递给了 A。但是 A 依赖了 C 的另一个版本。这个时候 A 可以主动排除 B 给的 C 依赖，转而使用自己需要的版本，这就用到了exclusions标签。 用exclusions元素声明排除依赖，exclusions可以包 含一个或者多个exclusion子元素，因此可以排除一个或者多个传递性依赖。 所以我用主动和被动的方式来区分他们。 依赖冲突接上面的问题，如果 A 和 B 依赖 C 的不同版本，而且既没有配置可选依赖也没有配置排除依赖。两个版本都被解析显然是不对的，因为那会造成依赖重复，因此必须选择一个。 路径最近者优先。如果直接与间接依赖中包含有同一个坐标不同版本的资源依赖，以直接依赖的版本为准。 第一声明者优先。在依赖路径长度相等的前 提下，在POM中依赖声明的顺序决定了谁会被解析使用，顺序最靠前的那个依赖优胜。 上面例子中,A -&gt; C(1.10) 和 A -&gt; B -&gt; C(?),C(1.10)的路径短所以用它。 Maven 生命周期Maven的生命周期就是为了对所有的构建过程进行抽象和统一。这个生命周期包含了项目的 清理、初始化、编译、测试、打包、集成测试、 验证、部署和站点生成等几乎所有构建步骤。 初学者往往会以为Maven的生命周期是一个整体，其实不然。Maven拥有三套相互独立的生命周期，它们分别为clean、default和site。clean生命周期的目的是清理项目，default生命周期的目的是构建项目，而site生命周期的目的是建立项目站点。 clean 生命周期。clean生命周期的目的是清理项目，它包含三个阶段： pre-clean 执行一些需要在clean之前完成的工作 clean 移除所有上一次构建生成的文件 post-clean 执行一些需要在clean之后立刻完成的工作 mvn clean 中的clean就是上面的clean，在一个生命周期中，运行某个阶段的时候，它之前的所有阶段都会被运行，也就是说，mvn clean 等同于 mvn pre-clean clean ，如果我们运行 mvn post-clean ，那么 pre-clean，clean 都会被运行。这是Maven很重要的一个规则，可以大大简化命令行的输入。 default生命周期default生命周期定义了真正构建时所需要执 行的所有步骤，它是所有生命周期中最核心的部分，其包含的阶段如下： validate generate-sources process-sources generate-resources process-resources 复制并处理资源文件，至目标目录，准备打包。 compile 编译项目的源代码。 process-classes generate-test-sources process-test-sources generate-test-resources process-test-resources 复制并处理资源文件，至目标测试目录。 test-compile 编译测试源代码。 process-test-classes test 使用合适的单元测试框架运行测试。这些测试代码不会被打包或部署。 prepare-package package 接受编译好的代码，打包成可发布的格式，如 JAR 。 pre-integration-test integration-test post-integration-test verify install 将包安装至本地仓库，以让其它项目依赖。 deploy 将最终的包复制到远程的仓库，以让其它开发人员与项目共享。 运行任何一个阶段的时候，它前面的所有阶段都会被运行，这也就是为什么我们运行mvn install 的时候，代码会被编译，测试，打包。此外，Maven的插件机制是完全依赖Maven的生命周期的，因此理解生命周期至关重要。 site生命周期site生命周期的目的是建立和发布项目站点，Maven能够基于POM所包含的信息，自动生成一个友好的站点，方便团队交流和发布项目信息。 pre-site 执行一些需要在生成站点文档之前完成的工作site 生成项目的站点文档 post-site 执行一些需要在生成站点文档之后完成的工作，并且为部署做准备 site-deploy 将生成的站点文档部署到特定的服务器上 这里经常用到的是site阶段和site-deploy阶段，用以生成和发布Maven站点，这可是Maven相当强大的功能，Manager比较喜欢，文档及统计数据自动生成，很好看。 命令与生命周期mvn clean：该命令调用clean生命周期的clean阶段。实际执行的阶段为clean生命周期的 pre-clean和clean阶段。 mvn test：该命令调用default生命周期的test阶段。实际执行的阶段为default生命周期的 validate、initialize等，直到test的所有阶段。这也解释了为什么在执行测试的时候，项目的代码能够自动得以编译。 mvn clean install：该命令调用clean生命周期 的clean阶段和default生命周期的install阶段。 mvn clean deploy site-deploy：该命令调用 clean生命周期的clean阶段、default生命周期的 deploy阶段，以及site生命周期的site-deploy阶段。 聚合与继承软件设计人员往往会采用各种方式对软件划分模块，以得到更清晰的设计及更高的重用性。当把Maven应用到实际项目中的时候，也需要将项目分成不同的模块。 简单的说就是有 A,B 两个模块，现在想要将他们统一管理。Maven 的聚合特性能够把项目的各个模块聚合在一起构建，而Maven的继承特性则能帮助抽取各模块相同的依赖和插件等配置，在简化POM的同时，还能促进各个模块配置的一致性。 聚合两个子模块希望同时构建。这时，一个简单的需求就会自然而然地显现出来：我们会想要一次构建两个项目，而不是到两个模块的目录下分别执行mvn命令。Maven聚合（或者称为多模块）这一特性就是为该需求服务的。 上图所示api是一个模块，cmd是一个模块他们都有各自的 pom 文件，其实每一个包都是一个子模块，而最底下的 pom 文件则是统一管理这些子模块。 他们的配置很简单，我们最好遵循规范。 api 的 pom.xml 12345678910111213&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;groupId&gt;com.shuiyujie.fu&lt;/groupId&gt; &lt;artifactId&gt;sop&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;api&lt;/artifactId&gt; ... cmd 的 pom.xml 123456789101112&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;groupId&gt;com.shuiyujie.fu&lt;/groupId&gt; &lt;artifactId&gt;sop&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cmd&lt;/artifactId&gt; 聚合 pom.xml 123456789101112131415161718192021&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.shuiyujie.fu&lt;/groupId&gt; &lt;artifactId&gt;pom&lt;/artifactId&gt; &lt;packaging&gt;sop&lt;/packaging&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;name&gt;sop&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; ... &lt;modules&gt; &lt;module&gt;base&lt;/module&gt; &lt;module&gt;core&lt;/module&gt; &lt;module&gt;server&lt;/module&gt; &lt;module&gt;persist&lt;/module&gt; &lt;module&gt;api&lt;/module&gt; &lt;module&gt;impl&lt;/module&gt; &lt;module&gt;cmd&lt;/module&gt; &lt;/modules&gt; ... 观察上面的三个代码清单可以聚合 pom 文件中定义了 &lt;modules&gt; 标签，标签中包含的就是各个子模块，并且用子模块的artifactId来标记他们。 注意：聚合 pom 文件的打包方式，即 packaging 必须为 pom。 这样只需要构建聚合 pom 文件即可同时构建在其管理下的多个子模块。 继承消除重复。在面向对象世界中，程序员可以使用类继承在一定程度上消除重复，在Maven的世界 中，也有类似的机制能让我们抽取出重复的配 置，这就是POM的继承。 任然看上面的三个 pom.xml 代码清单，子模块都有一个parent标签，这就表明他们继承了一个 pom 文件，而parent标签下的其他标签就是一个坐标系，通过一个坐标系就能定位一个唯一的项目。 比如上面的子模块继承自聚合 pom 文件，所以此时聚合 pom 文件也是父类 pom 文件。 排除父类的依赖在继承的过程中我们考虑一种情形，我们希望在父类中统一控制 spring 的版本，然后子类继承自父类就可以使用统一版本的 spring 依赖了。但是有些子模块不需要依赖 spring，并不需要从父类继承 spring 的依赖。 我们可以使用dependencyManagement 标签。 父类 pom.xml 123456789101112131415161718192021222324252627282930313233343536&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!-- 模块间依赖 start --&gt; &lt;dependency&gt; &lt;groupId&gt;${project.groupId}&lt;/groupId&gt; &lt;artifactId&gt;core&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;${project.groupId}&lt;/groupId&gt; &lt;artifactId&gt;persist&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;${project.groupId}&lt;/groupId&gt; &lt;artifactId&gt;api&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;${project.groupId}&lt;/groupId&gt; &lt;artifactId&gt;impl&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;${project.groupId}&lt;/groupId&gt; &lt;artifactId&gt;server&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;${project.groupId}&lt;/groupId&gt; &lt;artifactId&gt;cmd&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 模块间依赖 end --&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; 父类dependencyManagement中声明了各个子模块，子模块之间有的会需要相互引用，有的却并不需要。所以在父类中统一配置各个子模块的groupId,artifactId,version等基本信息。 在dependencyManagement中声明的依赖不会在当前pom中引入依赖，也不会再继承他的pom中引入依赖，他的作用只是声明了可能要引入依赖的一些通用信息。 如果要使用一个子模块要使用其他子模块就可以另外声明，但是不需要指定版本等通用信息，这样就可以减少依赖冲突的发生，代码如下： 1234567891011121314151617181920&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;groupId&gt;com.shuiyujie.fu&lt;/groupId&gt; &lt;artifactId&gt;sop&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;api&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;${project.parent.groupId}&lt;/groupId&gt; &lt;artifactId&gt;fu-persist&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 总结：Maven 的思想Maven 的核心思想是约定优于配置。 首先，Maven 约定了项目的结构，我们不需要配置 Maven 编译、打包等操作时文件的位置。统一的项目结构降低了学习的成本，让我能将精力集中到了项目本身。 其次，Maven 抽象了项目构建的过程，将其分成一个个生命周期进行管理。通过命令和插件的形式进一步简化操作，又让我们从繁琐的操作解放出来。 参考《Maven 实战》 Maven远程仓库的各种配置 本文大部分内容来自于《Maven 实战》一书，想要了解一手信息强烈建议阅读。网上的其他文章基本上都是摘抄《Maven 实战》的部分内容。 所以还想说一遍：发现一本好书就像发现了一座宝藏。","link":"/post/cfedc026.html"},{"title":"快，学会shell","text":"题图：https://pixabay.com/illustrations/hacker-cyber-crime-internet-2300772/ 本文分成入门篇和基础篇。基础篇包括变量、字符串处理、数学运算三部分。基础篇包括流控制、函数和函数库三部分。主要是基于例子进行讲解，其中有 4 个复杂一点的脚本，看懂了也就入门了。 我们先来聊一聊 shell 和 shell script 的概念。计算机的运行离不开硬件，我们通过操作系统（OS，Operating System）操作硬件，而我们所说的 linux 严格来说是操作系统（OS）的核心部分——内核（Kernel）。我们无法直接操作 kernel，需要借助于 kernel 外的一层壳 shell 才能与 kernel 进行交互。如果把操作系统(OS)看做是一家公司，shell 就是前台，kernel 就是董事会。当我们访问公司的时候，先和前台(shell)打个招呼，前台通知董事会(kernel)，董事会来控制公司(OS)。 俗话说“铁打的营盘流水的兵”，就是公司人来人往，都不会影响公司的运转。对于操作系统也一样，我们可以替换操作系统的前台(shell)，甚至董事会(kernel)。如果你想知道你的系统中用到的是什么 shell 可以访问 /etc/shells 文件。,我的电脑上就有下面几种 shell 1234567# /etc/shells: valid login shells/bin/sh/bin/dash/bin/bash/bin/rbash/bin/zsh/usr/bin/zsh 入门篇12345#!/bin/bashfor ((i=0; i&lt;10; i++));do echo ${i}done 直接来看一个例子吧。创建一个名为 shell001.sh 的文件，写上上面几行代码： 第 1 行，指定 shell 的解释器。shell 脚本就和 python 或者 jsp 需要用解释器来解析，第 1 行就是用于指定解释器，也就是之前提到的 /etc/shells 下面列出来的。 第 2 行，循环语句，共循环 10 次，会在后面流控制章节讲解，加上 do 和 done 是 for 循环中的语法规则，for、do、done 是 shell script 中的关键字 第 4 行，打印 i 这个变量 那么怎么运行这个脚本呢？既然是运行我们既要给它赋予可执行权限chmod +x shell001.sh，接着用 ./shell001.sh 执行这个脚本。脚本运行起来将会在终端输出 0 到 9 这几个数字。 变量前面没有解释第 4 行echo ${i}。echo 是一个简单的 linux 命令，它会将输入从到标准输出(stdout)上，然后在终端中显示出来，这里显示的就是${i}这个变量的值。 在 shell 中定义变量的规则如下： 变量和等号之间不能有空格 变量名称由字母、数字和下划线组成 变量名称的第一个字符必须是字母或者下划线 变量名称中不允许空格和标点 比如说一个变量为name=&quot;shuiyj&quot;，那么使用变量就要加上$符号，打印这个变量就使用echo ${name}。此外变量除了显示地赋值，还可以使用语句给变量赋值: 12# 获取该文件夹下后缀为 jpg 结尾的列表for image in `ls *.jpg` 变量匹配我们会定义和使用一个变量了，接下来我会介绍几个使用的处理变量的方法。 现在一张图片的名字叫做 cat.jpg，我想要获取文件的名称，即 cat。当然这有很多的中方法，这里介绍一种实用的方法——变量匹配。 语法 说明 ${变量名#匹配规则} 从变量开头进行规则匹配，将符合最短的数据删除 ${变量名##匹配规则} 从变量开头进行规则匹配，将符合最长的数据删除 ${变量名%匹配规则} 从变量结尾进行规则匹配，将符合最短的数据删除 ${变量名%%匹配规则} 从变量结尾进行规则匹配，将符合最长的数据删除 ${变量名/旧字符串/新字符串} 变量中符合规则的第一个旧字符串将会被旧字符串代替 ${变量名//旧字符串/新字符串} 变量中符合规则的所有旧字符串将会被旧字符串代替 回到最开始的需求，就可以使用%来实现 123cat=\"cat.jpg\"echo ${cat} # cat.jpgecho ${cat%.*} # cat 首先定义一个变量 cat 并为其赋值，接着用$获取 cat 变量的值并打印出来，最后使用变量替换截取字符串。 变量匹配在 shell 中会被高频使用，要记住这些规则。 特殊变量的含义shell 中有一些特殊的变量，它们有很多实用的功能，比如说校验输入的参数，允许追加更多参数，判断上一条命令是否执行成功等。 变量 含义 $0 当前脚本的文件名 $n 传递给脚本或函数的参数。n 是一个数字，表示第几个参数。例如，第一个参数是$1，第二个参数是$2 $# 传递给脚本或函数的参数个数。 $* 传递给脚本或函数的所有参数。 $@ 传递给脚本或函数的所有参数。被双引号(&quot; &quot;)包含时，与 $*稍有不同，下面将会讲到。 $? 上个命令的退出状态，或函数的返回值。 $$ 当前Shell进程ID。对于 Shell 脚本，就是这些脚本所在的进程ID。 比如说我们要对 shell 中的输入参数进行校验，可以添加这样一段 123456#!/bin/bashif [ $# != 2 ];then echo \"Usage: $0 &lt;change ID&gt; &lt;target ID&gt;\" exit -1fi... 其中$#表示输入的参数数量，我们通过条件判断在程序的输入参数不为 2 的时候将会进行提示，并退出程序。其中$0一般是可执行文件的名称。 字符串变量的话题就先讲到这里，接下来讲 shell 中处理字符串的一些注意事项和技巧。无论学习哪一门编程语言，字符串的处理都是一个绕不开的话题，并且在 shell 编程中用的最多的就是字符串。 单引号和双引号的区别字符串可以用单引号，也可以用双引号，还可以不用引号，我们要注意它们之间的区别。 123456# 单引号str='this is a string'# 双引号your_name='qinjx'str=\"Hello, I know your are \\\"$your_name\\\"! \\n\" 单引号 单引号里的任何字符都会原样输出，单引号字符串中的变量是无效的 单引号字串中不能出现单引号（对单引号使用转义符后也不行） 双引号 双引号里可以有变量 双引号里可以出现转义字符 想要了解更多它们之间的区别可以看这篇文章：shell十三问之4：””(双引号)与’’(单引号)差在哪？。 拼接字符串shell 中的字符串拼接只要直接连在一起就可以。 12345first_name=\"yujie\"last_name=\"shui\"greeting=\"hello,${first_name} ${last_name}\"echo ${greeting} 计算字符串的长度shell 中有两种方法可以计算字符串长度。 123str=\"abcde\"echo ${#str} # 5expr length \"${str}\" # 5 获取子串在字符串中的索引1expr index ${string} ${substring} 抽取子串 语法 说明 ${string:position} 从string中的position开始 ${string:position} 从position开始，并指定长度为length ${string:-position} 从右边开始匹配 ${string:(postion)} 从左边开始匹配 expr substr $string $position $length 从position开始，匹配长度为length 命令替换命令替换指的是 shell执行命令并将命令替换部分替换为执行该命令后的结果（先执行该命令，然后用结果代换到命令行中），共有有两种实现命令替换的方式： 1234# 方法一`command`# 方法二$(command) 还记得之前讲变量的时候提到变量既可以直接获取，也可以从语句获取么？ 12# 获取该文件夹下后缀为 jpg 结尾的列表for image in `ls *.jpg` 可以看到 Image 获取到的是ls *.jpg的返回值，也就是一个文件的列表。这里就用到命令替换的符号即两个反引号。 再比如获取系统的所有用户并输出 123456index=1 for user in `cat /etc/passwd | cut -d \":\" -f 1` do echo \"This is ${index} user: ${user}\" index = $(($index + 1)) done cat /etc/passwd | cut -d &quot;:&quot; -f 1将会截取用户名，由于使用了命令替换，其执行结果会返回给 user 变量，此时的 user 就是一个包含用户名称的列表。 最后再举一个使用$()的例子，比如获取系统时间计算今年或明年 12echo \"This is $(date +%Y) year\" echo \"This is $(($(date +%Y) + 1)) year\" 数学运算shell 中就两种变量，字符串和数字，数字又要按照整型和浮点型分开进行处理，处理它们的函数是不同的。整型运算需要使用expr $num1 operator $num2或者$(($num1 operator $num2))，浮点型运算则需要使用bc。 任然是通过案例的方式进行说明，假设现在有这样一个需求：提示用户输入一个正整数 num，然后计算 1+2+3+…+num 的值，并且必须对 num 是否为正整数做判断，不符合应该允许再次输入。 123456789101112131415161718#!/bin/bash#while truedo read -p \"please input a positive number: \" num expr $num + 1 &amp;&gt; /dev/null if [ $? -eq 0 ];then if [ `expr $num \\&gt; 0` -eq 1 ];then for((i=1;i&lt;=$num;i++)) do sum=`expr $sum + $i` done echo \"1+2+3+....+$num = $sum\" exit fi fi echo \"error,input enlegal\"done 这个脚本优点复杂但是不用着急，我们先关注于数学运算expr $num + 1 这一部分，其中关于if判断的部分会在下一节讲解。 expr $num + 1 意思就是做一次整数运算，将 num 和 1 相加。做这个操作的目的是判断 num 是不是一个整数，因为 expr 只能应用在整数运算上，所以执行expr $num + 1之后，如果 num 是整数退出状态就是正常的$? = 0，否则 $? ≠ 0 ，并且我们并不需要返回结果，可以将结果重定向到/dev/null中，即expr $num + 1 &amp;&gt; /dev/null。 注：在特殊变量的含义这一节可以了解$?的含义。退出状态指的是命令执行完毕之后像操作系统返回的值，成功则为 0。 expr 支持整数运算，不支持浮点数运算，要做浮点数运算那就要用到 bc。bc 是 bash 内建的运算器，支持浮点数运算，使用方法如下所示： 1234echo \"23.3+30\" | bc53.3echo \"scale=4;23.3/3.2\" | bc7.2812 基础篇在前面的入门篇，我们了解了变量、字符串和数学运算，接下来我将会介绍 shell 中流程控制的语法规则，以及 shell 中如何使用函数以及函数库。当我们掌握以上这些内容，shell 就可以算是入门了，那么就一起开始吧。 流控制流控制就是用判断语句，循环语句来控制程序执行的逻辑，就从我们在上一节数学运算中的那个脚本讲起吧，它既包含了if又包含了while循环，是一个很好的例子。 IF 控制语句123456789101112131415161718#!/bin/bash#while truedo read -p \"please input a positive number: \" num expr $num + 1 &amp;&gt; /dev/null if [ $? -eq 0 ];then if [ `expr $num \\&gt; 0` -eq 1 ];then for((i=1;i&lt;=$num;i++)) do sum=`expr $sum + $i` done echo \"1+2+3+....+$num = $sum\" exit fi fi echo \"error,input enlegal\"done 上一节中的脚本中expr $num + 1 &amp;&gt; /dev/null是关于数学运算的部分，紧跟着的if就是一个控制语句，我们抛开无关部分，开看一下关于if的骨架 12345expr $num + 1 &amp;&gt; /dev/nullif [ $? -eq 0 ];then ...fi 这里首选要进一步解释退出状态的含义。之前已经说了，退出状态指的是命令（包括脚本和函数）在执行完毕之后，向操作系统返回的值。这个值是一个 0~255 的整数，用来表示命令执行成功还是失败，其中 0 代表命令执行成功。参数$?则用于保存这个返回值。 由此可以看出if在这里做的就是判断expr $num + 1 &amp;&gt; /dev/null是否执行成功。 此外，我们也可以使用if...elif..else的形式，如下： 12345678if condition1then command1elif condition2 command2else commandNfi 此外，在实际开发过程中还经常会对文件状态进行判断，比如说判断这是不是一个文件夹、是不是一个文本文件等；或者会对字符串进行判断，比如说字符串是否为空，字符串长度是否符合要求；还会对数值进行比较操作，就像例子中提到到值是不是为 0 等。 判断表达式12345if test #表达式为真if test ! #表达式为假test 表达式1 –a 表达式2 #两个表达式都为真test 表达式1 –o 表达式2 #两个表达式有一个为真test 表达式1 ! 表达式2 #条件求反 文件表达式12345678910111213141516171819202122test File1 –ef File2 #两个文件是否为同一个文件，可用于硬连接。主要判断两个文件是否指向同一个inode。test File1 –nt File2 #判断文件1是否比文件2新test File1 –ot File2 #判断文件1比是否文件2旧test –b file #文件是否块设备文件test –c File #文件并且是字符设备文件test –d File #文件并且是目录test –e File #文件是否存在 （常用）test –f File #文件是否为正规文件 （常用）test –g File #文件是否是设置了组idtest –G File #文件属于的有效组IDtest –h File #文件是否是一个符号链接（同-L）test –k File #文件是否设置了Sticky bit位test –b File #文件存在并且是块设备文件test –L File #文件是否是一个符号链接（同-h）test –o File #文件的属于有效用户IDtest –p File #文件是一个命名管道test –r File #文件是否可读test –s File #文件是否是非空白文件test –t FD #文件描述符是在一个终端打开的test –u File #文件存在并且设置了它的set-user-id位test –w File #文件是否存在并可写test –x File #文件属否存在并可执行 字符串表达式12345678test string #string不为空test –n 字符串 #字符串的长度非零test –z 字符串 #字符串的长度是否为零test 字符串1＝字符串2 #字符串是否相等，若相等返回truetest 字符串1＝=字符串2 #字符串是否相等，若相等返回truetest 字符串1!＝字符串2 #字符串是否不等，若不等反悔falsetest 字符串1&gt;字符串2 # 在排序时，string1 在 string2 之后test 字符串1&lt;字符串2 # 在排序时，string1 在 string2 之前 整数表达式123456test 整数1 -eq 整数2 #整数相等test 整数1 -ge 整数2 #整数1大于等于整数2test 整数1 -gt 整数2 #整数1大于整数2test 整数1 -le 整数2 #整数1小于等于整数2test 整数1 -lt 整数2 #整数1小于整数2test 整数1 -ne 整数2 #整数1不等于整数2 以上表达式摘自test - shell环境中测试条件表达式工具，test 是测试条件表达式的工具，test 后面部分的内容可以用于if条件判断中。 WHILE 和 UNTIL 循环再接之前的脚本来讲解 while 的用法 123456789101112131415161718#!/bin/bash#while truedo read -p \"please input a positive number: \" num expr $num + 1 &amp;&gt; /dev/null if [ $? -eq 0 ];then if [ `expr $num \\&gt; 0` -eq 1 ];then for((i=1;i&lt;=$num;i++)) do sum=`expr $sum + $i` done echo \"1+2+3+....+$num = $sum\" exit fi fi echo \"error,input enlegal\"done 前面也说过，这个脚本的目的是接收一个 num，如果输入的 num 不是一个整数就一直让用户输入，直到输入的 num 是一个整数为止。这里就用到了 while 循环，并且将循环条件设置为 true，也就是一个永久的循环。循环不能终止，按照逻辑我们要在用户输入整数并完成计算之后推出程序,所以这里通过exit来退出程序，这里也可以使用break来跳出循环。我们还可以配合使用continue表示继续执行，这里没有举例说明。 while命令退出状态不为0时终止循环，而until命令则刚好相反。除此之外，until命令与while命令很相似。until循环会在接收到为0的退出状态时终止。在while-count脚本中，循环会一直重复到count变量小于等于5。使用until改写脚本也可以达到相同的效果。 12345678910#!/bin/bash# until-count: display a series of numberscount=1until [ $count -gt 5 ]; do echo $count count=$((count + 1))doneecho \"Finished.\" 将测试表达式改写为count –gt 5 until就可以在合适的时刻终止循环。选择使用while还是until，通常取决于哪种循环能够允许程序员写出最明了的测试表达式。 case 分支前面讲了使用if做条件判断，在其他语言比如 C++ 或者 Java 等中都存在switch..case..这样的语句，shell 也提供了case这个多选项符合命令，它的命令格式是这样的： 123case word in [pattern [| pattern]...) commands ;;]...esac 在这里我想举一个做算数运算的例子，这和例子与下一节讲解的函数相关，其中用到了case，但是即使不了解函数怎么使用，也不会对理解case的运用造成影响。 1234567891011121314151617181920#!/bin/bash#function calcu{ case $2 in +) echo \"`expr $1 + $3`\" ;; -) echo \"`expr $1 - $3`\" ;; \\*) echo \"`expr $1 \\* $3`\" ;; /) echo \"`expr $1 / $3`\" ;; esac}calcu $1 $2 $3 这个脚本希望做的是一次算数运算，根据操作符是+ - * /来进行运算。 for 循环现在到了流控制的最后一节了，for 循环其实在文章一开始我们就见过了，在文章最开始我举了两个例子： 1234567891011# 获取该文件夹下后缀为 jpg 结尾的列表for image in `ls *.jpg`do ....done# 输出 0-9 共 10 个数字for ((i=0; i&lt;10; i++));do echo ${i}done 第一种是传统的形式，和 python 中的 for 循环很像，我们可以像这样for i in A B C D;do echo $i; done使用 for 循环，可以将循环的内容就当成 python 中的一个列表，也可以像for i in {A..E};do echo $i; done这样创建字符列表。 第二种方式就是 C 语言的形式了for ((i=0; i&lt;10; i++))，比较常规也没什么值得讲的。 函数在上一节中，我们介绍了 shell 中的流控制的语法：if, while, until, case和 for。再之前我们讲了变量、字符串和数学运算。到这一节就可以讲一下函数这个话题了。 了解了上面这些内容理论上已经能够写出任何的程序的，不过写程序的过程中会有许多类似的代码，如果全部重新写一遍程序就会显得冗长，所以一般的做法就是将可以复用的代码抽取出来形成函数。shell 自然也支持函数的使用，接下里就看看在 shell 中怎么定义和使用函数。 首先看 shell 中函数是怎么定义的。shell 中的函数有两种定义格式，使用任意一种都可以。 1234567name(){ command1 command2 ... commandn} 1234567function name{ command1 command2 ... commandn} 我比较习惯用第二种形式，你可以选择任何一种方式，不过我接下来的例子是按照第二种定义方式。 我们知道了函数定义的架构，但是如果你用过其他编程语言会发现它没有参数列表，也没有返回值，这在一开始也让我觉得很困惑，但是我们在变量那一节学过特殊变量的含义，其中有一个变量是$0表示函数的名称，shell 中的变量是通过命令行键入，再用$1 $2 $3读取的。这就和 C++ 或者 Java 中的主函数读取参数一个道理，char** argv和String[] args就是由命令行键入的参数列表。 下面就用一个具体函数的例子进行说明，这个例子在 流控制——case 这一节也讲过，但是没有讲完： 12345678910111213141516171819202122#!/bin/bash#function calcu{ case $2 in +) echo \"`expr $1 + $3`\" ;; -) echo \"`expr $1 - $3`\" ;; \\*) echo \"`expr $1 \\* $3`\" ;; /) echo \"`expr $1 / $3`\" ;; esac}calcu $1 $2 $3echo \"\"calcu $1 $2 $3\"\" 首先这个脚本的文件名为 calcu，其中定义了一个函数 calcu，采用的是第二种函数定义方式，在函数体中我们利用case做了一个多条件判断。 在脚本的结尾我们调用了 calcu 这个函数，并将输入了三个参数，紧接着为了给大家看到三个参数分别是什么我选择将其打印出来。调用函数的过程是这样的： 123ubuntu@VM-0-2-ubuntu:/tmp$ ./calcu.sh 5 + 38calcu 5 + 3 可以看到在这里$1 = 5, $2 = +, $3 = 3，这就是 shell 中传递参数的方式。 再看 shell 中返回值这个问题，shell 有两种返回值的方式，一种是使用return，一种是使用echo。 使用return 使用 return 返回值，只能返回 1-255 的整数 函数使用 return 返回值。通常只能用来供其他地方调用获取状态，因此通常仅返回0或1；0表示成功，1表示失败 使用echo 使用 echo 可以返回任何字符串结果 通常用于返回数据，比如一个字符串值或者列表值 echo的内容作为返回值可以看一下上面这个例子，这里再举一个return来返回值的例子。 12345678910111213#!/bin/bash#this_pid=$$function is_nginx_running{ ps -ef | grep nginx | grep -v grep | grep -v $this_pid &amp;&gt; /dev/null if [ $? -eq 0 ];then return else return 1 fi}is_nginx_running &amp;&amp; echo \"Nginx is running\" || echo \"Nginx is stoped\" 和前面说过的退出状态一样，return 也是 0 表示函数执行成功，其他表示执行失败。这里举的例子是通过查看 Nginx 的进程来来确认 Nginx 是否运行。 首先是用$$来接收这个 shell 脚本的 Pid，因为脚本名字中带有 Nginx 就需要将其利用 Pid 过滤掉。还记得之前讲的的退出状态么，如果 ps 命令找到了 nginx 进程退出状态就会是 0，表示成功。最后就通过return来返回 nginx 是否正常运行。 之后可以用后台挂起的形式运行这个脚本，将其作为 nginx 的守护进程：nohup sh nginx.sh &amp;，使用tail -f nohup.out来查看监听结果。 局部变量和全局变量讲到函数就还有一个作用域的问题需要讨论，shell 中的局部变量、全局变量和一般编程语言没什么区别。 12345678910#!/bin/bash#var1=\"Hello world\"function test{ local var2=87}testecho $var1echo $var2 这里给到一个脚本自行体会一下即可。 函数库基础篇的最后一部分就用来介绍一下 shell 中的函数库。函数库是每一门编程语言中非常重要的一部分，比如说 C++ 中的标准库，Java 中的 JDK，正式这些优秀的库存在才让编程变得更加高效。 shell 也是可以封装自己的库的，比如我现在下一个你要加加减乘除封装成一个函数库，作为之前 calcu 脚本的升级版，该函数库实现以下几个函数： 加法函数 add 减法函数 reduce 乘法函数 multiple 除法函数 divide 打印系统运行情况的函数 sys_load，该函数显示内存运行情况， 1234567891011121314151617181920212223242526272829function add{ echo \"`expr $1 + $2`\"}function reduce{ echo \"`expr $1 - $2`\"}function multiple{ echo \"`expr $1 \\* $2`\"}function divide{ echo \"`expr $1 / $2`\"}function sys_load{ echo \"Memory Info\" echo free -m echo echo \"Disk Usage\" echo df -h echo} 我们将上面文件封装成一个函数库 lib/base_function。 经常使用的重复代码封装成函数文件 一般不直接执行，而是由其他脚本调用 接着用一个 shell 脚本 calculate.sh 调用函数库中的函数 1234567#!/bin/bash#. /root/lesson/3.5/lib/base_functionadd 12 23reduce 90 30multiple 12 12divide 12 2 编写函数库文件的建议 库文件名的后缀是任意的，但一般使用 .lib 库文件通常没有可执行选项 库文件无序和脚本在同级目录，只需在脚本中引用时指定 第一行一般使用 #/bin/echo, 输出警告信息，避免用户执行 参考资料《Linux 命令行大全》 Shell脚本编程30分钟入门 Awesome Shell","link":"/post/92782b0b.html"},{"title":"Java 多线程基础知识","text":"计算机发明之初，单个 CPU 在同一时间点只能执行单个任务，也就是单任务阶段。紧接着发展为多任务阶段，在单个 CPU 上能执行多个进程，但是此处的并行执行并不是指在同一时间执行多个任务，而是指由系统对进程进行调度轮流使用 CPU。 接着发展到现在的多线程阶段，一个程序内部能够运行多个线程，每个线程都可以被看做运行在一个 CPU 上，此时计算机真正做到了在同一时间点能够执行多个任务。 进程和线程进程和线程怎么界定？一个进程包含着一个或多个线程。 当我们启动一个应用程序的时候，操作系统将加载这个应用程序并为当前程序开辟一块独立的内存空间，这片空间就专门用来负责这个程序的运行。这就是一个进程，我们可以把它想象成一个车间。 假设我们启动的程序是微信，我们可以使用微信和多个人聊天并且互不干扰。同时和不同的人聊天就是将进程划分成多个区域，每个区域就是一个线程。如果把进程比作车间，线程就像车间中的工人，工人们各司其职维持车间的正常运转。 多线程运行原理多线程就是在一个进程中开启多个线程，让多个线程去实现不同功能。多线程最常见的就是 GUI 程序，比如说使用 IDE 运行程序的同时我们还能用 IDE 继续写代码，这就用到了多线程。 多线程运行则是利用 CPU 在线程中做时间片切换。CPU 负责运行程序且一次只能运行一个程序，多线程的实现依靠 CPU 在线程间快速切换，由于切换的时间很快就像同时运行多个线程一样。 多线程切换过程中，它需要先存储当前线程的本地的数据，程序指针等，然后载入另一个线程的本地数据，程序指针等，最后才开始执行。所以多线程一般能提高程序运行效率，但也不能无节制地开启线程。 Java 实现多线程的两种方式多线程的两种创建方式分别为继承 Thread 类以及实现 Runnable 接口。一般用实现 Runnable 接口的方式。 我们通过调用线程的 start() 方法新建一个线程并启动它，下面是两种主要实现方式的示例。 继承 Thread 类123456789101112131415161718public class MyThread1 extends Thread { private int count = 5; @Override public void run() { for (int i = 5; i &gt; 0 &amp;&amp; count&gt;0; i--,count--) { System.out.println(\"count----\" + count); } } public static void main(String[] args) { new MyThread1().start(); new MyThread1().start(); new MyThread1().start(); }} 可以创建一个实例直接 start()，因为 Thread 类中定义了 start() 方法。 实现 Runnable 接口123456789101112131415161718public class MyThread2 implements Runnable{ private int count = 5; @Override public void run() { for (int i = 5; i &gt; 0 &amp;&amp; count&gt;0; i--,count--) { System.out.println(\"count----\" + count); } } public static void main(String[] args) { MyThread2 myThread2 = new MyThread2(); new Thread(myThread2).start(); new Thread(myThread2).start(); new Thread(myThread2).start(); }} 但是他无法直接创建实例之后直接 start(),查看源码可以看到 Runnable 接口只有一个 run() 方法没有 start()方法，所以他必须由 Thread 来启动。 两者优缺点比较实现 Runable() 避免由于 Java 的单继承特性而带来的局限Java 使用 extends 关键字实现继承，可以理解成全盘接受了父类的特性。使用 implents 关键字实现接口，对类的功能进行拓展。要注意的是 Java 的继承是单继承，也就是只能继承一个父类。但是每个类都能实现多个接口。 当一个类需要实现多线程的时候，如果他已经继承了其他的父类则不能再继承 Thread 类，但是即使他实现了其他接口，他任然能实现 Runable 接口创建多线程。 但是当我们访问当前线程时需要使用Thread.currentThread()方法。 继承 Thread 类编写简单，方便理解通过继承 Thread 类的方法实现多线程，调用当前类只需要使用 this 关键字即可进行访问。但是使用这种方式之后就不能继承其他父类。 因此一般都是用实现 Runable() 接口的形式。本篇中使用显示创建线程的方式，而创建线程更好的方式是使用线程池。 多线程 run() 和 start() 的区别通过运行run()方法和start()方法，看看输出结果有什么区别。 run() 方法1234567891011121314151617181920212223public class MyThread3 extends Thread { private int count = 5; @Override public void run() { for (int i = 5; i &gt; 0 &amp;&amp; count&gt;0; i--,count--) { System.out.println(this.currentThread().getName() + \"----count----\" + count); } } public static void main(String[] args) { MyThread3 myThread1 = new MyThread3(); myThread1.setName(\"Thread1\"); myThread1.run(); MyThread3 myThread2 = new MyThread3(); myThread2.setName(\"Thread2\"); myThread2.run(); }} 输出结果为： 12345678910thread1----count----5thread1----count----4thread1----count----3thread1----count----2thread1----count----1thread2----count----5thread2----count----4thread2----count----3thread2----count----2thread2----count----1 Thread1 和 Thead2 只是在主线程上顺序执行，并没有开启新的线程。 start() 方法如果将 run() 改成 start()输出结果为: 1234567thread2---count----5thread3---count----5thread1---count----5thread3---count----3thread3---count----1thread2---count----4thread1---count----2 可以看到两个线程在抢占资源，成功创建了两个线程。 结果对比创建了两个相同的线程对象，但是结果有明显的差异。run() 的运行结果始终是顺次递减，线程1执行完之后再执行线程2，表明他们是在主线程上顺序运行，并没有开启新的线程。 但是使用start()方法则可以看到线程1和线程2在竞争资源，说明成功开启了两个线程。 线程 start() 和 run() 的区别先看一下 Runnable 接口 123public interface Runnable { public abstract void run();} 其中只有一个 run() 方法，注释是这么写的： When an object implementing interface Runnable is used to create a thread 所以用于实现了 run() 方法的对象可以被用于创建一个线程 再看 Thread 类 12345678910public class Thread implements Runnable { /* What will be run. */ private Runnable target; @Override public void run() { if (target != null) { target.run(); } } Thread 实现了 Runable 的接口,可以传入一个 Runnable，执行 Runnable 的 run() 方法,他说: If this thread was constructed using a separate Runnable run object, then that Runnable object’s run method is called; otherwise, this method does nothing and returns. 说明 Thread 类的作用就是用于运行 Runable 的实例，将实现了 Runable 方法的实例传入 Thread 类就可以运行该实例的run()方法 再看start() 方法的说明： 使用 start() 让线程会调用run()之后在虚拟机上执行 Causes this thread to begin execution; the Java Virtual Machine calls the run method of this thread. 12345678public synchronized void start() { if (threadStatus != 0) throw new IllegalThreadStateException(); /*把线程加到线程组中，表示这个线程将会被执行*/ group.add(this); ... } run() 只是在当前线程中启动，start() 才是真正新建一个线程并启动。 参考进程与线程的一个简单解释","link":"/post/1d67cce0.html"},{"title":"RocketMQ Start","text":"RocketMQ 是一款分布式、队列模型的消息中间件，具有以下特点： 能够保证严格的消息顺序 提供丰富的消息拉取模式 高效的订阅者水平扩展能力 实时的消息订阅机制 亿级消息堆积能力 今天开始试着理解她。 快速开始环境要求 64bit OS, Linux/Unix/Mac is recommended; 64bit JDK 1.8+; Maven 3.2.x Git 准备工作下载安装包 here 到服务器中，本文使用的是rocketmq-all-4.2.0。 unzip rocketmq-all-4.2.0-source-release.zipcd rocketmq-all-4.2.0/mvn -Prelease-all -DskipTests clean install -U 没有注意环境，maven 版本为 3.0.5，升级 maven 到 3.5.2 cd distribution/target/apache-rocketmq 启动 Name Server nohup sh bin/mqnamesrv &amp;tail -f ~/logs/rocketmqlogs/namesrv.logThe Name Server boot success… 启动 Broker nohup sh bin/mqbroker -n localhost:9876 &amp;tail -f ~/logs/rocketmqlogs/broker.log 错误：启动不成功，看错误日志 1234567891011121314151617181920212223## There is insufficient memory for the Java Runtime Environment to continue.# Native memory allocation (mmap) failed to map 8589934592 bytes for committing reserved memory.# Possible reasons:# The system is out of physical RAM or swap space# In 32 bit mode, the process size limit was hit# Possible solutions:# Reduce memory load on the system# Increase physical memory or swap space# Check if swap backing store is full# Use 64 bit Java on a 64 bit OS# Decrease Java heap size (-Xmx/-Xms)# Decrease number of Java threads# Decrease Java thread stack sizes (-Xss)# Set larger code cache with -XX:ReservedCodeCacheSize=# This output file may be truncated or incomplete.## Out of Memory Error (os_linux.cpp:2640), pid=3437, tid=0x00007f378a5c2700## JRE version: (8.0_151-b12) (build )# Java VM: Java HotSpot(TM) 64-Bit Server VM (25.151-b12 mixed mode linux-amd64 compressed oops)# Core dump written. Default location: /apps/rocketmq-all-4.2.0/distribution/core or core.3437# 原因：rocketmq默认jvm配置较高，导致内存不足 runserver.sh 12345JAVA_OPT=&quot;${JAVA_OPT} -server -Xms4g -Xmx4g -Xmn2g -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m&quot;改成JAVA_OPT=&quot;${JAVA_OPT} -server -Xms256m -Xmx256m -Xmn128m -XX:PermSize=128m -XX:MaxPermSize=320m&quot; runbroker.sh 12345JAVA_OPT=&quot;${JAVA_OPT} -server -Xms8g -Xmx8g -Xmn4g&quot;改成：JAVA_OPT=&quot;${JAVA_OPT} -server -Xms256m -Xmx256m -Xmn128m&quot; tools.sh 12345JAVA_OPT=&quot;${JAVA_OPT} -server -Xms1g -Xmx1g -Xmn256m -XX:PermSize=128m -XX:MaxPermSize=128m&quot;改成JAVA_OPT=&quot;${JAVA_OPT} -server -Xms256m -Xmx256m -Xmn128m -XX:PermSize=128m -XX:MaxPermSize=128m&quot; 再次启动 Broker 成功 The broker[main, 192.168.0.222:10911] boot success. serializeType=JSON and name server is localhost:9876 查看一下服务 Jps 1234[root@main apache-rocketmq]# jps4419 BrokerStartup4636 Jps4077 NamesrvStartup 发送接收消息 123456&gt; export NAMESRV_ADDR=localhost:9876&gt; sh bin/tools.sh org.apache.rocketmq.example.quickstart.ProducerSendResult [sendStatus=SEND_OK, msgId= ...&gt; sh bin/tools.sh org.apache.rocketmq.example.quickstart.ConsumerConsumeMessageThread_%d Receive New Messages: [MessageExt... 停止服务 12sh bin/mqshutdown brokersh bin/mqshutdown namesrv 使用 RocketMQ Console 监控在 Tomcat 中部署 RocketMQ Console，可以看到 RocketMQ 的运行情况。 RocketMQ 扩展项目地址将项目 clone 到本地，进入rocketmq-console，参考项目文档编译。 修改application.properties文件 rocketmq.config.namesrvAddr= 192.168.0.222:9876 编译运行文件 mvn clean package -Dmaven.test.skip=truejava -jar target/rocketmq-console-ng-1.0.0.jar 在浏览器访问192.168.0.222:8080即可访问监控界面，就能看到 RocketMQ 的基本信息。 客户端访问NameService 和 BrokerService已经启动，现在单机模式下用客户端来实现消息的订阅和发送。 Producer123456789101112131415161718192021222324252627282930public class TestProducer { public static void main(String[] args) throws MQClientException, InterruptedException { DefaultMQProducer producer = new DefaultMQProducer(\"DefaultCluster\"); producer.setNamesrvAddr(\"192.168.0.222:9876\"); producer.start(); for (int i = 0; i &lt; 100; i++) { try { { Message msg = new Message(\"TopicTest1\", \"TagA\", \"key113\", \"Hello world\".getBytes(RemotingHelper.DEFAULT_CHARSET)); SendResult sendResult = producer.send(msg); System.out.printf(\"%s%n\", sendResult); QueryResult queryMessage = producer.queryMessage(\"TopicTest1\", \"key113\", 10, 0, System.currentTimeMillis()); for (MessageExt m : queryMessage.getMessageList()) { System.out.printf(\"%s%n\", m); } } } catch (Exception e) { e.printStackTrace(); } } producer.shutdown(); }} Consumer1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class PullConsumer { private static final Map&lt;MessageQueue, Long&gt; OFFSE_TABLE = new HashMap&lt;MessageQueue, Long&gt;(); public static void main(String[] args) throws MQClientException { DefaultMQPullConsumer consumer = new DefaultMQPullConsumer(\"DefaultCluster\"); consumer.setNamesrvAddr(\"192.168.0.222:9876\"); consumer.start(); Set&lt;MessageQueue&gt; mqs = consumer.fetchSubscribeMessageQueues(\"TopicTest1\"); for (MessageQueue mq : mqs) { System.out.printf(\"Consume from the queue: %s%n\", mq); SINGLE_MQ: while (true) { try { PullResult pullResult = consumer.pullBlockIfNotFound(mq, null, getMessageQueueOffset(mq), 32); System.out.printf(\"%s%n\", pullResult); putMessageQueueOffset(mq, pullResult.getNextBeginOffset()); switch (pullResult.getPullStatus()) { case FOUND: break; case NO_MATCHED_MSG: break; case NO_NEW_MSG: break SINGLE_MQ; case OFFSET_ILLEGAL: break; default: break; } } catch (Exception e) { e.printStackTrace(); } } } consumer.shutdown(); } private static long getMessageQueueOffset(MessageQueue mq) { Long offset = OFFSE_TABLE.get(mq); if (offset != null) return offset; return 0; } private static void putMessageQueueOffset(MessageQueue mq, long offset) { OFFSE_TABLE.put(mq, offset); }} 从控制台可以看到集群的基本信息，包括消息的产生和消费数量等。 RocketMQ 单机模式跑通，接下来使用双 master 模式。 部署 RockerMQ 双 Master 模式 参考资料Apache RocketMQRocket-Externals安装rocketmq-consoleMaven 升级","link":"/post/20e9366a.html"},{"title":"部署 RockerMQ 双 Master 模式","text":"本文介绍搭建双 master 的 RocektMQ 的集群。 RocketMQ集群方式首先要部署一个 RocketMQ 的集群，以下集群方式摘自网络。 推荐的几种 Broker 集群部署方式，这里的 Slave 不可写但可读，类似于 Mysql 主备方式。 单个 Master这种方式风险较大，一旦Broker 重启或者宕机时，会导致整个服务不可用，不建议线上环境使用。 多 Master 模式一个集群无 Slave，全是 Master，例如 2 个 Master 或者 3 个 Master。 优点 配置简单，单个 Master 宕机或重启维护对应用无影响，在磁盘配置为 RAID10 时，即使机器宕机不可恢复情况下，由与 RAID10 磁盘非常可靠，消息也不会丢（异步刷盘丢失少量消息，同步刷盘一条不丢） 。性能最高。 缺点 单台机器宕机期间，这台机器上未被消费的消息在机器恢复之前不可订阅，消息实时性会受到受到影响。 启动顺序 先启动 NameServer 再机器 A，启动第一个 Master 再机器 B，启动第二个 Master 多 Master 多 Slave 模式，异步复制每个 Master 配置一个 Slave，有多对Master-Slave，HA 采用异步复制方式，主备有短暂消息延迟，毫秒级。 优点 即使磁盘损坏，消息丢失的非常少，且消息实时性不会受影响，因为 Master 宕机后，消费者仍然可以从 Slave 消费，此过程对应用透明。不需要人工干预。性能同多 Master 模式几乎一样。 缺点 Master 宕机，磁盘损坏情况，会丢失少量消息。 启动顺序 启动 NameServer 机器 A，启动第一个 Master 机器 B，启动第二个 Master 机器 C，启动第一个 Slave 机器 D，启动第二个 Slave 多 Master 多 Slave 模式，同步双写每个 Master 配置一个 Slave，有多对Master-Slave，HA 采用同步双写方式，主备都写成功，向应用返回成功。 优点 数据与服务都无单点，Master宕机情况下，消息无延迟，服务可用性与 数据可用性都非常高 缺点 性能比异步复制模式略低，大约低 10%左右，发送单个消息的 RT 会略高。目前主宕机后，备机不能自动切换为主机，后续会支持自动切换功能 。 启动顺序 启动 NameServer 机器 A，启动第一个 Master 机器 B，启动第二个 Master 机器 C，启动第一个 Slave 机器 D，启动第二个 Slave 以上 Broker 与 Slave 配对是通过指定相同的brokerName 参数来配对，Master 的 BrokerId 必须是 0，Slave 的BrokerId 必须是大与 0 的数。另外一个 Master 下面可以挂载多个 Slave，同一 Master 下的多个 Slave通过指定不同的 BrokerId 来区分。 部署双 master 模式的集群出于简单和可用的考虑，本文使用双 master 的方式部署 RocketMQ 集群。更多细节看上一篇文章RocketMQ Start，我们用上篇文章中相同的方式再部署一台主机。 服务器环境 序号 IP 用户名 角色 模式 1 192.168.0.222 root nameService1,brokerServer1 Master 2 192.168.0.255 Root nameService2,brokerServer2 Master2 修改 hosts vi /etc/hosts IP Name 192.168.0.222 rocketmq-nameserver1 192.168.0.222 rocketmq-master1 192.168.0.225 rocketmq-nameserver2 192.168.0.225 rocketmq-master2 修改配置文件修改目标文件： /usr/local/rocketmq/conf/2m-noslave 该目录下有两个文件,分别修改一个，与下面的配置文件的 brokerName 对应 broker-a.properties broker-b.properties 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#所属集群名字 brokerClusterName=rocketmq-cluster #broker名字，注意此处不同的配置文件填写的不一样brokerName=broker-a|broker-b#0 表示 Master，&gt;0 表示 Slave brokerId=0 #nameServer地址，分号分割namesrvAddr=rocketmq-nameserver1:9876;rocketmq-nameserver2:9876 #在发送消息时，自动创建服务器不存在的topic，默认创建的队列数defaultTopicQueueNums=4 #是否允许 Broker 自动创建Topic，建议线下开启，线上关闭autoCreateTopicEnable=true #是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭autoCreateSubscriptionGroup=true #Broker 对外服务的监听端口 listenPort=10911 #删除文件时间点，默认凌晨 4点 deleteWhen=04 #文件保留时间，默认 48 小时fileReservedTime=120#commitLog每个文件的大小默认1GmapedFileSizeCommitLog=1073741824#ConsumeQueue每个文件默认存30W条，根据业务情况调整mapedFileSizeConsumeQueue=300000#destroyMapedFileIntervalForcibly=120000#redeleteHangedFileInterval=120000#检测物理文件磁盘空间diskMaxUsedSpaceRatio=88#存储路径 storePathRootDir=/usr/local/rocketmq/store #commitLog 存储路径 storePathCommitLog=/usr/local/rocketmq/store/commitlog #消费队列存储路径存储路径storePathConsumeQueue=/usr/local/rocketmq/store/consumequeue#消息索引存储路径storePathIndex=/usr/local/rocketmq/store/index#checkpoint 文件存储路径storeCheckpoint=/usr/local/rocketmq/store/checkpoint#abort 文件存储路径abortFile=/usr/local/rocketmq/store/abort#限制的消息大小imaxMessageSize=65536#flushCommitLogLeastPages=4 #flushConsumeQueueLeastPages=2 #flushCommitLogThoroughInterval=10000 #flushConsumeQueueThoroughInterval=60000#Broker 的角色 #- ASYNC_MASTER 异步复制Master #- SYNC_MASTER 同步双写Master #- SLAVE brokerRole=ASYNC_MASTER#刷盘方式 #- ASYNC_FLUSH 异步刷盘 #- SYNC_FLUSH 同步刷盘 flushDiskType=ASYNC_FLUSH#checkTransactionMessageEnable=false#发消息线程池数量 #sendMessageThreadPoolNums=128 #拉消息线程池数量 #pullMessageThreadPoolNums=128 配置存储路径从配置文件中可以看到需要配置一些文件的存储位置，只要文件中配置的目录存在即可 123456789101112#存储路径 storePathRootDir=/usr/local/rocketmq/store #commitLog 存储路径 storePathCommitLog=/usr/local/rocketmq/store/commitlog #消费队列存储路径存储路径storePathConsumeQueue=/usr/local/rocketmq/store/consumequeue#消息索引存储路径storePathIndex=/usr/local/rocketmq/store/index#checkpoint 文件存储路径storeCheckpoint=/usr/local/rocketmq/store/checkpoint#abort 文件存储路径abortFile=/usr/local/rocketmq/store/abort 分别修改日志配置文件 mkdir -p /usr/local/rocketmq/logscd /usr/local/rocketmq/conf &amp;&amp; sed -i ‘s#${user.home}#/usr/local/rocketmq#g’ *.xml 修改 JVM 参数runserver.sh 12345JAVA_OPT=&quot;${JAVA_OPT} -server -Xms4g -Xmx4g -Xmn2g -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m&quot;改成JAVA_OPT=&quot;${JAVA_OPT} -server -Xms256m -Xmx256m -Xmn128m -XX:PermSize=128m -XX:MaxPermSize=320m&quot; runbroker.sh 12345JAVA_OPT=&quot;${JAVA_OPT} -server -Xms8g -Xmx8g -Xmn4g&quot;改成：JAVA_OPT=&quot;${JAVA_OPT} -server -Xms256m -Xmx256m -Xmn128m&quot; tools.sh 12345JAVA_OPT=&quot;${JAVA_OPT} -server -Xms1g -Xmx1g -Xmn256m -XX:PermSize=128m -XX:MaxPermSize=128m&quot;改成JAVA_OPT=&quot;${JAVA_OPT} -server -Xms256m -Xmx256m -Xmn128m -XX:PermSize=128m -XX:MaxPermSize=128m&quot; 启动两台主机的 NameServer cd /usr/local/rocketmq/binnohup sh mqnamesrv &amp; 启动BrokerServer A nohup sh mqbroker -c /usr/local/rocketmq/conf/2m-noslave/broker-a.properties &gt;/dev/null 2&gt;&amp;1 &amp;netstat -ntlptail -f -n 500 /usr/local/rocketmq/logs/rocketmqlogs/broker.logtail -f -n 500 /usr/local/rocketmq/logs/rocketmqlogs/namesrv.log 启动BrokerServer A nohup sh mqbroker -c /usr/local/rocketmq/conf/2m-noslave/broker-b.properties &gt;/dev/null 2&gt;&amp;1 &amp;netstat -ntlptail -f -n 500 /usr/local/rocketmq/logs/rocketmqlogs/broker.logtail -f -n 500 /usr/local/rocketmq/logs/rocketmqlogs/namesrv.log 数据清理12345678910111213cd /usr/local/rocketmq/bin sh mqshutdown brokersh mqshutdown namesrv*等待停止 *rm -rf /usr/local/rocketmq/storemkdir /usr/local/rocketmq/storemkdir /usr/local/rocketmq/store/commitlogmkdir /usr/local/rocketmq/store/consumequeue mkdir /usr/local/rocketmq/store/index*重复以上步骤重启NameServer与BrokerServer*","link":"/post/6fc5439d.html"},{"title":"RabbitMQ 安装和使用","text":"RabbitMQ 是一个消息队列，主要是用来实现应用程序的异步和解耦，同时也能起到消息缓冲，消息分发的作用。本文介绍RabbitMQ 安装和使用。 RabbitMQ 是一个开源的AMQP实现，服务器端用Erlang语言编写，支持多种客户端，如：Python、Ruby、.NET、Java、JMS、C、PHP、ActionScript、XMPP、STOMP等，支持AJAX。用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。 可以把消息队列想象成邮局，你的笔友把信件投递到邮局，邮递员源源不断地进出邮局，把笔友的信送到你的手里。此时的笔友就是一个生产者（Product）,邮递员一次送信就是（Queue）,而你收信就像是消费者（Consumer）。 AMQPAMQP（Advanced Message Queuing Protocol，高级消息队列协议）的原始用途只是为金融界提供一个可以彼此协作的消息协议，而现在的目标则是为通用消息队列架构提供通用构建工具。消息中间件主要用于组件之间的解耦，消息的发送者无需知道消息使用者的存在，反之亦然。AMQP的主要特征是面向消息、队列、路由（包括点对点和发布/订阅）、可靠性、安全。 RabbitMQ 则是一个开源的 AMQP 实现。 Rabbit 概念通常我们谈到队列服务, 会有三个概念： 发消息者、队列、收消息者，RabbitMQ 在这个基本概念之上, 多做了一层抽象, 在发消息者和 队列之间, 加入了交换器 (Exchange)。这样发消息者和队列就没有直接联系, 转而变成发消息者把消息给交换器, 交换器根据调度策略再把消息再给队列。 通过 RabbitMQ 官网 的示例中看到 RabbitMQ 有六种模式。 官网中有多种语言的实现，本文用 Java 来实现。采用 Springboot 集成 RabbitMQ。 CentOS 安装 RabbitMQ安装 Erlang、Elixir准备 yum update yum install epel-release yum install gcc gcc-c++ glibc-devel make ncurses-devel openssl-devel autoconf java-1.8.0-openjdk-devel git wget wxBase.x86_64 安装 Erlang wget http://packages.erlang-solutions.com/erlang-solutions-1.0-1.noarch.rpm rpm -Uvh erlang-solutions-1.0-1.noarch.rpm yum update yum install erlang 验证是否安装成功，输入命令：erl 安装 Elixir因为 EPEL 中的 Elixir 版本太老，所以下面是通过源码编译安装的过程： git clone https://github.com/elixir-lang/elixir.git cd elixir/ make clean test export PATH=”$PATH:/usr/local/elixir/bin” 验证是否安装成功，输入命令：iex 安装 RabbitMQ wget https://www.rabbitmq.com/releases/rabbitmq-server/v3.6.1/rabbitmq-server-3.6.1-1.noarch.rpm rpm –import https://www.rabbitmq.com/rabbitmq-signing-key-public.asc yum install rabbitmq-server-3.6.1-1.noarch.rpm Rabitmq 管理至此已经安装完成，下面介绍启动和自动开机启动命令和配置 启动： systemctl start rabbitmq-server 开机自动启动： systemctl enable rabbitmq-server 查看 rabbitmq-server 状态： rabbitmqctl status 关闭： systemctl enable rabbitmq-server 可以直接通过配置文件的访问进行管理，也可以通过Web的访问进行管理。 通过Web进行管理,开启 Web 管理: rabbitmq-plugins enable rabbitmq_management chown -R rabbitmq:rabbitmq /var/lib/rabbitmq/ 注：先启动 RabbitMQ 访问：http://192.168.2.223:15672/，默认用户 guest ，密码 guest。 发现登录失败，由于账号guest具有所有的操作权限，并且又是默认账号，出于安全因素的考虑，guest用户只能通过localhost登陆使用。 我们新增一个用户： rabbitmqctl add_user admin 123456 rabbitmqctl set_user_tags admin administrator rabbitmqctl set_permissions -p / admin “.“ “.“ “.*” Springboot 集成 RabbitMQ假设现在已经按照前面的步骤完成了 RabbitMQ 的安装，现在开始使用 Springboot 集成 RabbitMQ。 基本配置IDEA 先新建一个 maven 项目，在 pom 文件中添加相关依赖: pom 文件1234567891011121314151617181920212223242526272829303132333435363738&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.shuiyujie&lt;/groupId&gt; &lt;artifactId&gt;pom&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;name&gt;pom&lt;/name&gt; &lt;!-- Spring Boot 启动父依赖 --&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.2.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Test 依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- rabbitmq --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; application.properties123456# rabbitmq 配置文件spring.rabbitmq.host=192.168.0.223# 默认端口spring.rabbitmq.port=5672spring.rabbitmq.username=adminspring.rabbitmq.password=123456 “Hello World” 现在我们的目标很简单就是创建一个生产者 P，和一个消费者 C，同时将 P 产生的消息放到队列中供 C 使用。 Queue 1234567891011import org.springframework.amqp.core.Queue;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class RabbitConfig { @Bean public Queue helloQueue() { return new Queue(&quot;hello&quot;); }} HelloSender 123456789101112@Controllerpublic class HelloSender { @Autowired private AmqpTemplate rabbitTemplate; public void send() { String context = \"hello \" + new Date(); System.out.println(\"Sender : \" + context); this.rabbitTemplate.convertAndSend(\"hello\", context); }} HelloReceiver 12345678@Componentpublic class HelloReceiver { @RabbitHandler @RabbitListener(queues = \"hello\") public void process(String hello) { System.out.println(\"Receiver : \" + hello); }} 运行 123456789101112@RunWith(SpringRunner.class)@SpringBootTest(classes = HelloApplication.class)public class RabbitmqApplicationTests { @Autowired private HelloSender helloSender; @Test public void hello() throws Exception { helloSender.send(); }} 成功接收到消息 1Receiver : hello Thu Feb 01 22:21:39 CST 2018 注意：HelloReceiver的@RabbitListener(queues = &quot;hello&quot;)注解是方法级的，参照别的文章都是类级别的注解导致一直无法正常连接。 Work Queues Work Queues 模式在原来的基础上多增加了一个消费者。同理我们可以扩展三个、四个甚至更多的consumer。这样做的好处在于，当我们使用一个consumer的时候，当它收到一条消息进行处理的时候会发生阻塞。有多个consumer时，消息就可以分发给空闲的consumer进行处理。 生产者 123456789101112131415161718/** * Work 模式下的生产者 * * @author shui * @create 2018-02-04 **/@Controllerpublic class WorkSender { @Autowired private AmqpTemplate rabbitTemplate; public void send(int i) { String context = \"work \"; System.out.println(\"Sender : \" + context + \"*****\" + i); this.rabbitTemplate.convertAndSend(\"work\", context); }} Queue 1234567@Configurationpublic class WorkConfig { @Bean public Queue workQueue() { return new Queue(\"work\"); }} 两个消费者 1234567891011121314151617@Componentpublic class WorkReceicer1 { @RabbitHandler @RabbitListener(queues = \"work\") public void process(String message) { System.out.println(\"Work Receiver1 : \" + message); }}@Componentpublic class WorkReceicer2 { @RabbitHandler @RabbitListener(queues = \"work\") public void process(String message) { System.out.println(\"Work Receiver2 : \" + message); }} 测试 1234567891011121314@RunWith(SpringRunner.class)@SpringBootTest(classes = Startup.class)public class RabbitMQDirectTest { @Autowired private WorkSender workSender; @Test public void sendWorkTest() { for (int i = 0; i &lt; 20; i++) { workSender.send(i); } }} 结果 1234567891011121314151617181920Work Receiver1 : work Work Receiver2 : work Work Receiver2 : work Work Receiver1 : work Work Receiver2 : work Work Receiver1 : work Work Receiver2 : work Work Receiver1 : work Work Receiver1 : work Work Receiver2 : work Work Receiver2 : work Work Receiver1 : work Work Receiver2 : work Work Receiver1 : work Work Receiver1 : work Work Receiver2 : work Work Receiver1 : work Work Receiver2 : work Work Receiver2 : work Work Receiver1 : work 发现消费得很平均，每个consumer处理一半的消息。 public/subscribe 从上面的两个例子我们看到producer产生的消息直接发送给queue，然后queue又直接将消息传给consumer。RabbitMQ 的亮点就在于改变了上面这种消息传递的方式，producer不会将消息直接传给queue而是传给exchanges再由exchangers传给queue。然而我们在前面的两个例子中并没有使用exchanges，那是因为 RabbitMQ 有默认的exchanges，只要我们传的参数是&quot;&quot;。在默认模式下，不需要将exchanges做任何绑定。除此之外exchanges有以下几种类型： Direct：direct 类型的行为是”先匹配, 再投送”. 即在绑定时设定一个 routing_key, 消息的 routing_key 匹配时, 才会被交换器投送到绑定的队列中去. Topic：按规则转发消息（最灵活） Headers：设置header attribute参数类型的交换机 Fanout：转发消息到所有绑定队列 Queue 以下使用的是Fanout Exchange转发消息到所有绑定队列。这里要配置两个queue，并且配置exchanges，并把queue和exchanges绑定。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * * public/subscribe 模式 * * @author shui * @create 2018-02-04 **/@Configurationpublic class FanoutConfig { /************************************************************************ * 新建队列 fanout.A 、fanout.B************************************************************************/ @Bean public Queue AMessage() { return new Queue(\"fanout.A\"); } @Bean public Queue BMessage() { return new Queue(\"fanout.B\"); } /** * 建立一个交换机 * * @return */ @Bean FanoutExchange fanoutExchange() { return new FanoutExchange(\"fanoutExchange\"); } /************************************************************************ * 将 fanout.A 、 fanout.B 绑定到交换机 fanoutExchange 上************************************************************************/ @Bean Binding bindingExchangeA(Queue AMessage, FanoutExchange fanoutExchange) { return BindingBuilder.bind(AMessage).to(fanoutExchange); } @Bean Binding bindingExchangeB(Queue BMessage, FanoutExchange fanoutExchange) { return BindingBuilder.bind(BMessage).to(fanoutExchange); }} 生产者 在创建producter的时候，要将他和exchanges绑定。 1234567891011@Controllerpublic class FanoutSender { @Autowired private AmqpTemplate rabbitTemplate; public void send() { String context = \"hi, fanout msg \"; System.out.println(\"Sender : \" + context); this.rabbitTemplate.convertAndSend(\"fanoutExchange\",\"\", context); }} 两个消费者 123456789101112131415161718@Componentpublic class FanoutReceiveA { @RabbitHandler @RabbitListener(queues = \"fanout.A\") public void process(String message) { System.out.println(\"fanout Receiver A : \" + message); }}@Componentpublic class FanoutReceiveB { @RabbitHandler @RabbitListener(queues = \"fanout.B\") public void process(String message) { System.out.println(\"fanout Receiver B : \" + message); }} 测试 1234567891011@RunWith(SpringRunner.class)@SpringBootTest(classes = Startup.class)public class FanoutTest { @Autowired private FanoutSender fanoutSender; @Test public void setFanoutSender() { fanoutSender.send(); }} 结果 12fanout Receiver B : hi, fanout msg fanout Receiver A : hi, fanout msg Routing 在前面的Fanout模式下，消息会直接广播给queue。如果我们想让consumer处理某些特定的消息，就要让他接收消息的队列中没有其他类型的消息，所以能不能让queue只接收某些消息，而不接收另一些消息呢？ RabbitMQ 中有一个 Routingkey 的概念。在队列与交换机的绑定过程中添加Routingkey表示queue接收的消息需要带有Routingkey。 Topic Topic模式和Direct模式类似，Direct模式需要Routingkey完全匹配而Topic模式更加灵活，可以通过通配符进行配置。 在这种交换机模式下：路由键必须是一串字符，用句号（.） 隔开，例如：topic.A 路由模式必须包含一个星号*，主要用于匹配路由键指定位置的一个单词，比如说，一个路由模式是这样子：agreements..b.*，那么就只能匹配路由键是这样子的：第一个单词是 agreements，第四个单词是 b。 井号（#）就表示相当于一个或者多个单词；例如一个匹配模式是agreements.eu.berlin.#，那么，以agreements.eu.berlin开头的路由键都是可以的。 Queue and exchange 另个队列分别为 topic.A,topic.B,将他们绑定到 topicExchange 上。并且设置了规则，topic.A 必须是完全匹配的也就是Direct模式，topic.B 使用Topic模式，只要是Rouctingkey为 topic 开头的都可以接收。 12345678910111213141516171819202122232425262728293031@Configurationpublic class TopicConfig { final static String message = \"topic.A\"; final static String messages = \"topic.B\"; @Bean public Queue queueMessage() { return new Queue(TopicConfig.message); } @Bean public Queue queueMessages() { return new Queue(TopicConfig.messages); } @Bean TopicExchange exchange() { return new TopicExchange(\"topicExchange\"); } @Bean Binding bindingExchangeMessage(Queue queueMessage, TopicExchange exchange) { return BindingBuilder.bind(queueMessage).to(exchange).with(\"topic.message\"); } @Bean Binding bindingExchangeMessages(Queue queueMessages, TopicExchange exchange) { return BindingBuilder.bind(queueMessages).to(exchange).with(\"topic.#\"); }} 生产者 1234567891011121314151617181920212223@Controllerpublic class TopicSend { @Autowired private AmqpTemplate rabbitTemplate; public void send() { String context = \"hi, i am message 0\"; System.out.println(\"Sender : \" + context); this.rabbitTemplate.convertAndSend(\"topicExchange\", \"topic.1\", context); } public void send1() { String context = \"hi, i am message 1\"; System.out.println(\"Sender : \" + context); this.rabbitTemplate.convertAndSend(\"topicExchange\", \"topic.message\", context); } public void send2() { String context = \"hi, i am messages 2\"; System.out.println(\"Sender : \" + context); this.rabbitTemplate.convertAndSend(\"topicExchange\", \"topic.messages\", context); }} 消费者 1234567891011121314151617@Component@RabbitListener(queues = \"topic.A\")public class TopicReceiver { @RabbitHandler public void process(String message) { System.out.println(\"Topic Receiver1 : \" + message); }}@Component@RabbitListener(queues = \"topic.B\")public class TopicReceiver2 { @RabbitHandler public void process(String message) { System.out.println(\"Topic Receiver2 : \" + message); }} 测试 123456789101112131415161718192021@RunWith(SpringRunner.class)@SpringBootTest(classes = Startup.class)public class TopicTest { @Autowired private TopicSend sender; @Test public void topic() throws Exception { sender.send(); } @Test public void topic1() throws Exception { sender.send1(); } @Test public void topic2() throws Exception { sender.send2(); }} 结果 1234567Sender : hi, i am message 1Sender : hi, i am messages 2Sender : hi, i am message 0Topic Receiver1 : hi, i am message 1Topic Receiver2 : hi, i am message 1Topic Receiver2 : hi, i am messages 2Topic Receiver2 : hi, i am message 0 总结掌握 RabbitMQ 的核心在于如何使用好exchanges，它有默认模式&quot;&quot; , direct , topic , headers 和 fanout 这几种模式。 通过 RabbitMQ 的 routingkey 可以过滤交换机传递给队列的消息。fanout 模式下，需要队列和交换机的routingkey完全匹配，而在topic模式下，可以通过通配符进行配置，变得更加灵活。 安装参考：Install RabbitMQ server in CentOS 7 CentOS 7 下安装 RabbitMQ Install Erlang and Elixir in CentOS 7 rabbitmq——用户管理 Springboot 集成 RabbitMQ 参考RabbitMQ Tutorials Spring Boot 中使用 RabbitMQ springboot rabbitmq整合 Spring Boot系列(八)：RabbitMQ详解","link":"/post/29003c34.html"},{"title":"【Darknet】darknet实战","text":"Darknet is an open source neural network framework written in C and CUDA. It is fast, easy to install, and supports CPU and GPU computation. —— https://pjreddie.com/darknet/ 本文是对使用 darknet 进行目标检测的小结，包括： 数据集准备：如何使用 labelimage 对数据进行标注，注意事项，文件格式转换 darknet 使用：如何编译和修改配置文件 模型评估：如何查看 loss、计算 IoU、recall、mAP 数据集准备 大多数情况下，数据集决定了任务的成败。一开始我认为标注数据是一件非常枯燥和乏味的事情，但是当模型指标一直上不去，检测和识别效果也一直不好时，回过头才会发现是因为数据标注的有问题。 这只有自己经历过之后才会有体会，得出这样几条经验： 保持类间差距大，类内差距小 一开始先标注少量的图片并训练模型查看效果，根据结果进行调整，否则等到标注了大量图片之后再回过头修改，得不偿失。 labelimage图片标注使用的是开源的工具 LabelImg，可以查看文档自行编译，下载之后的文件结构如下： 1234567.├── build-tools├── CONTRIBUTING.rst├── data |—— predefined_classes.txt├── labelImg.py... 在data/predefined_classes.txt文件配置进行图片的类别 界面展示及注意事项启动 labelimg 之后的界面如下图所示 注意： 存放图片文件夹和存放标记文件的文件夹需要保持一致 正确选择标记文件的格式，是需要 yolo 格式还是 xml 格式，默认为 xml 格式 右侧可以选择默认标签，当密集标注一个类的时候很实用 打完几张标签之后请确认标签是否正确，再去文件目录下确认以下标记文件是否生成且格式正确 快捷键123456789+------------+--------------------------------------------+| Space | 保存 |+------------+--------------------------------------------+| w | 创建矩形框 |+------------+--------------------------------------------+| d | 下一张图片 |+------------+--------------------------------------------+| a | 上一张图片 |+------------+--------------------------------------------+ 最常用的快捷键是上面这 4 个，用好快捷键可以调高打标效率。此外按住ctrl+鼠标滚轮可以调整图片大小，局部放大图片可以提高打标的精准度。 yolo格式和 xml 格式转换xml2yolo.py12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758\"\"\"1. 修改 classes 列表中的元素为当前标签列表2. 修改 list_xml 指向的 xml 文件保存的位置\"\"\"#import xml.etree.ElementTree as ETfrom xml.etree import ElementTree as ETimport pickleimport osfrom os import listdir, getcwdfrom os.path import joinimport globclasses = ['rabbit']def convert(size, box): dw = 1. / (size[0]) dh = 1. / (size[1]) x = (box[0] + box[1]) / 2.0 - 1 y = (box[2] + box[3]) / 2.0 - 1 w = box[1] - box[0] h = box[3] - box[2] x = x * dw w = w * dw y = y * dh h = h * dh return (x, y, w, h)def convert_annotation(xml_file, txt_file): in_file = open(xml_file) tree = ET.parse(in_file) root = tree.getroot() size = root.find('size') w = int(size.find('width').text) h = int(size.find('height').text) for obj in root.iter('object'): cls = obj.find('name').text if cls not in classes: continue cls_id = classes.index(cls) xmlbox = obj.find('bndbox') b = (float(xmlbox.find('xmin').text), float(xmlbox.find('xmax').text), float(xmlbox.find('ymin').text), float(xmlbox.find('ymax').text)) bb = convert((w, h), b) txt_file.write(str(cls_id) + \" \" + \" \".join([str(a) for a in bb]) + '\\n')list_xml = []list_xml = glob.glob(r\"/file_path/*.xml\")for xml_file in list_xml: xml_name = xml_file.split('.')[0] txt_file = open('%s.txt' % (xml_name), 'w') convert_annotation(xml_file, txt_file) txt_file.close() yolo2xml.py123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123\"\"\"1. 修改 class_name2. 修改 src_img_dir/src_txt_dir/src_xml_dir 路径\"\"\"import os, sysimport globfrom PIL import Imageclass_name = ['switch_closed','switch_open','whirled_switch_closed','whirled_switch_open', 'lifting_switch_closed','lifting_switch_open','closure_switch_closed','closure_switch_open', 'color_switch01_red','color_switch01_green','color_switch02_red','color_switch02_green', 'isolation_switch_closed','isolation_switch_open','grounding_knife_switch01_closed','grounding_knife_switch01_open', 'grounding_knife_switch02_closed','grounding_knife_switch02_open']def convert_yolo_coordinates_to_voc(x_c_n, y_c_n, width_n, height_n, img_width, img_height): ## remove normalization given the size of the image x_c = float(x_c_n) * img_width y_c = float(y_c_n) * img_height width = float(width_n) * img_width height = float(height_n) * img_height ## compute half width and half height half_width = width / 2 half_height = height / 2 ## compute left, top, right, bottom ## in the official VOC challenge the top-left pixel in the image has coordinates (1;1) left = int(x_c - half_width) + 1 top = int(y_c - half_height) + 1 right = int(x_c + half_width) + 1 bottom = int(y_c + half_height) + 1 return left, top, right, bottom# 将标注的txt转换为 voc xml# VEDAI 图像存储位置src_img_dir = \"./switch_mAP\"# VEDAI 图像的 ground truth 的 txt 文件存放位置src_txt_dir = \"./switch_mAP\"src_xml_dir = \"./switch_mAP\"img_Lists = glob.glob(src_img_dir + '/*.txt')# 文件名(含扩展名)img_basenames = [] # e.g. 100for item in img_Lists: img_basenames.append(os.path.basename(item))img_names = [] # e.g. 100for item in img_basenames: # 文件名与扩展名 temp1, temp2 = os.path.splitext(item) img_names.append(temp1)for img in img_names: im = \"\" suffix = \"\" # 同一个文件夹下存在多种图片格式，在这里加上格式判断 if os.path.exists(src_img_dir + '/' + img + '.jpg'): im = Image.open((src_img_dir + '/' + img + '.jpg')) suffix = '.jpg' elif os.path.exists(src_img_dir + '/' + img + '.JPG'): im = Image.open((src_img_dir + '/' + img + '.JPG')) suffix = '.JPG' elif os.path.exists(src_img_dir + '/' + img + '.png'): im = Image.open((src_img_dir + '/' + img + '.png')) suffix = '.png' elif os.path.exists(src_img_dir + '/' + img + '.PNG'): im = Image.open((src_img_dir + '/' + img + '.PNG')) suffix = '.PNG' elif os.path.exists(src_img_dir + '/' + img + '.JPEG'): im = Image.open((src_img_dir + '/' + img + '.JPEG')) suffix = '.JPEG' elif os.path.exists(src_img_dir + '/' + img + '.jpeg'): im = Image.open((src_img_dir + '/' + img + '.jpeg')) suffix = '.jpeg' width, height = im.size \"\"\" 以下部分为 xml 解析 \"\"\" # open the crospronding txt file # 提取每一行并分割 gt = open(src_txt_dir + '/' + img + '.txt').read().splitlines() print(img + '\\n') # write in xml file # os.mknod(src_xml_dir + '/' + img + '.xml') xml_file = open((src_xml_dir + '/' + img + '.xml'), 'a') xml_file.write('&lt;annotation&gt;\\n') xml_file.write(' &lt;folder&gt;VOC2007&lt;/folder&gt;\\n') xml_file.write(' &lt;filename&gt;' + str(img) + suffix + '&lt;/filename&gt;\\n') xml_file.write(' &lt;size&gt;\\n') xml_file.write(' &lt;width&gt;' + str(width) + '&lt;/width&gt;\\n') xml_file.write(' &lt;height&gt;' + str(height) + '&lt;/height&gt;\\n') xml_file.write(' &lt;depth&gt;3&lt;/depth&gt;\\n') xml_file.write(' &lt;/size&gt;\\n') # write the region of image on xml file for img_each_label in gt: spt = img_each_label.split(' ') # 这里如果txt里面是以逗号‘，’隔开的，那么就改为spt = img_each_label.split(',')。 name = class_name[int(spt[0])] x_c,y_c,width_n,height_n = spt[1:] xmin,ymin,xmax,ymax = convert_yolo_coordinates_to_voc(x_c,y_c,width_n,height_n,width,height) xml_file.write(' &lt;object&gt;\\n') xml_file.write(' &lt;name&gt;' + name + '&lt;/name&gt;\\n') xml_file.write(' &lt;pose&gt;Unspecified&lt;/pose&gt;\\n') xml_file.write(' &lt;truncated&gt;0&lt;/truncated&gt;\\n') xml_file.write(' &lt;difficult&gt;0&lt;/difficult&gt;\\n') xml_file.write(' &lt;bndbox&gt;\\n') xml_file.write(' &lt;xmin&gt;' + str(xmin) + '&lt;/xmin&gt;\\n') xml_file.write(' &lt;ymin&gt;' + str(ymin) + '&lt;/ymin&gt;\\n') xml_file.write(' &lt;xmax&gt;' + str(xmax) + '&lt;/xmax&gt;\\n') xml_file.write(' &lt;ymax&gt;' + str(ymax) + '&lt;/ymax&gt;\\n') xml_file.write(' &lt;/bndbox&gt;\\n') xml_file.write(' &lt;/object&gt;\\n') xml_file.write('&lt;/annotation&gt;') 使用 darknet 训练模型安装和编译12# 从 Github 下载git clone https://github.com/pjreddie/darknet 进入darknet目录中，对编译文件Makefile进行如下修改 12345GPU=1CUDNN=1OPENCV=0OPENMP=0DEBUG=0 注: 画图或显示图片等操作需要配置OPENCV并设置为1 需要多线程相关操作需要将OPENMP设置为1 修改完成保存并执行make命令。 目录结构介绍12345678910111213.├── backup├── cfg |—— voc.data |—— yolov3-voc.cfg├── darknet├── data |—— voc.names |—— train.txt |—— val.txt |—— test.txt├── scripts... 编译完成之后，我们关注目录中的这几个文件和文件夹。 backup 存放训练出来的权值文件 cfg 保存配置文件，其中两个文件，在后面介绍 darknet 是可执行文件 scripts 下是一些脚本 data/voc.names 存放类别标签 train.txt 保存用于训练的图片全路径(自建，位置无特殊要求) val.txt 保存用于校正的图片全路径(自建，位置无特殊要求) test.txt 保存用于校正的图片全路径(自建，位置无特殊要求) 注: train.txt, val.txt, test.txt 中图片数量比例建议为 8:1:1 修改配置文件类别文件 voc.names修改data/voc.names，将我们的类别标签写这个文件，比如说有以下 5 类 12345dogcatmagpiepigeonnest 注意： 类别标签要与训练集包含的图片类别一一对应，训练集中有以上 5 类则voc.names包含以上 5 类 类别标签需要连续，如果不连续就必须要修改类别标签改成连续的 配置 voc.data修改cfg/voc.data文件 12345classes= class_numbertrain = /path/train.txtvalid = /path/val.txtnames = data/voc.namesbackup = backup classes 配置类别数量，与上一步voc.names中类别数量一致 train 配置为目录结构一章介绍的train.txt文件的位置 vaild 配置为目录结构一章介绍的val.txt文件的位置 names 配置为voc.names位置(默认不变即可) backup 配置为权值文件的位置(默认不变即可) 配置 yolov3-voc.cfg在文件开头位置 123456789101112131415[net]# Testing# batch=1 # 测试时开启，训练时关闭# subdivisions=1 # 测试时开启，训练时关闭# Trainingbatch=6 # 训练时开启，测试时关闭subdivisions=2 # 训练时开启，测试时关闭 ...learning_rate=0.0001 # 学习率，可以调整得小一点burn_in=1000max_batches = 50200policy=stepssteps=40000,45000scales=.1,.1 batch 和 subdivisions 在测试和训练的时候请按照上面注释开启或者关闭 batch 一批处理几张图片，没有超过显存的情况下越大越好 subdivisions 表示在 batch 中再划分的数量 当前配置的意思是每轮迭代从所有训练集中抽取 6 张图片，这 6 张样本图片又被分成 2 次，每次 3 张送入到网络参与训练。 接着在文件中搜索yolo，会有三条结果。每个yolo上下都要修改filters和classes，总共需要修改3 组共 6 个字段。 12345678910111213141516[convolutional]size=1stride=1pad=1filters=30 # 3*(classes+5)activation=linear[yolo]mask = 6,7,8anchors = 10,13, 16,30, 33,23, 30,61, 62,45, 59,119, 116,90, 156,198, 373,326classes=5 # 类别(classes)数量num=9jitter=.3ignore_thresh = .5truth_thresh = 1random=1 训练方法一1./darknet detector train cfg/voc.data cfg/yolov3-voc.cfg scripts/darknet53.conv.74 -gpus 0 方法二1nohup ./darknet detector train cfg/voc.data cfg/yolov3-voc.cfg scripts/darknet53.conv.74 -gpus 0 &gt;train.log 2&gt;&amp;1 &amp; 我们需要保留训练的日志，所以用方法二更好。 查看 GPU 使用情况我们可以使用nvidia-smi来查看 gpu 的使用情况，注意先查看 gpu 的使用情况。 12345678910111213141516171819202122Fri Mar 29 16:33:31 2019 +-----------------------------------------------------------------------------+| NVIDIA-SMI 410.78 Driver Version: 410.78 CUDA Version: 10.0 ||-------------------------------+----------------------+----------------------+| GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC || Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. ||===============================+======================+======================|| 0 GeForce GTX 108... Off | 00000000:01:00.0 On | N/A || 59% 87C P2 221W / 250W | 4874MiB / 11175MiB | 98% Default |+-------------------------------+----------------------+----------------------+| 1 GeForce GTX 108... Off | 00000000:02:00.0 Off | N/A || 24% 42C P8 16W / 250W | 5107MiB / 11178MiB | 0% Default |+-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+| Processes: GPU Memory || GPU PID Type Process name Usage ||=============================================================================|| 0 1218 G /usr/lib/xorg/Xorg 69MiB || 0 24338 C ./darknet 4793MiB || 1 12712 C ./bin/psd_be 5095MiB |+-----------------------------------------------------------------------------+ 用nvidia-smi输出的是静态的信息，如果想要动态查看 gpu 的使用情况可以使用watch -n 1 nvidia-smi表示每一秒刷新一个 gpu 的使用情况。 查看日志输出信息123450181: 0.084739, 0.367084 avg, 0.000001 rate, 0.244283 seconds, 301086 imagesLoaded: 0.000030 secondsRegion 82 Avg IOU: 0.775331, Class: 0.611054, Obj: 0.963920, No Obj: 0.005009, .5R: 1.000000, .75R: 0.833333, count: 6Region 94 Avg IOU: 0.753700, Class: 0.962260, Obj: 0.777823, No Obj: 0.000218, .5R: 1.000000, .75R: 0.500000, count: 2 50181 表示迭代次数 0.084739 表示整体 Loss 0.367084 avg 表示平均 Loss 0.000001 rate 表示学习率，对应.cfg文件中的learning_rate 0.244283 seconds 表示当前批次训练花费了多少时间 301086 images 表示目前已经训练了多少照片 判断训练没有异常的标准 IOU 表示预测目标与真实目标的交集与并集之比，越接近于 1 越好，出现大量 -nan 表示训练异常 Class: 0.611054 表示标记物体的正确率，越接近于 1 越好 Obj: 0.963920 越接近 1 越好 No Obj 0.005009 越接近 0 越好 当训练整体趋势按照上面描述的一样向好的方向发展就表示训练正常，反之表示训练异常。 测试1./darknet detector test cfg/voc.data cfg/yolov3-voc.cfg backup/yolov3-voc_50000.weights 1 注意：测试时，修改cfg/yolov3-voc.cfg配置文件，请参照之前配置 yolov3-voc.cfg这一节。 其他 训练集中各个类别的数量要尽可能保持均衡，不要有的类特别多或者有的特别少 train.txt 文件中配置了训练用的图片，这些图片必须要有对应的txt文件，且txt文件不可以为空 train.txt 文件不可以有空行，存在空行会导致训练失败 开始新的训练注意删除backup中原先的.weight文件 如何评估模型的效果darknet 编译格式123456./darknet detector test &lt;data_cfg&gt; &lt;models_cfg&gt; &lt;weights&gt; &lt;test_file&gt; [-thresh] [-out]./darknet detector train &lt;data_cfg&gt; &lt;models_cfg&gt; &lt;weights&gt; [-thresh] [-gpu] [-gpus] [-clear]./darknet detector valid &lt;data_cfg&gt; &lt;models_cfg&gt; &lt;weights&gt; [-out] [-thresh]./darknet detector recall &lt;data_cfg&gt; &lt;models_cfg&gt; &lt;weights&gt; [-thresh]'&lt;&gt;'必选项，’[ ]‘可选项 data_cfg：数据配置文件，eg：cfg/voc.data models_cfg：模型配置文件，eg：cfg/yolov3-voc.cfg weights：权重配置文件，eg：weights/yolov3.weights test_file：测试文件，eg：//*/test.txt -thresh：显示被检测物体中confidence大于等于 [-thresh] 的bounding-box，默认0.005 -out：输出文件名称，默认路径为results文件夹下，eg：-out “” //输出class_num个文件，文件名为class_name.txt；若不选择此选项，则默认输出文件名为comp4_det_test_”class_name”.txt -i/-gpu：指定单个gpu，默认为0，eg：-gpu 2 -gpus：指定多个gpu，默认为0，eg：-gpus 0,1,2 根据训练日志生成 loss-iter 曲线使用 drawcurve.py 解析训练日志，据此生成 loss-iter 曲线。该脚本通过训练日志计算 loss,不过训练日志格式可能会有区别,可能需要自己修改脚本来适应. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# coding: utf-8import argparseimport sysimport matplotlib.pyplot as pltdef main(argv): parser = argparse.ArgumentParser() parser.add_argument(\"log_file\", help = \"path to log file\" ) parser.add_argument( \"option\", help = \"0 -&gt; loss vs iter\" ) args = parser.parse_args() f = open(args.log_file) lines = [line.rstrip(\"\\n\") for line in f.readlines()] # skip the first 3 lines lines = lines[3:] numbers = {'1','2','3','4','5','6','7','8','9', '0'} iters = [] loss = [] for line in lines: print(line) #跳过空行 if not len(line): continue if line[0] in numbers: args = line.split(\" \") # print(args) if len(args) &gt; 4 and is_number(args[2]): iters.append(int(args[0][:-1])) loss.append(float(args[2])) plt.plot(iters,loss) plt.xlabel('iters') plt.ylabel('loss') plt.grid() plt.show()# 0.692735 seconds, 595200 imagesdef is_number(s): try: float(s) return True except ValueError: pass try: import unicodedata unicodedata.numeric(s) return True except (TypeError, ValueError): pass return Falseif __name__ == \"__main__\": main(sys.argv) 生成预测结果通过./darknet detector valid &lt;data_cfg&gt; &lt;models_cfg&gt; &lt;weights&gt; 可以批量生成模型的测试结果,测试结果保存在results目录下面,按照类别分成一个个文件. 12#!/bin/bash./darknet detector valid switch_18/switch.data switch_18/switch.cfg switch_18/switch.weights -i 1 -out \"\" 结果生成在 &lt;data_cfg&gt; 的指定的目录下以 &lt;out_file&gt; 开头的若干文件中，若&lt;data_cfg&gt;没有指定results，那么默认为&lt;darknet_root&gt;/results； &lt;models_cfg&gt; 文件中 batch 和 subdivisions 两项必须为1； 若 -out 未指定字符串，则在 results 文件夹下生成 comp4_det_test_[类名].txt 文件并保存测试结果； 本次实验在 results 文件夹下生成 [类名].txt 文件； 统计召回率 recall12#!/bin/bash./darknet detector recall switch_18/switch.data switch_18/switch.cfg switch_18/switch.weights 输出结果为 1234567891011121314151617835 35 45 RPs/Img: 1.81 IOU: 57.69% Recall:77.78%836 35 45 RPs/Img: 1.81 IOU: 57.69% Recall:77.78%837 35 45 RPs/Img: 1.81 IOU: 57.69% Recall:77.78%838 35 45 RPs/Img: 1.81 IOU: 57.69% Recall:77.78%839 35 45 RPs/Img: 1.82 IOU: 57.69% Recall:77.78%840 35 45 RPs/Img: 1.82 IOU: 57.69% Recall:77.78%841 35 45 RPs/Img: 1.82 IOU: 57.69% Recall:77.78%842 35 45 RPs/Img: 1.82 IOU: 57.69% Recall:77.78%843 35 45 RPs/Img: 1.82 IOU: 57.69% Recall:77.78%844 35 45 RPs/Img: 1.82 IOU: 57.69% Recall:77.78%845 35 45 RPs/Img: 1.82 IOU: 57.69% Recall:77.78%846 35 45 RPs/Img: 1.82 IOU: 57.69% Recall:77.78%847 35 45 RPs/Img: 1.82 IOU: 57.69% Recall:77.78%848 35 45 RPs/Img: 1.82 IOU: 57.69% Recall:77.78%849 35 45 RPs/Img: 1.82 IOU: 57.69% Recall:77.78%850 35 45 RPs/Img: 1.82 IOU: 57.69% Recall:77.78%851 35 45 RPs/Img: 1.82 IOU: 57.69% Recall:77.78% 数据格式为Number Correct Total Rps/Img IOU Recall Number表示处理到第几张图片。 Correct 表示正确的识别除了多少bbox。这个值算出来的步骤是这样的，丢进网络一张图片，网络会预测出很多 bbox，每个bbox都有其置信概率，概率大于threshold的bbox与实际的bbox，也就是labels中txt的内容计算IOU，找出IOU最大的bbox，如果这个最大值大于预设的IOU的threshold，那么correct加一。 Total表示实际有多少个bbox。 Rps/img表示平均每个图片会预测出来多少个bbox。 IOU： 这个是预测出的bbox和实际标注的bbox的交集 除以 他们的并集。显然，这个数值越大，说明预测的结果越好。 Recall召回率， 意思是检测出物体的个数 除以 标注的所有物体个数。通过代码我们也能看出来就是Correct除以Total的值。 计算的是全部图片的 recall 和 IOU,而不是单类的,不是很方便. 计算 mAPreval_voc.py123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101#!/usr/bin/env python# Adapt from -&gt;# --------------------------------------------------------# Fast R-CNN# Copyright (c) 2015 Microsoft# Licensed under The MIT License [see LICENSE for details]# Written by Ross Girshick# --------------------------------------------------------# &lt;- Written by Yaping Sun\"\"\"Reval = re-eval. Re-evaluate saved detections.\"\"\"import os, sys, argparseimport numpy as npimport cPicklefrom voc_eval import voc_evaldef parse_args(): \"\"\" Parse input arguments \"\"\" parser = argparse.ArgumentParser(description='Re-evaluate results') parser.add_argument('output_dir', nargs=1, help='results directory', type=str) parser.add_argument('--voc_dir', dest='voc_dir', default='data/VOCdevkit', type=str) parser.add_argument('--year', dest='year', default='2017', type=str) parser.add_argument('--image_set', dest='image_set', default='test', type=str) parser.add_argument('--classes', dest='class_file', default='data/voc.names', type=str) if len(sys.argv) == 1: parser.print_help() sys.exit(1) args = parser.parse_args() return argsdef get_voc_results_file_template(image_set, out_dir = 'results'): filename = 'comp4_det_' + image_set + '_{:s}.txt' path = os.path.join(out_dir, filename) return pathdef do_python_eval(devkit_path, year, image_set, classes, output_dir = 'results'): annopath = os.path.join( devkit_path, 'VOC' + year, 'Annotations', '{:s}.xml') imagesetfile = os.path.join( devkit_path, 'VOC' + year, 'ImageSets', 'Main', image_set + '.txt') cachedir = os.path.join(devkit_path, 'annotations_cache') aps = [] # The PASCAL VOC metric changed in 2010 use_07_metric = True if int(year) &lt; 2010 else False print('VOC07 metric? ' + ('Yes' if use_07_metric else 'No')) if not os.path.isdir(output_dir): os.mkdir(output_dir) for i, cls in enumerate(classes): if cls == '__background__': continue filename = get_voc_results_file_template(image_set).format(cls) rec, prec, ap = voc_eval( filename, annopath, imagesetfile, cls, cachedir, ovthresh=0.5, use_07_metric=use_07_metric) aps += [ap] print('AP for {} = {:.4f}'.format(cls, ap)) with open(os.path.join(output_dir, cls + '_pr.pkl'), 'w') as f: cPickle.dump({'rec': rec, 'prec': prec, 'ap': ap}, f) print('Mean AP = {:.4f}'.format(np.mean(aps))) print('~~~~~~~~') print('Results:') for ap in aps: print('{:.3f}'.format(ap)) print('{:.3f}'.format(np.mean(aps))) print('~~~~~~~~') print('') print('--------------------------------------------------------------') print('Results computed with the **unofficial** Python eval code.') print('Results should be very close to the official MATLAB eval code.') print('-- Thanks, The Management') print('--------------------------------------------------------------')if __name__ == '__main__': args = parse_args() output_dir = os.path.abspath(args.output_dir[0]) with open(args.class_file, 'r') as f: lines = f.readlines() classes = [t.strip('\\n') for t in lines] print('Evaluating detections') do_python_eval(args.voc_dir, args.year, args.image_set, classes, output_dir) voc_eval.py123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211# --------------------------------------------------------# Fast/er R-CNN# Licensed under The MIT License [see LICENSE for details]# Written by Bharath Hariharan# --------------------------------------------------------import xml.etree.ElementTree as ETimport osimport pickleimport numpy as npdef parse_rec(filename): \"\"\" Parse a PASCAL VOC xml file \"\"\" tree = ET.parse(filename) objects = [] for obj in tree.findall('object'): obj_struct = {} obj_struct['name'] = obj.find('name').text obj_struct['pose'] = obj.find('pose').text obj_struct['truncated'] = int(obj.find('truncated').text) obj_struct['difficult'] = int(obj.find('difficult').text) bbox = obj.find('bndbox') obj_struct['bbox'] = [int(bbox.find('xmin').text), int(bbox.find('ymin').text), int(bbox.find('xmax').text), int(bbox.find('ymax').text)] objects.append(obj_struct) return objectsdef voc_ap(rec, prec, use_07_metric=False): \"\"\" ap = voc_ap(rec, prec, [use_07_metric]) Compute VOC AP given precision and recall. If use_07_metric is true, uses the VOC 07 11 point method (default:False). \"\"\" if use_07_metric: # 11 point metric ap = 0. for t in np.arange(0., 1.1, 0.1): if np.sum(rec &gt;= t) == 0: p = 0 else: p = np.max(prec[rec &gt;= t]) ap = ap + p / 11. else: # correct AP calculation # first append sentinel values at the end mrec = np.concatenate(([0.], rec, [1.])) mpre = np.concatenate(([0.], prec, [0.])) # compute the precision envelope for i in range(mpre.size - 1, 0, -1): mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i]) # to calculate area under PR curve, look for points # where X axis (recall) changes value i = np.where(mrec[1:] != mrec[:-1])[0] # and sum (\\Delta recall) * prec ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1]) return apdef voc_eval(detpath, annopath, imagesetfile, classname, cachedir, ovthresh=0.5, use_07_metric=False): \"\"\"rec, prec, ap = voc_eval(detpath, annopath, imagesetfile, classname, [ovthresh], [use_07_metric]) Top level function that does the PASCAL VOC evaluation. detpath: Path to detections detpath.format(classname) should produce the detection results file. annopath: Path to annotations annopath.format(imagename) should be the xml annotations file. imagesetfile: Text file containing the list of images, one image per line. classname: Category name (duh) cachedir: Directory for caching the annotations [ovthresh]: Overlap threshold (default = 0.5) [use_07_metric]: Whether to use VOC07's 11 point AP computation (default False) \"\"\" # assumes detections are in detpath.format(classname) # assumes annotations are in annopath.format(imagename) # assumes imagesetfile is a text file with each line an image name # cachedir caches the annotations in a pickle file # first load gt if not os.path.isdir(cachedir): os.mkdir(cachedir) cachefile = os.path.join(cachedir, 'annots.pkl') # read list of images with open(imagesetfile, 'r') as f: lines = f.readlines() imagenames = [x.strip() for x in lines] if not os.path.isfile(cachefile): # load annots recs = {} for i, imagename in enumerate(imagenames): recs[imagename] = parse_rec(annopath.format(imagename)) if i % 100 == 0: print ('Reading annotation for {:d}/{:d}'.format( i + 1, len(imagenames))) # save print ('Saving cached annotations to {:s}'.format(cachefile)) with open(cachefile, 'wb') as f: pickle.dump(recs, f) else: # load with open(cachefile, 'rb') as f: recs = pickle.load(f) # extract gt objects for this class class_recs = {} npos = 0 for imagename in imagenames: R = [obj for obj in recs[imagename] if obj['name'] == classname] difficult = np.array([x['difficult'] for x in R]).astype(np.bool) bbox = np.array([x['bbox'] for x in R]) #difficult = np.array([x['difficult'] for x in R]).astype(np.bool) det = [False] * len(R) npos = npos + sum(~difficult) class_recs[imagename] = {'bbox': bbox, #'difficult': difficult, 'det': det} # read dets detfile = detpath.format(classname) with open(detfile, 'r') as f: lines = f.readlines() splitlines = [x.strip().split(' ') for x in lines] image_ids = [x[0] for x in splitlines] confidence = np.array([float(x[1]) for x in splitlines]) BB = np.array([[float(z) for z in x[2:]] for x in splitlines]) # sort by confidence sorted_ind = np.argsort(-confidence) sorted_scores = np.sort(-confidence) BB = BB[sorted_ind, :] image_ids = [image_ids[x] for x in sorted_ind] # go down dets and mark TPs and FPs nd = len(image_ids) tp = np.zeros(nd) fp = np.zeros(nd) for d in range(nd): R = class_recs[image_ids[d]] bb = BB[d, :].astype(float) ovmax = -np.inf BBGT = R['bbox'].astype(float) if BBGT.size &gt; 0: # compute overlaps # intersection ixmin = np.maximum(BBGT[:, 0], bb[0]) iymin = np.maximum(BBGT[:, 1], bb[1]) ixmax = np.minimum(BBGT[:, 2], bb[2]) iymax = np.minimum(BBGT[:, 3], bb[3]) iw = np.maximum(ixmax - ixmin + 1., 0.) ih = np.maximum(iymax - iymin + 1., 0.) inters = iw * ih # union uni = ((bb[2] - bb[0] + 1.) * (bb[3] - bb[1] + 1.) + (BBGT[:, 2] - BBGT[:, 0] + 1.) * (BBGT[:, 3] - BBGT[:, 1] + 1.) - inters) overlaps = inters / uni ovmax = np.max(overlaps) jmax = np.argmax(overlaps) \"\"\" if ovmax &gt; ovthresh: if not False: if not R['det'][jmax]: tp[d] = 1. R['det'][jmax] = 1 else: fp[d] = 1. else: fp[d] = 1. \"\"\" if ovmax &gt; ovthresh: if not False: if not R['det'][jmax]: tp[d] = 1. R['det'][jmax] = 1 else: fp[d] = 1. else: fp[d] = 1. # compute precision recall fp = np.cumsum(fp) tp = np.cumsum(tp) rec = tp / float(npos) # avoid divide by zero in case the first detection matches a difficult # ground truth prec = tp / np.maximum(tp + fp, np.finfo(np.float64).eps) ap = voc_ap(rec, prec, use_07_metric) return rec, prec, ap computer_Single_ALL_mAP.py results_path = “填写前面生成的 results 文件的路径” /xxx/results/{}.txt - results_path 的路径 /xxx/{}.xml - xml 格式的标注文件 /xxx/list.txt - 只包含图片名字的列表文件 执行 computer_Single_ALL_mAP.py 将会生成各个分类的 mAP. 12345678910111213141516171819202122232425from voc_eval import voc_eval import os current_path = os.getcwd()results_path = \"填写前面生成的 results 文件的路径\"sub_files = os.listdir(results_path) mAP = [] for i in range(len(sub_files)): class_name = sub_files[i].split(\".txt\")[0] rec, prec, ap = voc_eval('/xxx/results/{}.txt', '/xxx/{}.xml', '/xxx/list.txt', class_name, '.') # print(\"{} :\\t {} \".format(class_name, ap)) print(\"{} :\\t {} \".format(class_name, ap)) mAP.append(ap) # class_name = 'switch_open'# rec, prec, ap = voc_eval('/aseit-data/program/darknet/results/{}.txt', '/aseit-data/data_set/swich/dataset_test/switch_mAP/{}.xml', '/aseit-data/data_set/swich/dataset_test/list.txt', class_name, '.')# print(\"{} :\\t {} \".format(class_name, ap)) # mAP.append(ap) mAP = tuple(mAP) print(\"***************************\") print(\"mAP :\\t {}\".format( float( sum(mAP)/len(mAP)) )) detector.c在 test 和计算 recall 的时候需要修改 examples/detector.c 如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779780781782783784785786787788789790791792793794795796797798799800801802803804805806807808809810811812813814815816817818819820821822823824825826827828829830831832833834835836837838839840841842843844845846847848849850851852853854855856857858859860861862863864865866867868869870871872873874875876877878879880881882883884885886887888889890891892893894895896897898899900901902903904905906907908909910911912913914915916917918919920921922923924925926927928929930931932933934935936937938939940941942943944945946947948949950951952953954955956957958959960961962963964965966967968969970971972973974975976977978979980981982983984985986987988989990991992993994995996997998999100010011002100310041005100610071008100910101011101210131014101510161017101810191020102110221023102410251026102710281029103010311032103310341035103610371038#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include \"darknet.h\"#include &lt;sys/stat.h&gt;#include &lt;stdio.h&gt;#include &lt;time.h&gt;#include &lt;sys/types.h&gt;static int coco_ids[] = {1,2,3,4,5,6,7,8,9,10,11,13,14,15,16,17,18,19,20,21,22,23,24,25,27,28,31,32,33,34,35,36,37,38,39,40,41,42,43,44,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,67,70,72,73,74,75,76,77,78,79,80,81,82,84,85,86,87,88,89,90};char *GetFilename(char *fullname){ int from,to,i; char *newstr,*temp; if(fullname!=NULL){ //if not find dot if((temp=strchr(fullname,'.'))==NULL){ newstr = fullname; } else { from = strlen(fullname) - strlen(temp); to = (temp-fullname); //the first dot's index for (i=from; i&lt;=to; i--){ if (fullname[i]=='.') break;//find the last dot } newstr = (char*)malloc(i+1); strncpy(newstr,fullname,i); *(newstr+i)=0; } } static char name[50] = {\"\"}; char *q = strrchr(newstr,'/') + 1; strncpy(name,q,40); return name;}void train_detector(char *datacfg, char *cfgfile, char *weightfile, int *gpus, int ngpus, int clear){ list *options = read_data_cfg(datacfg); //解析data文件，用自定义链表options存储训练集基本信息，函数位于option_list.c char *train_images = option_find_str(options, \"train\", \"data/train.list\"); //从options中找训练集 char *backup_directory = option_find_str(options, \"backup\", \"/backup/\"); //从options中找backup路径 srand(time(0)); //初始化随机种子数 char *base = basecfg(cfgfile); //此函数位于utils.c,返回cfg文件不带后缀的名字 printf(\"%s\\n\", base); float avg_loss = -1; network **nets = calloc(ngpus, sizeof(network)); srand(time(0)); int seed = rand(); int i; for(i = 0; i &lt; ngpus; ++i){ srand(seed);#ifdef GPU cuda_set_device(gpus[i]);#endif nets[i] = load_network(cfgfile, weightfile, clear); nets[i]-&gt;learning_rate *= ngpus; } srand(time(0)); network *net = nets[0]; int imgs = net-&gt;batch * net-&gt;subdivisions * ngpus; printf(\"Learning Rate: %g, Momentum: %g, Decay: %g\\n\", net-&gt;learning_rate, net-&gt;momentum, net-&gt;decay); data train, buffer; layer l = net-&gt;layers[net-&gt;n - 1]; int classes = l.classes; float jitter = l.jitter; list *plist = get_paths(train_images); //int N = plist-&gt;size; char **paths = (char **)list_to_array(plist); load_args args = get_base_args(net); args.coords = l.coords; args.paths = paths; args.n = imgs; args.m = plist-&gt;size; args.classes = classes; args.jitter = jitter; args.num_boxes = l.max_boxes; args.d = &amp;buffer; args.type = DETECTION_DATA; //args.type = INSTANCE_DATA; args.threads = 64; pthread_t load_thread = load_data(args); double time; int count = 0; //while(i*imgs &lt; N*120){ while(get_current_batch(net) &lt; net-&gt;max_batches){ if(l.random &amp;&amp; count++%10 == 0){ printf(\"Resizing\\n\"); int dim = (rand() % 10 + 10) * 32; if (get_current_batch(net)+200 &gt; net-&gt;max_batches) dim = 608; //int dim = (rand() % 4 + 16) * 32; printf(\"%d\\n\", dim); args.w = dim; args.h = dim; pthread_join(load_thread, 0); train = buffer; free_data(train); load_thread = load_data(args); #pragma omp parallel for for(i = 0; i &lt; ngpus; ++i){ resize_network(nets[i], dim, dim); } net = nets[0]; } time=what_time_is_it_now(); pthread_join(load_thread, 0); train = buffer; load_thread = load_data(args); /* int k; for(k = 0; k &lt; l.max_boxes; ++k){ box b = float_to_box(train.y.vals[10] + 1 + k*5); if(!b.x) break; printf(\"loaded: %f %f %f %f\\n\", b.x, b.y, b.w, b.h); } */ /* int zz; for(zz = 0; zz &lt; train.X.cols; ++zz){ image im = float_to_image(net-&gt;w, net-&gt;h, 3, train.X.vals[zz]); int k; for(k = 0; k &lt; l.max_boxes; ++k){ box b = float_to_box(train.y.vals[zz] + k*5, 1); printf(\"%f %f %f %f\\n\", b.x, b.y, b.w, b.h); draw_bbox(im, b, 1, 1,0,0); } show_image(im, \"truth11\"); cvWaitKey(0); save_image(im, \"truth11\"); } */ printf(\"Loaded: %lf seconds\\n\", what_time_is_it_now()-time); time=what_time_is_it_now(); float loss = 0;#ifdef GPU if(ngpus == 1){ loss = train_network(net, train); } else { loss = train_networks(nets, ngpus, train, 4); }#else loss = train_network(net, train);#endif if (avg_loss &lt; 0) avg_loss = loss; avg_loss = avg_loss*.9 + loss*.1; i = get_current_batch(net); printf(\"%ld: %f, %f avg, %f rate, %lf seconds, %d images\\n\", get_current_batch(net), loss, avg_loss, get_current_rate(net), what_time_is_it_now()-time, i*imgs); if(i%100==0){#ifdef GPU if(ngpus != 1) sync_nets(nets, ngpus, 0);#endif char buff[256]; sprintf(buff, \"%s/%s.backup\", backup_directory, base); save_weights(net, buff); } if(i%10000==0 || (i &lt; 1000 &amp;&amp; i%100 == 0)){#ifdef GPU if(ngpus != 1) sync_nets(nets, ngpus, 0);#endif char buff[256]; sprintf(buff, \"%s/%s_%d.weights\", backup_directory, base, i); save_weights(net, buff); } free_data(train); }#ifdef GPU if(ngpus != 1) sync_nets(nets, ngpus, 0);#endif char buff[256]; sprintf(buff, \"%s/%s_final.weights\", backup_directory, base); save_weights(net, buff);}static int get_coco_image_id(char *filename){ char *p = strrchr(filename, '/'); char *c = strrchr(filename, '_'); if(c) p = c; return atoi(p+1);}static void print_cocos(FILE *fp, char *image_path, detection *dets, int num_boxes, int classes, int w, int h){ int i, j; int image_id = get_coco_image_id(image_path); for(i = 0; i &lt; num_boxes; ++i){ float xmin = dets[i].bbox.x - dets[i].bbox.w/2.; float xmax = dets[i].bbox.x + dets[i].bbox.w/2.; float ymin = dets[i].bbox.y - dets[i].bbox.h/2.; float ymax = dets[i].bbox.y + dets[i].bbox.h/2.; if (xmin &lt; 0) xmin = 0; if (ymin &lt; 0) ymin = 0; if (xmax &gt; w) xmax = w; if (ymax &gt; h) ymax = h; float bx = xmin; float by = ymin; float bw = xmax - xmin; float bh = ymax - ymin; for(j = 0; j &lt; classes; ++j){ if (dets[i].prob[j]) fprintf(fp, \"{\\\"image_id\\\":%d, \\\"category_id\\\":%d, \\\"bbox\\\":[%f, %f, %f, %f], \\\"score\\\":%f},\\n\", image_id, coco_ids[j], bx, by, bw, bh, dets[i].prob[j]); } }}void print_detector_detections(FILE **fps, char *id, detection *dets, int total, int classes, int w, int h){ int i, j; for(i = 0; i &lt; total; ++i){ float xmin = dets[i].bbox.x - dets[i].bbox.w/2. + 1; float xmax = dets[i].bbox.x + dets[i].bbox.w/2. + 1; float ymin = dets[i].bbox.y - dets[i].bbox.h/2. + 1; float ymax = dets[i].bbox.y + dets[i].bbox.h/2. + 1; if (xmin &lt; 1) xmin = 1; if (ymin &lt; 1) ymin = 1; if (xmax &gt; w) xmax = w; if (ymax &gt; h) ymax = h; for(j = 0; j &lt; classes; ++j){ if (dets[i].prob[j]) fprintf(fps[j], \"%s %f %f %f %f %f\\n\", id, dets[i].prob[j], xmin, ymin, xmax, ymax); } }}void print_imagenet_detections(FILE *fp, int id, detection *dets, int total, int classes, int w, int h){ int i, j; for(i = 0; i &lt; total; ++i){ float xmin = dets[i].bbox.x - dets[i].bbox.w/2.; float xmax = dets[i].bbox.x + dets[i].bbox.w/2.; float ymin = dets[i].bbox.y - dets[i].bbox.h/2.; float ymax = dets[i].bbox.y + dets[i].bbox.h/2.; if (xmin &lt; 0) xmin = 0; if (ymin &lt; 0) ymin = 0; if (xmax &gt; w) xmax = w; if (ymax &gt; h) ymax = h; for(j = 0; j &lt; classes; ++j){ int class = j; if (dets[i].prob[class]) fprintf(fp, \"%d %d %f %f %f %f %f\\n\", id, j+1, dets[i].prob[class], xmin, ymin, xmax, ymax); } }}void validate_detector_flip(char *datacfg, char *cfgfile, char *weightfile, char *outfile){ int j; list *options = read_data_cfg(datacfg); char *valid_images = option_find_str(options, \"valid\", \"data/valid.list\"); char *name_list = option_find_str(options, \"names\", \"data/names.list\"); char *prefix = option_find_str(options, \"results\", \"results\"); char **names = get_labels(name_list); char *mapf = option_find_str(options, \"map\", 0); int *map = 0; if (mapf) map = read_map(mapf); network *net = load_network(cfgfile, weightfile, 0); set_batch_network(net, 2); fprintf(stderr, \"Learning Rate: %g, Momentum: %g, Decay: %g\\n\", net-&gt;learning_rate, net-&gt;momentum, net-&gt;decay); srand(time(0)); list *plist = get_paths(valid_images); char **paths = (char **)list_to_array(plist); layer l = net-&gt;layers[net-&gt;n-1]; int classes = l.classes; char buff[1024]; char *type = option_find_str(options, \"eval\", \"voc\"); FILE *fp = 0; FILE **fps = 0; int coco = 0; int imagenet = 0; if(0==strcmp(type, \"coco\")){ if(!outfile) outfile = \"coco_results\"; snprintf(buff, 1024, \"%s/%s.json\", prefix, outfile); fp = fopen(buff, \"w\"); fprintf(fp, \"[\\n\"); coco = 1; } else if(0==strcmp(type, \"imagenet\")){ if(!outfile) outfile = \"imagenet-detection\"; snprintf(buff, 1024, \"%s/%s.txt\", prefix, outfile); fp = fopen(buff, \"w\"); imagenet = 1; classes = 200; } else { if(!outfile) outfile = \"comp4_det_test_\"; fps = calloc(classes, sizeof(FILE *)); for(j = 0; j &lt; classes; ++j){ snprintf(buff, 1024, \"%s/%s%s.txt\", prefix, outfile, names[j]); fps[j] = fopen(buff, \"w\"); } } int m = plist-&gt;size; int i=0; int t; float thresh = .95; float nms = .45; int nthreads = 4; image *val = calloc(nthreads, sizeof(image)); image *val_resized = calloc(nthreads, sizeof(image)); image *buf = calloc(nthreads, sizeof(image)); image *buf_resized = calloc(nthreads, sizeof(image)); pthread_t *thr = calloc(nthreads, sizeof(pthread_t)); image input = make_image(net-&gt;w, net-&gt;h, net-&gt;c*2); load_args args = {0}; args.w = net-&gt;w; args.h = net-&gt;h; //args.type = IMAGE_DATA; args.type = LETTERBOX_DATA; for(t = 0; t &lt; nthreads; ++t){ args.path = paths[i+t]; args.im = &amp;buf[t]; args.resized = &amp;buf_resized[t]; thr[t] = load_data_in_thread(args); } double start = what_time_is_it_now(); for(i = nthreads; i &lt; m+nthreads; i += nthreads){ fprintf(stderr, \"%d\\n\", i); for(t = 0; t &lt; nthreads &amp;&amp; i+t-nthreads &lt; m; ++t){ pthread_join(thr[t], 0); val[t] = buf[t]; val_resized[t] = buf_resized[t]; } for(t = 0; t &lt; nthreads &amp;&amp; i+t &lt; m; ++t){ args.path = paths[i+t]; args.im = &amp;buf[t]; args.resized = &amp;buf_resized[t]; thr[t] = load_data_in_thread(args); } for(t = 0; t &lt; nthreads &amp;&amp; i+t-nthreads &lt; m; ++t){ char *path = paths[i+t-nthreads]; char *id = basecfg(path); copy_cpu(net-&gt;w*net-&gt;h*net-&gt;c, val_resized[t].data, 1, input.data, 1); flip_image(val_resized[t]); copy_cpu(net-&gt;w*net-&gt;h*net-&gt;c, val_resized[t].data, 1, input.data + net-&gt;w*net-&gt;h*net-&gt;c, 1); network_predict(net, input.data); int w = val[t].w; int h = val[t].h; int num = 0; detection *dets = get_network_boxes(net, w, h, thresh, .5, map, 0, &amp;num); if (nms) do_nms_sort(dets, num, classes, nms); if (coco){ print_cocos(fp, path, dets, num, classes, w, h); } else if (imagenet){ print_imagenet_detections(fp, i+t-nthreads+1, dets, num, classes, w, h); } else { print_detector_detections(fps, id, dets, num, classes, w, h); } free_detections(dets, num); free(id); free_image(val[t]); free_image(val_resized[t]); } } for(j = 0; j &lt; classes; ++j){ if(fps) fclose(fps[j]); } if(coco){ fseek(fp, -2, SEEK_CUR); fprintf(fp, \"\\n]\\n\"); fclose(fp); } fprintf(stderr, \"Total Detection Time: %f Seconds\\n\", what_time_is_it_now() - start);}void validate_detector(char *datacfg, char *cfgfile, char *weightfile, char *outfile){ int j; list *options = read_data_cfg(datacfg); char *valid_images = option_find_str(options, \"valid\", \"data/valid.list\"); char *name_list = option_find_str(options, \"names\", \"data/voc.names\"); char *prefix = option_find_str(options, \"results\", \"results\"); char **names = get_labels(name_list); char *mapf = option_find_str(options, \"map\", 0); int *map = 0; if (mapf) map = read_map(mapf); network *net = load_network(cfgfile, weightfile, 0); set_batch_network(net, 1); fprintf(stderr, \"Learning Rate: %g, Momentum: %g, Decay: %g\\n\", net-&gt;learning_rate, net-&gt;momentum, net-&gt;decay); srand(time(0)); list *plist = get_paths(valid_images); char **paths = (char **)list_to_array(plist); layer l = net-&gt;layers[net-&gt;n-1]; int classes = l.classes; char buff[1024]; char *type = option_find_str(options, \"eval\", \"voc\"); FILE *fp = 0; FILE **fps = 0; int coco = 0; int imagenet = 0; if(0==strcmp(type, \"coco\")){ if(!outfile) outfile = \"coco_results\"; snprintf(buff, 1024, \"%s/%s.json\", prefix, outfile); fp = fopen(buff, \"w\"); fprintf(fp, \"[\\n\"); coco = 1; } else if(0==strcmp(type, \"imagenet\")){ if(!outfile) outfile = \"imagenet-detection\"; snprintf(buff, 1024, \"%s/%s.txt\", prefix, outfile); fp = fopen(buff, \"w\"); imagenet = 1; classes = 200; } else { if(!outfile) outfile = \"comp4_det_test_\"; fps = calloc(classes, sizeof(FILE *)); for(j = 0; j &lt; classes; ++j){ snprintf(buff, 1024, \"%s/%s%s.txt\", prefix, outfile, names[j]); fps[j] = fopen(buff, \"w\"); } } int m = plist-&gt;size; int i=0; int t; float thresh = .95; float nms = .45; int nthreads = 4; image *val = calloc(nthreads, sizeof(image)); image *val_resized = calloc(nthreads, sizeof(image)); image *buf = calloc(nthreads, sizeof(image)); image *buf_resized = calloc(nthreads, sizeof(image)); pthread_t *thr = calloc(nthreads, sizeof(pthread_t)); load_args args = {0}; args.w = net-&gt;w; args.h = net-&gt;h; //args.type = IMAGE_DATA; args.type = LETTERBOX_DATA; for(t = 0; t &lt; nthreads; ++t){ args.path = paths[i+t]; args.im = &amp;buf[t]; args.resized = &amp;buf_resized[t]; thr[t] = load_data_in_thread(args); } double start = what_time_is_it_now(); for(i = nthreads; i &lt; m+nthreads; i += nthreads){ fprintf(stderr, \"%d\\n\", i); for(t = 0; t &lt; nthreads &amp;&amp; i+t-nthreads &lt; m; ++t){ pthread_join(thr[t], 0); val[t] = buf[t]; val_resized[t] = buf_resized[t]; } for(t = 0; t &lt; nthreads &amp;&amp; i+t &lt; m; ++t){ args.path = paths[i+t]; args.im = &amp;buf[t]; args.resized = &amp;buf_resized[t]; thr[t] = load_data_in_thread(args); } for(t = 0; t &lt; nthreads &amp;&amp; i+t-nthreads &lt; m; ++t){ char *path = paths[i+t-nthreads]; char *id = basecfg(path); float *X = val_resized[t].data; network_predict(net, X); int w = val[t].w; int h = val[t].h; int nboxes = 0; detection *dets = get_network_boxes(net, w, h, thresh, .5, map, 0, &amp;nboxes); if (nms) do_nms_sort(dets, nboxes, classes, nms); if (coco){ print_cocos(fp, path, dets, nboxes, classes, w, h); } else if (imagenet){ print_imagenet_detections(fp, i+t-nthreads+1, dets, nboxes, classes, w, h); } else { print_detector_detections(fps, id, dets, nboxes, classes, w, h); } free_detections(dets, nboxes); free(id); free_image(val[t]); free_image(val_resized[t]); } } for(j = 0; j &lt; classes; ++j){ if(fps) fclose(fps[j]); } if(coco){ fseek(fp, -2, SEEK_CUR); fprintf(fp, \"\\n]\\n\"); fclose(fp); } fprintf(stderr, \"Total Detection Time: %f Seconds\\n\", what_time_is_it_now() - start);}void validate_detector_recall(char *datacfg, char *cfgfile, char *weightfile){ network *net = load_network(cfgfile, weightfile, 0); set_batch_network(net, 1); fprintf(stderr, \"Learning Rate: %g, Momentum: %g, Decay: %g\\n\", net-&gt;learning_rate, net-&gt;momentum, net-&gt;decay); srand(time(0)); list *options = read_data_cfg(datacfg); char *valid_images = option_find_str(options, \"valid\", \"data/valid.list\"); list *plist = get_paths(valid_images); char **paths = (char **)list_to_array(plist); //layer l = net-&gt;layers[net-&gt;n-1]; int j, k; int m = plist-&gt;size; //测试的图片总数 int i=0; float thresh = .95; float iou_thresh = .5; float nms = .4; int total = 0; //实际有多少个bbox int correct = 0; //正确识别出了多少个bbox int proposals = 0; //测试集预测的bbox总数 float avg_iou = 0; //printf(\"l.w*l.h*l.n = %d\\n\",l.w*l.h*l.n); for(i = 0; i &lt; m; ++i){ char *path = paths[i]; image orig = load_image_color(path, 0, 0); image sized = resize_image(orig, net-&gt;w, net-&gt;h); char *id = basecfg(path); network_predict(net, sized.data); int nboxes = 0; detection *dets = get_network_boxes(net, sized.w, sized.h, thresh, .5, 0, 1, &amp;nboxes); if (nms) do_nms_obj(dets, nboxes, 1, nms); char labelpath[4096]; find_replace(path, \"images\", \"labels\", labelpath); find_replace(labelpath, \"JPEGImages\", \"labels\", labelpath); find_replace(labelpath, \".jpg\", \".txt\", labelpath); find_replace(labelpath, \".JPEG\", \".txt\", labelpath); int num_labels = 0; //测试集实际的标注框数量 box_label *truth = read_boxes(labelpath, &amp;num_labels); for(k = 0; k &lt; nboxes; ++k){ if(dets[k].objectness &gt; thresh){ ++proposals; } } for (j = 0; j &lt; num_labels; ++j) { ++total; box t = {truth[j].x, truth[j].y, truth[j].w, truth[j].h}; //printf(\"truth x=%f, y=%f, w=%f,h=%f\\n\",truth[j].x,truth[j].y,truth[j].w,truth[j].h); float best_iou = 0; //对每一个标注的框 for(k = 0; k &lt; nboxes; ++k){ //for(k = 0; k &lt; l.w*l.h*l.n; ++k){ float iou = box_iou(dets[k].bbox, t); //printf(\"predict=%f iou=%f x=%f, y=%f, w=%f,h=%f\\n\",dets[k].objectness,iou,dets[k].bbox.x,dets[k].bbox.y,dets[k].bbox.w,dets[k].bbox.h); if(dets[k].objectness &gt; thresh &amp;&amp; iou &gt; best_iou){ best_iou = iou; } } //printf(\"best_iou=%f\\n\",best_iou); avg_iou += best_iou; if(best_iou &gt; iou_thresh){ ++correct; } } fprintf(stderr, \"%5d %5d %5d\\tRPs/Img: %.2f\\tIOU: %.2f%%\\tRecall:%.2f%%\\n\", i, correct, total, (float)proposals/(i+1), avg_iou*100/total, 100.*correct/total); free(id); free_image(orig); free_image(sized); }}void test_detector(char *datacfg, char *cfgfile, char *weightfile, char *filename, float thresh, float hier_thresh, char *outfile, int fullscreen){ list *options = read_data_cfg(datacfg); //options存储分类的标签等基本训练信息 char *name_list = option_find_str(options, \"names\", \"data/names.list\"); //抽取标签名称 char **names = get_labels(name_list); image **alphabet = load_alphabet(); //加载位于data/labels下的字符图片，用于显示矩形框名称 network *net = load_network(cfgfile, weightfile, 0); //用netweork.h中自定义的network结构体存储模型文件,函数位于parser.c set_batch_network(net, 1); srand(2222222); double start_time; double end_time; double img_time; double sum_time=0.0; char buff[256]; char *input = buff; float nms=.45; int i=0; while(1){ //读取结构对应的权重文件 if(filename){ strncpy(input, filename, 256); image im = load_image_color(input,0,0); image sized = letterbox_image(im, net-&gt;w, net-&gt;h); //输入图片大小经过resize至输入大小 //image sized = resize_image(im, net-&gt;w, net-&gt;h); //image sized2 = resize_max(im, net-&gt;w); //image sized = crop_image(sized2, -((net-&gt;w - sized2.w)/2), -((net-&gt;h - sized2.h)/2), net-&gt;w, net-&gt;h); //resize_network(net, sized.w, sized.h); layer l = net-&gt;layers[net-&gt;n-1]; float *X = sized.data; //X指向图片的data元素，即图片像素 start_time=what_time_is_it_now(); network_predict(net, X); //network_predict函数负责预测当前图片的数据X end_time=what_time_is_it_now(); img_time= end_time - start_time; printf(\"%s: Predicted in %f seconds.\\n\", input, img_time); int nboxes = 0; detection *dets = get_network_boxes(net, im.w, im.h, thresh, hier_thresh, 0, 1, &amp;nboxes); //printf(\"%d\\n\", nboxes); //if (nms) do_nms_obj(boxes, probs, l.w*l.h*l.n, l.classes, nms); if (nms) do_nms_sort(dets, nboxes, l.classes, nms); draw_detections(im, dets, nboxes, thresh, names, alphabet, l.classes); free_detections(dets, nboxes); if(outfile) { save_image(im, outfile); } else{ //save_image(im, \"predictions\"); char image[2048]; sprintf(image,\"./data/predict/%s\",GetFilename(filename)); save_image(im,image); printf(\"predict %s successfully!\\n\",GetFilename(filename));#ifdef OPENCV cvNamedWindow(\"predictions\", CV_WINDOW_NORMAL); if(fullscreen){ cvSetWindowProperty(\"predictions\", CV_WND_PROP_FULLSCREEN, CV_WINDOW_FULLSCREEN); } show_image(im, \"predictions\"); cvWaitKey(0); cvDestroyAllWindows();#endif } free_image(im); free_image(sized); if (filename) break; } else { printf(\"Enter Image Path: \"); fflush(stdout); input = fgets(input, 256, stdin); if(!input) return; strtok(input, \"\\n\"); list *plist = get_paths(input); char **paths = (char **)list_to_array(plist); printf(\"Start Testing!\\n\"); int m = plist-&gt;size; if(access(\"/aseit-data/XCM_WorkSpace/darknet_test/darknet/test_out\",0)==-1)//修改成自己的路径 { if (mkdir(\"/aseit-data/XCM_WorkSpace/darknet_test/darknet/test_out\",0777))//修改成自己的路径 { printf(\"creat file bag failed!!!\"); } } for(i = 0; i &lt; m; ++i){ char *path = paths[i]; image im = load_image_color(path,0,0); image sized = letterbox_image(im, net-&gt;w, net-&gt;h); //输入图片大小经过resize至输入大小 //image sized = resize_image(im, net-&gt;w, net-&gt;h); //image sized2 = resize_max(im, net-&gt;w); //image sized = crop_image(sized2, -((net-&gt;w - sized2.w)/2), -((net-&gt;h - sized2.h)/2), net-&gt;w, net-&gt;h); //resize_network(net, sized.w, sized.h); layer l = net-&gt;layers[net-&gt;n-1]; float *X = sized.data; //X指向图片的data元素，即图片像素 start_time = what_time_is_it_now(); network_predict(net, X); //network_predict函数负责预测当前图片的数据X end_time = what_time_is_it_now(); img_time = end_time - start_time; sum_time = sum_time+img_time; printf(\"Try Very Hard:\"); printf(\"%s: Predicted in %f seconds.\\n\", path, img_time); int nboxes = 0; detection *dets = get_network_boxes(net, im.w, im.h, thresh, hier_thresh, 0, 1, &amp;nboxes); //printf(\"%d\\n\", nboxes); //if (nms) do_nms_obj(boxes, probs, l.w*l.h*l.n, l.classes, nms); if (nms) do_nms_sort(dets, nboxes, l.classes, nms); draw_detections(im, dets, nboxes, thresh, names, alphabet, l.classes); free_detections(dets, nboxes); if(outfile){ save_image(im, outfile); } else{ char b[2048]; sprintf(b,\"/aseit-data/XCM_WorkSpace/darknet_test/darknet/test_out/%s\",GetFilename(path));//修改成自己的路径 save_image(im, b); printf(\"save %s successfully!\\n\",GetFilename(path));#ifdef OPENCV cvNamedWindow(\"predictions\", CV_WINDOW_NORMAL); if(fullscreen){ cvSetWindowProperty(\"predictions\", CV_WND_PROP_FULLSCREEN, CV_WINDOW_FULLSCREEN); } show_image(im, \"predictions\"); cvWaitKey(0); cvDestroyAllWindows();#endif } free_image(im); free_image(sized); if (filename) break; } printf(\"fps: %.2f totall image %d\\n\",(float)m/sum_time,m); } }}/*void test_detector(char *datacfg, char *cfgfile, char *weightfile, char *filename, float thresh, float hier_thresh, char *outfile, int fullscreen){ list *options = read_data_cfg(datacfg); char *name_list = option_find_str(options, \"names\", \"data/names.list\"); char **names = get_labels(name_list); image **alphabet = load_alphabet(); network *net = load_network(cfgfile, weightfile, 0); set_batch_network(net, 1); srand(2222222); double time; char buff[256]; char *input = buff; float nms=.45; while(1){ if(filename){ strncpy(input, filename, 256); } else { printf(\"Enter Image Path: \"); fflush(stdout); input = fgets(input, 256, stdin); if(!input) return; strtok(input, \"\\n\"); } image im = load_image_color(input,0,0); image sized = letterbox_image(im, net-&gt;w, net-&gt;h); //image sized = resize_image(im, net-&gt;w, net-&gt;h); //image sized2 = resize_max(im, net-&gt;w); //image sized = crop_image(sized2, -((net-&gt;w - sized2.w)/2), -((net-&gt;h - sized2.h)/2), net-&gt;w, net-&gt;h); //resize_network(net, sized.w, sized.h); layer l = net-&gt;layers[net-&gt;n-1]; float *X = sized.data; time=what_time_is_it_now(); network_predict(net, X); printf(\"%s: Predicted in %f seconds.\\n\", input, what_time_is_it_now()-time); int nboxes = 0; detection *dets = get_network_boxes(net, im.w, im.h, thresh, hier_thresh, 0, 1, &amp;nboxes); //printf(\"%d\\n\", nboxes); //if (nms) do_nms_obj(boxes, probs, l.w*l.h*l.n, l.classes, nms); if (nms) do_nms_sort(dets, nboxes, l.classes, nms); draw_detections(im, dets, nboxes, thresh, names, alphabet, l.classes); free_detections(dets, nboxes); if(outfile){ save_image(im, outfile); } else{ save_image(im, \"predictions\");#ifdef OPENCV make_window(\"predictions\", 512, 512, 0); show_image(im, \"predictions\", 0);#endif } free_image(im); free_image(sized); if (filename) break; }}void censor_detector(char *datacfg, char *cfgfile, char *weightfile, int cam_index, const char *filename, int class, float thresh, int skip){#ifdef OPENCV char *base = basecfg(cfgfile); network *net = load_network(cfgfile, weightfile, 0); set_batch_network(net, 1); srand(2222222); CvCapture * cap; int w = 1280; int h = 720; if(filename){ cap = cvCaptureFromFile(filename); }else{ cap = cvCaptureFromCAM(cam_index); } if(w){ cvSetCaptureProperty(cap, CV_CAP_PROP_FRAME_WIDTH, w); } if(h){ cvSetCaptureProperty(cap, CV_CAP_PROP_FRAME_HEIGHT, h); } if(!cap) error(\"Couldn't connect to webcam.\\n\"); cvNamedWindow(base, CV_WINDOW_NORMAL); cvResizeWindow(base, 512, 512); float fps = 0; int i; float nms = .45; while(1){ image in = get_image_from_stream(cap); //image in_s = resize_image(in, net-&gt;w, net-&gt;h); image in_s = letterbox_image(in, net-&gt;w, net-&gt;h); layer l = net-&gt;layers[net-&gt;n-1]; float *X = in_s.data; network_predict(net, X); int nboxes = 0; detection *dets = get_network_boxes(net, in.w, in.h, thresh, 0, 0, 0, &amp;nboxes); //if (nms) do_nms_obj(boxes, probs, l.w*l.h*l.n, l.classes, nms); if (nms) do_nms_sort(dets, nboxes, l.classes, nms); for(i = 0; i &lt; nboxes; ++i){ if(dets[i].prob[class] &gt; thresh){ box b = dets[i].bbox; int left = b.x-b.w/2.; int top = b.y-b.h/2.; censor_image(in, left, top, b.w, b.h); } } show_image(in, base); cvWaitKey(10); free_detections(dets, nboxes); free_image(in_s); free_image(in); float curr = 0; fps = .9*fps + .1*curr; for(i = 0; i &lt; skip; ++i){ image in = get_image_from_stream(cap); free_image(in); } } #endif}void extract_detector(char *datacfg, char *cfgfile, char *weightfile, int cam_index, const char *filename, int class, float thresh, int skip){#ifdef OPENCV char *base = basecfg(cfgfile); network *net = load_network(cfgfile, weightfile, 0); set_batch_network(net, 1); srand(2222222); CvCapture * cap; int w = 1280; int h = 720; if(filename){ cap = cvCaptureFromFile(filename); }else{ cap = cvCaptureFromCAM(cam_index); } if(w){ cvSetCaptureProperty(cap, CV_CAP_PROP_FRAME_WIDTH, w); } if(h){ cvSetCaptureProperty(cap, CV_CAP_PROP_FRAME_HEIGHT, h); } if(!cap) error(\"Couldn't connect to webcam.\\n\"); cvNamedWindow(base, CV_WINDOW_NORMAL); cvResizeWindow(base, 512, 512); float fps = 0; int i; int count = 0; float nms = .45; while(1){ image in = get_image_from_stream(cap); //image in_s = resize_image(in, net-&gt;w, net-&gt;h); image in_s = letterbox_image(in, net-&gt;w, net-&gt;h); layer l = net-&gt;layers[net-&gt;n-1]; show_image(in, base); int nboxes = 0; float *X = in_s.data; network_predict(net, X); detection *dets = get_network_boxes(net, in.w, in.h, thresh, 0, 0, 1, &amp;nboxes); //if (nms) do_nms_obj(boxes, probs, l.w*l.h*l.n, l.classes, nms); if (nms) do_nms_sort(dets, nboxes, l.classes, nms); for(i = 0; i &lt; nboxes; ++i){ if(dets[i].prob[class] &gt; thresh){ box b = dets[i].bbox; int size = b.w*in.w &gt; b.h*in.h ? b.w*in.w : b.h*in.h; int dx = b.x*in.w-size/2.; int dy = b.y*in.h-size/2.; image bim = crop_image(in, dx, dy, size, size); char buff[2048]; sprintf(buff, \"results/extract/%07d\", count); ++count; save_image(bim, buff); free_image(bim); } } free_detections(dets, nboxes); free_image(in_s); free_image(in); float curr = 0; fps = .9*fps + .1*curr; for(i = 0; i &lt; skip; ++i){ image in = get_image_from_stream(cap); free_image(in); } } #endif}*//*void network_detect(network *net, image im, float thresh, float hier_thresh, float nms, detection *dets){ network_predict_image(net, im); layer l = net-&gt;layers[net-&gt;n-1]; int nboxes = num_boxes(net); fill_network_boxes(net, im.w, im.h, thresh, hier_thresh, 0, 0, dets); if (nms) do_nms_sort(dets, nboxes, l.classes, nms);}*/// ./darknet [xxx]中如果命令如果第二个xxx参数是detector，则调用这个void run_detector(int argc, char **argv){ char *prefix = find_char_arg(argc, argv, \"-prefix\", 0); //寻找是否有参数prefix, 默认参数0，argv为二维数组，存储了参数字符串 float thresh = find_float_arg(argc, argv, \"-thresh\", .5); //寻找是否有参数thresh，thresh为输出的阈值,默认参数0.24 float hier_thresh = find_float_arg(argc, argv, \"-hier\", .5); //寻找是否有参数hier_thresh,默认0.5 int cam_index = find_int_arg(argc, argv, \"-c\", 0); //寻找是否有参数c，默认0 int frame_skip = find_int_arg(argc, argv, \"-s\", 0); //寻找是否有参数s，默认0 int avg = find_int_arg(argc, argv, \"-avg\", 3); //如果输入参数小于4个，输出正确语法如何使用 //printf 等价于 fprintf(stdout, ...)，这里stderr和stdout默认输出设备都是屏幕，但是stderr一般指标准出错输入设备 if(argc &lt; 4){ fprintf(stderr, \"usage: %s %s [train/test/valid] [cfg] [weights (optional)]\\n\", argv[0], argv[1]); return; } char *gpu_list = find_char_arg(argc, argv, \"-gpus\", 0); //寻找是否有参数gpus，默认0 char *outfile = find_char_arg(argc, argv, \"-out\", 0); //检查是否指定GPU运算,默认0 int *gpus = 0; int gpu = 0; int ngpus = 0; if(gpu_list){ printf(\"%s\\n\", gpu_list); int len = strlen(gpu_list); ngpus = 1; int i; for(i = 0; i &lt; len; ++i){ if (gpu_list[i] == ',') ++ngpus; } gpus = calloc(ngpus, sizeof(int)); for(i = 0; i &lt; ngpus; ++i){ gpus[i] = atoi(gpu_list); gpu_list = strchr(gpu_list, ',')+1; } } else { gpu = gpu_index; gpus = &amp;gpu; ngpus = 1; } int clear = find_arg(argc, argv, \"-clear\"); //检查clear参数 int fullscreen = find_arg(argc, argv, \"-fullscreen\"); int width = find_int_arg(argc, argv, \"-w\", 0); int height = find_int_arg(argc, argv, \"-h\", 0); int fps = find_int_arg(argc, argv, \"-fps\", 0); //int class = find_int_arg(argc, argv, \"-class\", 0); char *datacfg = argv[3]; //存data文件路径 char *cfg = argv[4]; //存cfg文件路径 char *weights = (argc &gt; 5) ? argv[5] : 0; //存weight文件路径 char *filename = (argc &gt; 6) ? argv[6]: 0; //存待检测文件路径 //根据第三个参数的内容，调用不同的函数，并传入之前解析的参数 if(0==strcmp(argv[2], \"test\")) test_detector(datacfg, cfg, weights, filename, thresh, hier_thresh, outfile, fullscreen); else if(0==strcmp(argv[2], \"train\")) train_detector(datacfg, cfg, weights, gpus, ngpus, clear); else if(0==strcmp(argv[2], \"valid\")) validate_detector(datacfg, cfg, weights, outfile); else if(0==strcmp(argv[2], \"valid2\")) validate_detector_flip(datacfg, cfg, weights, outfile); else if(0==strcmp(argv[2], \"recall\")) validate_detector_recall(datacfg, cfg, weights); else if(0==strcmp(argv[2], \"demo\")) { list *options = read_data_cfg(datacfg); int classes = option_find_int(options, \"classes\", 20); char *name_list = option_find_str(options, \"names\", \"data/names.list\"); char **names = get_labels(name_list); demo(cfg, weights, thresh, cam_index, filename, names, classes, frame_skip, prefix, avg, hier_thresh, width, height, fps, fullscreen); } //else if(0==strcmp(argv[2], \"extract\")) extract_detector(datacfg, cfg, weights, cam_index, filename, class, thresh, frame_skip); //else if(0==strcmp(argv[2], \"censor\")) censor_detector(datacfg, cfg, weights, cam_index, filename, class, thresh, frame_skip);} 参考YOLO-V3实战（darknet） Darknet 评估训练好的网络的性能 yolov3实战(darknet) yolo_person_detect Yolo-v3 and Yolo-v2 for Windows and Linux [pjreddie/darknet](","link":"/post/5ba44047.html"}],"tags":[{"name":"c++","slug":"c","link":"/tags/c/"},{"name":"c","slug":"c","link":"/tags/c/"},{"name":"stl","slug":"stl","link":"/tags/stl/"},{"name":"deeplearning","slug":"deeplearning","link":"/tags/deeplearning/"},{"name":"caffe","slug":"caffe","link":"/tags/caffe/"},{"name":"开源框架","slug":"开源框架","link":"/tags/开源框架/"},{"name":"学习资料","slug":"学习资料","link":"/tags/学习资料/"},{"name":"machinelearning","slug":"machinelearning","link":"/tags/machinelearning/"},{"name":"java","slug":"java","link":"/tags/java/"},{"name":"protobuf","slug":"protobuf","link":"/tags/protobuf/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"ubuntu","slug":"ubuntu","link":"/tags/ubuntu/"},{"name":"ssh","slug":"ssh","link":"/tags/ssh/"},{"name":"分布式","slug":"分布式","link":"/tags/分布式/"},{"name":"opencv","slug":"opencv","link":"/tags/opencv/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"numpy","slug":"numpy","link":"/tags/numpy/"},{"name":"zookeeper","slug":"zookeeper","link":"/tags/zookeeper/"},{"name":"网站","slug":"网站","link":"/tags/网站/"},{"name":"工具","slug":"工具","link":"/tags/工具/"},{"name":"markdown","slug":"markdown","link":"/tags/markdown/"},{"name":"图片素材","slug":"图片素材","link":"/tags/图片素材/"},{"name":"tensorflow","slug":"tensorflow","link":"/tags/tensorflow/"},{"name":"dataset","slug":"dataset","link":"/tags/dataset/"},{"name":"mybatis","slug":"mybatis","link":"/tags/mybatis/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"anaconda","slug":"anaconda","link":"/tags/anaconda/"},{"name":"ffmpeg","slug":"ffmpeg","link":"/tags/ffmpeg/"},{"name":"图像处理","slug":"图像处理","link":"/tags/图像处理/"},{"name":"音频处理","slug":"音频处理","link":"/tags/音频处理/"},{"name":"jvm","slug":"jvm","link":"/tags/jvm/"},{"name":"并发编程","slug":"并发编程","link":"/tags/并发编程/"},{"name":"springboot","slug":"springboot","link":"/tags/springboot/"},{"name":"设计模式","slug":"设计模式","link":"/tags/设计模式/"},{"name":"管程","slug":"管程","link":"/tags/管程/"},{"name":"并发工具类","slug":"并发工具类","link":"/tags/并发工具类/"},{"name":"消息队列","slug":"消息队列","link":"/tags/消息队列/"},{"name":"maven","slug":"maven","link":"/tags/maven/"},{"name":"shell","slug":"shell","link":"/tags/shell/"},{"name":"RocketMQ","slug":"RocketMQ","link":"/tags/RocketMQ/"},{"name":"MQ","slug":"MQ","link":"/tags/MQ/"},{"name":"RabbitMQ","slug":"RabbitMQ","link":"/tags/RabbitMQ/"},{"name":"darknet","slug":"darknet","link":"/tags/darknet/"}],"categories":[{"name":"C/C++","slug":"C-C","link":"/categories/C-C/"},{"name":"DeepLearning","slug":"DeepLearning","link":"/categories/DeepLearning/"},{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"Linux","slug":"Linux","link":"/categories/Linux/"},{"name":"OpenCV","slug":"OpenCV","link":"/categories/OpenCV/"},{"name":"Python","slug":"Python","link":"/categories/Python/"},{"name":"分布式","slug":"分布式","link":"/categories/分布式/"},{"name":"善用佳软","slug":"善用佳软","link":"/categories/善用佳软/"},{"name":"图像处理","slug":"图像处理","link":"/categories/图像处理/"},{"name":"JVM","slug":"Java/JVM","link":"/categories/Java/JVM/"},{"name":"Java并发编程","slug":"Java/Java并发编程","link":"/categories/Java/Java并发编程/"},{"name":"Java并发编程","slug":"Java并发编程","link":"/categories/Java并发编程/"}]}