{"pages":[{"title":"About","text":"","link":"/About/index.html"},{"title":"categories","text":"","link":"/categories/index.html"},{"title":"Tags","text":"","link":"/tags/index.html"},{"title":"Project","text":"","link":"/project/index.html"}],"posts":[{"title":"C/C++学习笔记-静态库、动态库的制作和使用","text":"本文将介绍 C 语言静态库和动态库制作和使用的过程，系统环境是 Ubuntu16.04，其他系统制作方法可能略有差别。 示例代码 目录结构12345678910.├── README.md├── include│ └── head.h├── lib├── main.c└── src ├── add.c ├── mul.c ├── sub.c include - 头文件目录 lib - 库文件目录 src - 源代码目录 静态库本节介绍如何将代码编译成静态库。当我们希望程序响应更快，或者不想提供源代码，我们可以使用静态库。 编译静态库123456789101112131415# 将 .c 文件编译成 .o 文件➜ lsadd.c mul.c sub.c➜ gcc *.c -c -I ../include➜ lsadd.c add.o mul.c mul.o sub.c sub.o# 将 .o 文件打包，生成 .a 文件➜ ar rcs libMyCalc.a *.o➜ lsadd.c libMyCalc.a mul.o sub.oadd.o mul.c sub.c# 将 .a 文件移动到 lib 目录下➜ mv libMyCalc.a ../lib 使用静态库1234567# 方式 1gcc main.c lib/libMyCalc.a -I include -o sum./sum# 方式 2gcc main.c -Iinclude -L lib -l MyCalc -o myapp./myapp 动态库 编译动态库123456789101112131415# .c 编译为 .o➜ src git:(master) ✗ lsadd.c mul.c sub.c➜ src git:(master) ✗ gcc -fPIC -c *.c -I ../include➜ src git:(master) ✗ lsadd.c add.o mul.c mul.o sub.c sub.o# .o 打包为 .so➜ src git:(master) ✗ gcc -shared -o libMyCalc.so *.o -Iinclude➜ src git:(master) ✗ lsadd.c libMyCalc.so mul.o sub.oadd.o mul.c sub.c# .so 移动到 lib➜ src git:(master) ✗ mv libMyCalc.so ../lib 使用动态库1234567# 方式 1gcc main.c lib/libMyCalc.so -o app -Iinclude./app# 方式 2gcc main.c -Iinclude -L lib -l MyCalc -o myapp./myapp 如果在使用动态库的过程中遇到了问题，请看下一小结。 动态库链接失败问题动态库是由动态连机器加载的，通过ldd app我们可以查看可执行文件执行的时候依赖的所有动态库。交由动态连接器管理的动态库都能被正确加载，比如说/lib目录下的库文件。我们自定义的动态库没有被加载就是因为没有告知动态连接器我们的动态库在哪里。 方法一 临时配置要想汤动态连机器知道我们的动态库在哪，一种方式是直接把自定义的动态库丢到/lib目录下，这样自然就能加载到了，当然我想没有人会想这么做的。另一种方式就是在配置文件中配置动态库的位置，比如像下面的这样： 1export LD_LIBRARY_PATH=我们的动态库位置 LD_LIBRARY_PATH我们可以将动态库的位置保存在这里，此时就能顺利运行程序，但是重启终端将会失效，临时测试的时候使用很方便。 方法二 永久配置1231. vim /etc/ld.so.conf2. 将动态库的路径配置在里面3. sudo ldconfig -v","link":"/post/62b06016.html"},{"title":"Protobuf 编译 Java","text":"Google Protocol Buffers 简称 Protobuf，它提供了一种灵活、高效、自动序列化结构数据的机制，可以联想 XML，但是比 XML 更小、更快、更简单。仅需要自定义一次你所需的数据格式，然后用户就可以使用 Protobuf 编译器自动生成各种语言的源码，方便的读写用户自定义的格式化的数据。与语言无关，与平台无关，还可以在不破坏原数据格式的基础上，依据老的数据格式，更新现有的数据格式。 官方下载地址： https://github.com/google/protobuf/releases/tag/v2.6.1 protobuf-2.6.1 百度云盘： 链接:http://pan.baidu.com/s/1hrK7m7a 密码:epnb 安装过程 解压文件 unzip protobuf-2.6.1.zip 进入目录 cd protobuf-2.6.1 自定义编译目录 ./configure –prefix= /Users/shui/company/protobuf 安装 make mak install 配置环境变量 vim .bash_profile 添加如下配置 export PROTOBUF=/Users/shui/company/protobufexport PATH=$PROTOBUF/bin:$PATH` 使配置生效 source .bash_profile 查看是否生效 protoc –version 安装结束，进行编译 指定需要进行编译的 proto 文件 指定编译产生的 java 文件存放的位置 假设文件名为 file.proto,文件放置在 filedir 目录下；产生的java文件也位于 filedir 目录下，编译命令如下： protoc /filedir/file/proto –java_out=/filedir 如果有很多需要编译的 proto 文件，可以进入项目目录 protoc *.proto –java_out=/filedir 参考： https://github.com/google/protobuf/tree/master/javahttp://blog.csdn.net/u013045971/article/details/50592998http://my.oschina.NET/KingPan/blog/283881?fromerr=8vajR5S9","link":"/post/7e6ba807.html"},{"title":"CentOS 7 配置","text":"本文说明如何在 Parallels 虚拟机上安装 CentOS 7 以及对其的一些基本配置，几个常用配置文件的说明和 JDK, Tomcat 和 Mysql 的安装。 CentOS 7 基本配置安装 centos 7首先下载镜像文件，我装的是 CentOS-7-x86_64-Minimal-1708.iso。我从网易的镜像下载，下载完后上传了一份到百度云盘： 网易镜像地址：http://mirrors.163.com/centos/7/isos/x86_64/百度云盘链接:http://pan.baidu.com/s/1gf7w1uN 密码:5lbx 之后按照引导即可完成，有问题可以参看 Mac利用PD虚拟机安装Centos7。 更换 yum 源yum 是一种包管理工具，就像 Java 中常用的 maven，或者安卓中用的 Gradle，再或者 Node.js 中的 npm。通过他我们能够统一地下载安装软件。但是由于网络原因下载缓慢，所以要把源换成国内的。更换过程如下： 备份： mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup 去下面的源下载对应版本repo文件, 放入/etc/yum.repos.d/ repo文件下载地址： 网易:http://mirrors.163.com/.help/centos.html阿里:http://mirrors.aliyun.com/repo/ 运行以下命令生成缓存 yum clean allyum makecache yum 源配置完成 通过 yum 安装一些基本软件net-tools 提供dig, nslookup, ipconfig等，用于配置网络： yum install net-tools 添加 wget 下载文件： yum install wget 创建一个普通用户并赋予 root 权限用普通账号进行登录可以避免 root 用户进行错误操作，而且用普通用户登录就像给服务器建立了两道墙，必须先用普通用户登录再设置能用 root 账号登录，所以后面还要配置禁止 root 用户用过 SSH 登录。 创建普通用户 useradd shuipasswd shui输入密码 这个普通用户有时也需要使用 root 权限，所以讲他加入到sudoers 用户组，允许其使用sudo临时调用 root 权限 echo ‘shui ALL=(ALL) ALL’&gt;&gt; /etc/sudoerstail -1 /etc/sudoersshui ALL=(ALL) ALL 禁止 root 使用 ssh 登入进入配置文件： /etc/ssh/sshd_config 找到如下语句进行修改 PermitRootLogin yes 把它改成 PermitRootLogin no 重启 sshd systemctl restart sshd.service 这样别人就要必须要获取普通用户账号密码，然后才能破解 root 将防火墙换成 iptablesCentOS 7.0 默认使用的是 firewall 作为防火墙，常用的是 iptables。先关闭 firewall 再安装 iptables。 关闭 firewall 1234#停止firewallsystemctl stop firewalld.service #禁止firewall开机启动systemctl disable firewalld.service 安装 iptables yum -y install iptables-services 启动 iptables 1234#重启防火墙使配置生效systemctl restart iptables.service #设置防火墙开机启动systemctl enable iptables.service 关闭 SELinux查看 SELinux 状态 /usr/sbin/sestatus -v | grep SELinuxSELinux status: enabled # 表示为开启状态 永久关闭，重启生效 vi /etc/selinux/config#修改内容如下SELINUX=disabled 更改系统语言查看当前系统语言 12345localectlSystem Locale: LANG=zh_CN.UTF-8 VC Keymap: cn X11 Layout: cn 查看系统中存在的语言列表，因为很长通过 grep 来查找需要的语言是否存在 12345678localectl list-locales | grep USen_USen_US.iso88591en_US.iso885915en_US.utf8.. 设置自己要改的语言 1localectl set-locale LANG=en_US.UTF-8 参考：CentOS yum 源的配置与使用 安裝 CentOS 7 後必做的七件事 Change system language in centos 7 一些配置文件的修改修改主机名可以用hostname来查看你的主机名，修改主机名配置文件： vi /etc/hostname 重启生效 reboot 修改 ip 地址 vi /etc/sysconfig/network-scripts/ifcfg-eth0 在网卡中配置如下内容可以设置静态 ip 12345678DEVICE=eth0TYPE=EthernetONBOOT=yesBOOTPROTO=staticIPADDR=192.168.0.11NETMASK=255.255.255.0DNS1=192.168.0.1DNS2=8.8.8.8 配置完之后保存重启网络 service network restart 设置 ip 和 hostname 的映射 vi /etc/hosts 添加上 ip 和 hostname 的键值对，举例前面设置hostname为 main 设置ip为 192.168.0.11 在最后追加一行： 123127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain6192.168.0.11 main 之后可以用主机名进行访问 安装 JDK将 JDK 安装包上传，上传可以使用 scp,rz 从本机上传，也可以直接下载。 解压 JDK 安装包： tar -zxvf jdk-8u151-linux-x64.tar.gz -C /usr/local 配置环境变量： 12345vi /etc/profile# 追加内容如下export JAVA_HOME=/usr/local/jdk1.8.0_151export PATH=$PATH:$JAVA_HOME/bin 加载环境变量： source /etc/profile 更多 linux配置java环境变量(详细) 安装 Tomcat点击此处下载安装包。本文使用的版本是apache-tomcat-8.5.23.tar.gz，下载后再安装包传到 Linux 主机。 解压安装包： tar -zxvf apache-tomcat-8.5.23.tar.gz -C /usr/local/ 启动 tomacat /usr/local/apache-tomcat-8.5.23/bin/startup.sh 查看 tomcat 进程 ps -ef | grep tomcat 访问http://192.168.2.224:8080/即主机 ip + tomcat 端口。小猫出现表示成功。 安装 MysqlMysql 安装之前先留个心，安装过程中可能会需要记录密码，有些默认没有密码，请留心有没有提示记录密码，然而没看见也没关系就是要再折腾一下。本文演示用yum安装 mysql 数据库。 配置YUM源1234567891011# 下载mysql源安装包shell&gt; wget http://dev.mysql.com/get/mysql57-community-release-el7-8.noarch.rpm# 安装mysql源shell&gt; yum localinstall mysql57-community-release-el7-8.noarch.rpm# 检查mysql源是否安装成功yum repolist enabled | grep &quot;mysql.*-community.*&quot;# 成功显示如下mysql-connectors-community/x86_64 MySQL Connectors Community 42mysql-tools-community/x86_64 MySQL Tools Community 51mysql57-community/x86_64 MySQL 5.7 Community Server 227 安装MySQL yum install mysql-community-server 启动 mysql systemctl start mysqld 查看MySQL的启动状态 systemctl status mysqld 修改 root 默认密码mysql安装完成之后，在/var/log/mysqld.log文件中给root生成了一个默认密码。通过下面的方式找到root默认密码，然后登录mysql进行修改： grep ‘temporary password’ /var/log/mysqld.log2017-11-15T16:26:37.970235Z 1 [Note] A temporary password is generated for root@localhost: d54aqgZr69&gt;d 此时默认的密码就是d54aqgZr69&gt;d，用 root 身份登录之后修改密码： mysql -uroot -pALTER USER ‘root‘@’localhost’ IDENTIFIED BY ‘MyNewPass1!’; 注：mysql 的密码需要有一定复杂度 更多请参考:CentOS7下安装MySQL5.7安装与配置（YUM）","link":"/post/99732d8a.html"},{"title":"Linux 权限","text":"Linux 是多用户的操作系统，同一时间可以有多个用户同时操作同一台计算机。为了让用户和用户之间不相互影响，必须要有一种机制来保障每一个用户的行为不会越界对其他用户造成不必要的影响。 用户和用户组了解 Linux 的权限管理首先要了解用户和组的概念。Linux 引入了用户和用户组的概念，一个用户可以拥有多个文件和目录， 用户对这个文件或目录的访问权限拥有控制权。同时用户可以属于一个或者多个用户组，用户组中的用户拥有同属于这个组的对文件的访问控制权。 Linux 会给每个用户分配一个 uid（标识用户） 和 gid (标识用户组)，在创建用户的时候默认就会创建一个和用户名同名的用户组，我可以用id命令来查看： iduid=0(root) gid=0(root) 组=0(root) 环境=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 这些信息都是配置在配置文件中的，我们有必要了解这些信息在哪些配置文件中,他们主要配置在三个文件中/etc/shadow,/etc/passwd和/etc/group。 用户帐户 定义在/etc/passwd 文件里面，用户组定义在/etc/group 文件里面。当用户帐户和用户组创建以后， 这些文件随着文件/etc/shadow 的变动而修改，文件/etc/shadow 包含了关于用户密码的信息。 对于每个用户帐号，文件/etc/passwd 定义了用户（登录）名、uid、gid、帐号的真实姓名、家目录 和登录 shell。如果你查看一下文件/etc/passwd 和文件/etc/group 的内容，你会注意到除了普通 用户帐号之外，还有超级用户（uid 0）帐号，和各种各样的系统用户。 基本的用户管理创建一个普通用户添加用户 useradd shui 设置密码 passwd shui 按提示输入密码即可 这样就会创建一个新的用户，我们可以在/etc/group中看到新建的默认用户组的信息shui:x:1000:也可以再/etc/shadow,/etc/passwd看到相关信息。 为用户配置sudo权限配置sudo权限就是将永不加入到sudoers用户组中，这是一个特殊的用户组，在这个用户组中的用户可以通过在命令前面添加sudo临时获取root的权限。 用root编辑 vi /etc/sudoers 在文件的如下位置，为hadoop添加一行即可 root ALL=(ALL) ALLshui ALL=(ALL) ALL 或者使用如下语句也是相同效果 echo ‘shui ALL=(ALL) ALL’&gt;&gt; /etc/sudoers 然后，hadoop用户就可以用sudo来执行系统级别的指令 文件权限的操作前面说过用户具有对文件的的访问控制权，访问控制权具有可读、可写、可操作三种，我们来具体看一下 linux 文件权限的描述格式解读用ll命令来看一下根目录下的文件信息,我们复制其中的一部分： 1234dr-xr-xr-x. 5 root root 4096 11月 2 10:34 bootdrwxr-xr-x. 20 root root 3140 11月 2 10:36 devdrwxr-xr-x. 74 root root 8192 11月 2 20:48 etcdrwxr-xr-x. 3 root root 18 11月 2 19:03 home 每个文件的信息大同小异，关注最前面的十个字符，他就表示文件的操作权限。 以/etc目录的信息为例drwxr-xr-x. 74 root root 8192 11月 2 20:48 etc 第一位表示文件类型,d 表示这是一个文件夹，文件属性还有以下内容 后面的九位分别代表用户权限、用户组权限和其他用户权限 r:表示可读 read w:表示可惜 write x:表示可执行 excute /etc 目录的权限 rwxr-xr-x 就表示，root 用户具有可读可写可操作的权限，文件所有者的组成员可以访问该目录，但是不能新建、重命名、删除文件，其他成员可以访问该目录，但是不能新建、重命名、删除文件。 chmod 更改权限只有root和文件的所有者才能更改文件的权限，更改文件的权限有两种方式，一种是使用符号，另一种是使用八进制数字。 符号方式修改文件权限符号即前面rwx对应的含义，ugoa则分别表示用户(user)、用户组(group)、其他人(other)和所有(all),一组示例来演示： 123chmod g-rw haha.dat 表示将haha.dat对所属组的rw权限取消chmod o-rw haha.dat 表示将haha.dat对其他人的rw权限取消chmod u+x haha.dat 表示将haha.dat对所属用户的权限增加x 八进制的方式来修改权限一个八进制数字可以表示三个二进制数，二进制的 111 对应八进制的 7，而 111 正好可以表示 rwx 的含义，1 则代表有权限 0 则代表没有权限。 八进制 二进制 符号 0 000 — 1 001 —-x 2 010 -w- 3 011 -wx 4 100 r– 5 101 r-x 6 110 rw- 7 111 rwx 例如： chmod 664 haha.dat修改成 rw-rw-r– 一些人喜欢使用八进制表示法，而另一些人则非常喜欢符号表示法。符号表示法的优点是， 允许你设置文件模式的某个属性，而不影响其他的属性。 更多权限Linux 用户和用户组管理","link":"/post/40efde90.html"},{"title":"Linux中几种常用的文件传输方式","text":"整理scp,wget,ftp以及其他Linux中常用的文件传输方式的介绍。 scp当没有安装web server和ftp server的时候或感觉上面的方法比较麻烦，那么用scp命令就会排上用场。 scp是什么？scp是secure copy的简写，用于在Linux下进行远程拷贝文件的命令，和它类似的命令有cp，不过cp只是在本机进行拷贝不能跨服务器，而且scp传输是加密的。可能会稍微影响一下速度。 scp有什么用？1、我们需要获得远程服务器上的某个文件，远程服务器既没有配置ftp服务器，没有开启web服务器，也没有做共享，无法通过常规途径获得文件时，只需要通过scp命令便可轻松的达到目的。 2、我们需要将本机上的文件上传到远程服务器上，远程服务器没有开启ftp服务器或共享，无法通过常规途径上传是，只需要通过scp命令便可以轻松的达到目的。 scp使用方法获取远程服务器上的文件 scp root@192.168.0.223:/apps/test/a.md /Users/shui/Desktop/b.md root@192.168.0.223 : 使用root用户登录服务器192.168.0.223 /apps/test/a.md:本机要传递过去的文件 /Users/shui/Desktop/b.md：远程主机目录 获取远程服务器上的目录 scp -r root@192.168.0.223:/apps/test/a /Users/shui/Desktop/b 将本地文件上传到服务器上 scp test.txt root@192.168.0.223:/apps/test/a.txt root@192.168.0.223 : 使用root用户登录远程服务器192.168.0.223 test.txt:本机要传递过去的文件 /apps/test/a.txt：远程主机目录和文件名 将本地目录上传到服务器上 scp -r dir1 root@192.168.0.223:/apps/test/a 当 scp 指定端口时 scp -P 2222 -r dir1 root@192.168.0.223:/apps/test/a 可能有用的几个参数 -v 和大多数 linux 命令中的 -v 意思一样 , 用来显示进度 . 可以用来查看连接 , 认证 , 或是配置错误 .-C 使能压缩选项 .-4 强行使用 IPV4 地址 .-6 强行使用 IPV6 地址 . 参考：scp 命令 Wget Linux系统中的wget是一个下载文件的工具，它用在命令行下。对于Linux用户是必不可少的工具，我们经常要下载一些软件或从远程服务器恢复备份到本地服务器。wget支持HTTP，HTTPS和FTP协议，可以使用HTTP代理。所谓的自动下载是指，wget可以在用户退出系统的之后在后台执行。这意味这你可以登录系统，启动一个wget下载任务，然后退出系统，wget将在后台执行直到任务完成，相对于其它大部分浏览器在下载大量数据时需要用户一直的参与，这省去了极大的麻烦。 wget 可以跟踪HTML页面上的链接依次下载来创建远程服务器的本地版本，完全重建原始站点的目录结构。这又常被称作”递归下载”。在递归下载的时候，wget 遵循Robot Exclusion标准(/robots.txt). wget可以在下载的同时，将链接转换成指向本地文件，以方便离线浏览。 wget 非常稳定，它在带宽很窄的情况下和不稳定网络中有很强的适应性.如果是由于网络的原因下载失败，wget会不断的尝试，直到整个文件下载完毕。如果是服务器打断下载过程，它会再次联到服务器上从停止的地方继续下载。这对从那些限定了链接时间的服务器上下载大文件非常有用。 下载单个文件 wget http://www.minjieren.com/wordpress-3.1-zh_CN.zip 下载并以不同的文件名保存 wget -O tomcat.tar.gz http://mirrors.tuna.tsinghua.edu.cn/apache/tomcat/tomcat-8/v8.5.24/bin/apache-tomcat-8.5.24.tar.gz 后台下载 wget -b http://mirrors.hust.edu.cn/apache/maven/maven-3/3.5.2/binaries/apache-maven-3.5.2-bin.tar.gz 参考：每天一个linux命令（61）：wget命令 Ftp功能 ftp 命令使用文件传输协议（File Transfer Protocol, FTP）在本地主机和远程主机之间或者在两个远程主机之间进行文件传输。 FTP 协议允许数据在不同文件系统的主机之间传输。尽管这个协议在传输数据上提供了高适应性，但是它并没有尝试去保留一个特定文件系统上的文件属性（例如一个文件的保护模式或者修改次数）。而且 FTP 协议很少对一个文件系统的整体结构作假定，也不提供这样的功能，比如递归的拷贝子目录。在使用 ftp 命令时，需要注意 FTP 协议的这些特性。当需要保留文件属性或者需要递归的拷贝子目录时，可以使用 rcp/scp 等命令。 语法 ftp [-dignv][主机名称或IP地址] 参数： -d 详细显示指令执行过程，便于排错或分析程序执行的情形。-i 关闭互动模式，不询问任何问题。-g 关闭本地主机文件名称支持特殊字符的扩充特性。-n 不使用自动登陆。-v 显示指令执行过程。 Linux ftp命令 其他摘自：Linux 上的常用文件传输方式介绍与比较 综上所述各种文件传输方式的特征表现各有千秋，我们从以下几个方面综合对比，更深入地了解它们各自的特性。 传输性能wget 通过支持后台执行及断点续传提高文件传输效率 ； rsync 则以其高效的传输及压缩算法达到快传输的目的。 配置难度rcp 只需进行简单的配置，创建 .rhost 文件以及设置 /etc/hosts 文件中主机名与 IP 地址列表； wget 设置设置方便简单，只需在客户端指定参数执行命令即可； rsync 在使用前需要对服务端 /etc/rsyncd.conf 进行参数设定，配置内容相对复杂。 安全性能ftp、rcp 不保证传输的安全性，scp、rsync 则均可基于 ssh 认证进行传输，提供了较强的安全保障。 wget 也可通过指定安全协议做到安全传输。 通过上述的对比不难发现，每种文件传输方法基于其自身的特点与优势均有其典型的适用场景： ftp 作为最常用的入门式的文件传输方法，使用简单，易于理解，并且可以实现脚本自动化； rcp 相对于 ftp 可以保留文件属性并可递归的拷贝子目录； scp 利用 ssh 传输数据，并使用与 ssh 相同的认证模式，相对于 rcp 提供更强的安全保障； wget，实现递归下载，可跟踪 HTML 页面上的链接依次下载来创建远程服务器的本地版本，完全重建原始站点的目录结构，适合实现远程网站的镜像； curl 则适合用来进行自动的文件传输或操作序列，是一个很好的模拟用户在网页浏览器上的行为的工具； rsync 更适用于大数据量的每日同步，拷贝的速度很快，相对 wget 来说速度快且安全高效。","link":"/post/a6fc1711.html"},{"title":"Ubuntu OpenSSH Server","text":"本文介绍如何使用OpenSSH实现计算机之间的远程控制和数据交换。你将了解到OpenSSH的一些配置以及如何在Ubuntu中修改这些配置。 Ubuntu16.04是目前Ubuntu较为稳定的版本，本文使用该版本进行说明。 介绍OpenSSH基于SSH协议，是用于实现计算机之间远程控制和数据交换的工作的工具。 传统的工具实现远程登录(telnet)和rcp等功能的方式不安全的，他们会用明文的方式交换用户密码。OpenSSH用后台进程和客户端工具来提高安全性，对远程控制和数据交换操作进行加密，比其他传统工具更加高效。 OpenSSH使用sshd持续地监听来自各个客户端程序的连接。当客户端发出连接请求，ssh根据客户端的连接类型来判断是否建立连接。比如，如果远程计算机是一个ssh客户端程序，OpenSSH将会在认证之后建立一个控制会话。如果远程用户使用scp进行连接，OpenSSH在认证之后会与客户端建立连接，并在后台初始化一个安全的文件拷贝。 OpenSSH可以使用密码、公钥和 Kerberos 等多种方式进行认证。 安装OpenSSH的安装非常简单，分别安装OpenSSH Sever和OpenSSH Client。 sudo apt install openssh-clientsudo apt install openssh-server 配置OpenSSH的配置文件是/etc/ssh/sshd_config，查看详细配置可以使用 man sshd_config 在修改配置文件之前我们应当对配置文件进行备份 sudo cp /etc/ssh/sshd_config /etc/ssh/sshd_config.originalsudo chmod a-w /etc/ssh/sshd_config.original 我们可以通过修改配置文件做这些事情： 将OpenSSH监听的默认TCP端口从2222改为默认端口22，可以修改Port 2222 允许运行使用公式登录，可以使用PubkeyAuthentication yes 修改完成之后重启服务使其生效 sudo systemctl restart sshd.service SSH Keys配置了ssh key允许主机之间直接通信而不用输入密码。 首选生成ssh key，使用一下命令并一路回车 ssh-keygen -t rsa 此时会在~/.ssh文件夹在生产一个密钥文件和一个公钥文件，我们将公钥拷贝给远程的主机 ssh-copy-id username@remotehost 之后用相同的方式将远程主机的公钥拷贝给本机，就可以实现双方免密登录。 最后我们还要注意，认证用户需要对用于认证的文件有读写的权限。 chmod 600 .ssh/authorized_keys 引用OpenSSH Server","link":"/post/cbbc9ca0.html"},{"title":"实现 SSH 免密登录","text":"SSH (Secure Shell的) 是一种网络协议，用于计算机之间的加密登录。 通过使用SSH，你可以把所有传输的数据进行加密更加安全可靠。使用SSH，还有一个额外的好处就是传输的数据是经过压缩的，所以可以加快传输的速度。SSH 有很多功能，它既可以代替 Telnet，又可以为FTP、Pop、甚至为 PPP 提供一个安全的”通道”。 主机之间通过 SSH 进行连接的时候需要输入密码进行校验。在部署分布式应用时，主机间要建立良好的通信，首先要做的就是配置 SSH 免密登录。 以下演示在centos 7中配置免密登录。 配置主机间的免密登录配置免密登录什么是免密登录呢？ 通常我们登录 SSH 是通过账号和免密来登录的，输入ssh username@ip-server然后输入密码。 如果每次都输入密码会很麻烦，而且要对多台主机进行自动化管理，每次都要输入密码不现实。我们可以配置公钥和密钥进行免密登录。免密登录做的事情其实就是通过 SSH 的公钥和密钥来校验身份信息。 首先你要知道每台主机有一份公钥和一份私钥。我们要做的事情可以用一张图来表示： 1.生成密匙对 ssh-keygen 之后可以在/root/.ssh中看到生成的密匙对 123[root@main /]# cd /root/.ssh/[root@main .ssh]# lsid_rsa id_rsa.pub 2.拷贝一份 A 的公钥给 B ssh-copy-id 192.168.0.10输入密码 此时在 B 的authorized_keys中就会有一份 A 的id_rsa.pub公钥信息。 注：第二步操作的做的事情其实就是一个拷贝密钥的工作，也可以手动拷贝，但是用上面的命令更方便。 3.最后我们就可以免密登录,也就是不输入密码 A 就可以登录 B ssh root@192.168.0.10 192.168.0.10 为 B 的 ip 地址 如果要退出登录，输入exit即可。 给主机起一个别名192.168.0.10 是 ip 地址，也就是说登录的时候我们还要输入一次 ip。我们可以给每个主机配置一个别名，用ssh ip-server的方式登录。 就像人有身份证也有名字一样，我们可以通过 ip 来辨识主机。给他一个别名就是给一个hostname。 可以用hostname来查看你的主机名，要改主机名改他的配置文件 vi /etc/hostname在其中替换为你要改的名字，比如 main 重启生效 reboot 这样主机名已经改掉了，还差一步。我们要让主机名和我们的 ip 关联在一起，修改/etc/hosts文件 vi /etc/hosts添加上 ip 和 hostname 的键值对 例如： 1234127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain6192.168.0.11 main192.168.0.10 slave 两边都配置完成可以用ssh slave直接连接slave。如果你想自己免密连接自己那就按照上面的步骤给自己配置一份密匙就行了，动手试试吧。 SSH 协议是什么以及更多参考SSH 协议介绍 数字签名是什么 SSH原理与运用（一）：远程登录 SSH原理与运用（二）：远程操作与端口转发 如何在CentOS 7上修改主机名","link":"/post/ea055f0d.html"},{"title":"Numpy 小结","text":"NumPy 是 Python 语言的一个扩充程序库。支持高级大量的维度数组与矩阵运算，此外也针对数组运算提供大量的数学函数库，也是学习 python 必学的一个库。 1. 读取文件numpy.genfromtxt() 用于读取 txt 文件，其中传入的参数依次为： 需要读取的 txt 文件位置，此处文件与程序位于同一目录下 分割的标记 转换类型，如果文件中既有文本类型也有数字类型，就先转成文本类型 help(numpy.genfromtxt)用于查看帮助文档：如果不想看 API 可以启动一个程序用 help 查看指令的详细用法 123456import numpyworld_alcohol = numpy.genfromtxt(\"world_alcohol.txt\", delimiter=\",\",dtype=str)print(type(world_alcohol))print(world_alcohol)print(help(numpy.genfromtxt)) 2. 构造 ndarraynumpy.array()构造 ndarraynumpy.array()中传入数组参数，可以是一维的也可以是二维三维的。numpy 会将其转变成 ndarray 的结构。 12vector = numpy.array([1,2,3,4])matrix = numpy.array([[1,2,3],[4,5,6]]) 传入的参数必须是同一结构,不是同一结构将发生转换。 123vector = numpy.array([1,2,3,4])array([1, 2, 3, 4]) 均为 int 类型 123vector = numpy.array([1,2,3,4.0])array([ 1., 2., 3., 4.]) 转为浮点数类型 123vector = numpy.array([1,2,'3',4])array(['1', '2', '3', '4'],dtype='&lt;U21') 转为字符类型 利用 .shape 查看结构能够了解 array 的结构，debug 时通过查看结构能够更好地了解程序运行的过程。 1234print(vector.shape)print(matrix.shape)(4,)(2, 3) 利用 dtype 查看类型1234vector = numpy.array([1,2,3,4])vector.dtypedtype('int64') ndim 查看维度一维 1234vector = numpy.array([1,2,3,4])vector.ndim1 二维 123456matrix = numpy.array([[1,2,3], [4,5,6], [7,8,9]])matrix.ndim2 size 查看元素数量12matrix.size9 3. 获取与计算numpy 能使用切片获取数据123matrix = numpy.array([[1,2,3], [4,5,6], [7,8,9]]) 根据条件获取numpy 能够依次比较 vector 和元素之间是否相同 1234vector = numpy.array([5, 10, 15, 20])vector == 10array([False, True, False, False], dtype=bool) 根据返回值获取元素 1234567vector = numpy.array([5, 10, 15, 20])equal_to_ten = (vector == 10)print(equal_to_ten)print(vector[equal_to_ten])[False True False False][10] 进行运算之后获取 12vector = numpy.array([5, 10, 15, 20])equal_to_ten_and_five = (vector == 10) &amp; (vector == 5) 12vector = numpy.array([5, 10, 15, 20])equal_to_ten_or_five = (vector == 10) | (vector == 5) 类型转换将整体类型进行转换 1234567vector = numpy.array([5, 10, 15, 20])print(vector.dtype)vector = vector.astype(str)print(vector.dtype)int64&lt;U21 求和sum() 能够对 ndarray 进行各种求和操作，比如分别按行按列进行求和 12345678910matrix = numpy.array([[1,2,3], [4,5,6], [7,8,9]])print(matrix.sum())print(matrix.sum(1))print(matrix.sum(0))45[ 6 15 24][12 15 18] sum(1) 是 sum(axis=1)) 的缩写，1表示按照 x轴方向求和，0表示按照y轴方向求和 4. 常用函数reshape生成从 0-14 的 15 个数字，使用 reshape(3,5) 将其构造成一个三行五列的 array。 1234567import numpy as nparr = np.arange(15).reshape(3, 5)arrarray([[ 0, 1, 2, 3, 4], [ 5, 6, 7, 8, 9], [10, 11, 12, 13, 14]]) zeros生成指定结构的默认为 0. 的 array 12345np.zeros ((3,4))array([[ 0., 0., 0., 0.], [ 0., 0., 0., 0.], [ 0., 0., 0., 0.]]) ones生成一个三维的 array,通过 dtype 指定类型 123456789np.ones( (2,3,4), dtype=np.int32 )array([[[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]], [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]]) range指定范围和数值间的间隔生成 array，注意范围包左不包右 123np.arange(0,10,2)array([0, 2, 4, 6, 8]) random 随机数生成指定结构的随机数，可以用于生成随机权重 1234np.random.random((2,3))array([[ 0.86166627, 0.37756207, 0.94265883], [ 0.9768257 , 0.96915312, 0.33495431]]) 5. ndarray 运算元素之间依次相减相减 12345a = np.array([10,20,30,40])b = np.array(4)a - barray([ 6, 16, 26, 36]) 乘方12a**2array([ 100, 400, 900, 1600]) 开根号 1234np.sqrt(B)array([[ 1.41421356, 0. ], [ 1.73205081, 2. ]]) e 求方 1234np.exp(B)array([[ 7.3890561 , 1. ], [ 20.08553692, 54.59815003]]) 向下取整 12345a = np.floor(10*np.random.random((2,2)))aarray([[ 0., 0.], [ 3., 6.]]) 行列变换 1234a.Tarray([[ 0., 3.], [ 0., 6.]]) 变换结构 1234a.resize(1,4)aarray([[ 0., 0., 3., 6.]]) 6. 矩阵运算矩阵之间的运算 1234A = np.array( [[1,1], [0,1]] )B = np.array( [[2,0], [3,4]] ) 对应位置一次相乘 1234A*Barray([[2, 0], [0, 4]]) 矩阵乘法 12345print (A.dot(B))print(np.dot(A,B))[[5 4] [3 4]] 横向相加 12345678910111213a = np.floor(10*np.random.random((2,2)))b = np.floor(10*np.random.random((2,2)))print(a)print(b)print(np.hstack((a,b)))[[ 2. 3.] [ 9. 3.]][[ 8. 1.] [ 0. 0.]][[ 2. 3. 8. 1.] [ 9. 3. 0. 0.]] 纵向相加 123456print(np.vstack((a,b)))[[ 2. 3.] [ 9. 3.] [ 8. 1.] [ 0. 0.]] 矩阵分割 1234#横向分割print( np.hsplit(a,3))#纵向风格print(np.vsplit(a,3)) 7. 复制的区别地址复制通过 b = a 复制 a 的值，b 与 a 指向同一地址，改变 b 同时也改变 a。 123456789101112131415a = np.arange(12)b = aprint(a is b)print(a.shape)print(b.shape)b.shape = (3,4)print(a.shape)print(b.shape)True(12,)(12,)(3, 4)(3, 4) 复制值通过 a.view() 仅复制值，当对 c 值进行改变会改变 a 的对应的值，而改变 c 的 shape 不改变 a 的 shape 1234567891011121314a = np.arange(12)c = a.view()print(c is a)c.shape = 2,6c[0,0] = 9999print(a)print(c)False[9999 1 2 3 4 5 6 7 8 9 10 11][[9999 1 2 3 4 5] [ 6 7 8 9 10 11]] 完整拷贝a.copy() 进行的完整的拷贝，产生一份完全相同的独立的复制 1234567891011121314a = np.arange(12)c = a.copy()print(c is a)c.shape = 2,6c[0,0] = 9999print(a)print(c)False[ 0 1 2 3 4 5 6 7 8 9 10 11][[9999 1 2 3 4 5] [ 6 7 8 9 10 11]]","link":"/post/a404f4e2.html"},{"title":"Ubuntu16.04配置OpenCV环境","text":"本文介绍在 Ubuntu16.04 中配置 OpenCV 的环境 Linux 环境: Ubuntu16.04 LST 软件版本: opencv-3.4.0 、opencv_contrib-3.4.0 (安装包在文末下载) 参考文档：Installation in Linux 依赖安装执行以下命令 12345[compiler] sudo apt-get install build-essential[required] sudo apt-get install cmake git libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-dev cmake-gui[optional] sudo apt-get install python-dev python-numpy libtbb2 libtbb-dev libjpeg-dev libpng-dev libtiff-dev libjasper-dev libdc1394-22-dev 下载以下两个文件，注意版本 opencv-3.4.0 、opencv_contrib-3.4.0 解压文件，并新建一个build文件夹作为编译目录，如下 1234opencv/├── build├── opencv-3.4.0└── opencv_contrib-3.4.0 使用CMake-gui进行编译使用cmake-gui生成Makefile,并进行编译 生成 Makefile 点击 Browse_Source… 引入 opencv-3.4.0 文件夹 点击 Browse_Build… 引入 build 文件夹 点击 Configure 点击 Generate 弹出如下对话框，选择使用Makefile生成的系统平台 123注：1. 第一次会弹出`CMakeSetup`选择`default`那个就可以了2. 开始的时候没有上图红色部分 之后我们勾选下面这几个选项 编译成静态库，取消选择 BUILD_SHARED_LIBS 勾选 OPENCV_ENABLE_NOFREE 选择 OPENCV_EXTRA_MODULES_PATH 引入 opencv_contrib-3.4.0 下的 modules 文件夹 点击 Configure 点击 Generate 编译进入 build 文件夹路径 make -j7 # 7 表示7个并发 修改 opencv.pv 文件 cd /build/unix_install vim opencv.pc 12345678910111213# Package Information for pkg-configprefix=/usr/localexec_prefix=${prefix}libdir=${exec_prefix}/libincludedir_old=${prefix}/include/opencvincludedir_new=${prefix}/includeName: OpenCVDescription: Open Source Computer Vision LibraryVersion: 3.4.0Libs: -L${exec_prefix}/lib -lopencv_stitching -lopencv_superres -lopencv_videostab -lopencv_aruco -lopencv_bgsegm -lopencv_bioinspired -lopencv_ccalib -lopencv_dpm -lopencv_face -lopencv_photo -lopencv_freetype -lopencv_fuzzy -lopencv_img_hash -lopencv_line_descriptor -lopencv_optflow -lopencv_reg -lopencv_rgbd -lopencv_saliency -lopencv_stereo -lopencv_structured_light -lopencv_phase_unwrapping -lopencv_surface_matching -lopencv_tracking -lopencv_datasets -lopencv_text -lopencv_dnn -lopencv_plot -lopencv_xfeatures2d -lopencv_shape -lopencv_video -lopencv_ml -lopencv_ximgproc -lopencv_calib3d -lopencv_features2d -lopencv_highgui -lopencv_videoio -lopencv_flann -lopencv_xobjdetect -lopencv_imgcodecs -lopencv_objdetect -lopencv_xphoto -lopencv_imgproc -lopencv_coreLibs.private: -ldl -lm -lpthread -lrtCflags: -I${includedir_old} -I${includedir_new} 将文件中的Libs.private:删除 sudo make install sudo updatedb sudo ldconfig 运行写一段测试程序，可以使用命令行的方式或者 CMake 进行编译 测试程序12345678910111213141516171819202122232425262728293031323334353637#include \"opencv2/highgui/highgui.hpp\"#include \"opencv2/imgproc/imgproc.hpp\"#include \"opencv2/core/core.hpp\"#include \"opencv2/video/video.hpp\"#include &lt;iostream&gt;using namespace cv;int main(int argc, char **argv){ // 从命令行参数读取图片路径 char *imageName = argv[1]; Mat image; image = imread(imageName, IMREAD_COLOR); if (argc != 2 || !image.data) { std::cout &lt;&lt; \"No image data\" &lt;&lt; std::endl; return -1; } Mat gray_image; cvtColor(image, gray_image, COLOR_BGR2GRAY); // 保存转换之后的灰度图片 imwrite(\"Gray_Image.jpg\", gray_image); namedWindow(imageName, WINDOW_AUTOSIZE); namedWindow(\"Gray image\", WINDOW_AUTOSIZE); imshow(imageName, image); imshow(\"Gray image\", gray_image); waitKey(0); return 0;} 命令行方式编译 g++ ModifyImage.cpp pkg-config --cflags --libs opencv -o ModifyImage CMake 方式编译新建一个CMakeLists.txt 123456cmake_minimum_required(VERSION 2.8)project( ModifyImage )find_package( OpenCV REQUIRED )include_directories( ${OpenCV_INCLUDE_DIRS} )add_executable( ModifyImage ModifyImage.cpp )target_link_libraries( ModifyImage ${OpenCV_LIBS} ) 输入以下命令 cmake . make 通过以上两种方式都会生成一个可执行文件，我们可以执行它 ./ModifyImage","link":"/post/5359e313.html"},{"title":"zookeeper 的安装和配置","text":"ZooKeeper 是一个分布式协调服务。其本身就是一个高可用的分布式程序，只需半数以上节点存活即可继续使用，所以使用中往往配置奇数台主机。他主要能提供主从协调、服务器节点动态上下线、统一配置管理、分布式共享锁、统一名称服务等。 本文演示在 CentOS 7 虚拟机部署和配置 zookeeper。 下载首先需要下载安装包。前去下载地址下载安装包，本文使用的 zookeeper 版本是zookeeper-3.4.10。 下载完成之后将安装包传到服务器，我将其传到 apps 目录下： scp zookeeper-3.4.10.tar.gz root@192.168.2.222:/apps/ 解压安装包 sudo tar -zxvf zookeeper-3.4.10.tar.gz -C /apps/ 重命名解压文件 sudo mv zookeeper-3.4.10 zookeeper 配置环境变量修改配置文件 vi /etc/profile添加如下内容：# zookeeperexport ZOOKEEPER_HOME=/apps/zookeeperexport PATH=\\$PATH:$ZOOKEEPER_HOME/bin 注：ZOOKEEPER_HOME 为你自己的文件位置。 手动加载配置文件： source /etc/profile 修改 zookeeper 配置文件配置文件放置在 zookeeper/conf 目录下，查看目录文件有三个，其中zoo_sample.cfg是范例配置文件： 12$lsconfiguration.xsl log4j.properties zoo_sample.cfg 复制zoo_sample.cfg并重命名zoo.cfg,zoo.cfg就是需要的配置文件： cp zoo_sample.cfg zoo.cfgvi zoo.cfg 配置文件中添加或修改如下内容： 12345678# 数据目录dataDir=/home/hadoop/zookeeper/data# 日志目录dataLogDir=/home/hadoop/zookeeper/log# 包括自己在内的所有主机名称server.1=slave1:2888:3888 (主机名, 心跳端口、数据端口)server.2=slave2:2888:3888server.3=slave3:2888:3888 注意：slave1、slave2、slave3 是主机名即 hostname。所以需要配置主机名和 ip 的映射。 新建对应的文件夹: mkdir -m 755 zookeeper/datamkdir -m 755 zookeeper/log 配置 myid： echo 1 &gt; zookeeper/data/myid 给三台主机的名称分别配置为1,2,3。 最后：在另外两台主机上使用任意方法重复如上配置并修改主机名配置完成 启动 zookeeper进入启动目录 cd /apps/zookeeper/bin 启动 zkServer.sh start 查看状态 zkServer.sh status 12345Using config: /apps/zookeeper/bin/../conf/zoo.cfgMode: leader----Using config: /apps/zookeeper/bin/../conf/zoo.cfgMode: follower 以上，zookeeper 的基本安装配置完毕。","link":"/post/530b5399.html"},{"title":"更多搜索引擎","text":"善用搜索引擎，程序员提升的一大步。 谷歌 全球最大搜索引擎公司。 必应 微软旗下，比较出名了，国内可访问。 Bird.so 技术问题的聚合，国内也可访问，是我谷歌替代方案。 DuckDuckGo 注重隐私安全，不记录用户数据是卖点，注重隐私的人的上好选择。 Wikipedia 维基百科就像是一本参考书，有很高的权威性。 SemanticScholar Semantic Scholar 是由微软联合创始人 Paul Allen 做的免费学术搜索引擎，其检索结果来自于期刊、学术会议资料或者是学术机构的文献。 MEZW MEZW 搜索服务可以汇集国内外网页的搜索结果，登录帐号，更可自定义的屏蔽掉不希望展示在搜索结果中的网站。","link":"/post/9a276542.html"},{"title":"Python 编程，从入门到实践","text":"本周读的是《Python编程，从入门到实践》这本书。读这本书的目的很简单，工作中需要用到 Python 这门编程语言，需要补充一下知识。 全书分成两个部分，第一部分是Python的语法说明，第二部分是 3 个实战项目。我学习的方式是梳理了Python的思维导图，并且实现书中的一些 Practice。读完本书之后基本掌握了Python的语法，了解到一些使用的Python库的用法，将其应用到工作中可以写一些脚本，还写了一个爬取百度图片的程序。 总体的感受是Python是一门简单且实用的语言，要想更好地掌握这门语言需要更多的练习。 最后，推荐实用本书作为 Python 入门之用，优点在于书中的例子详实且有趣，只要能在理解之后自己敲一遍就能基本学会 Python 的使用。 开始 每周一书 的活动，上周入职开始上班，没有在学校里那样多完全属于自己的时间。开始思考如何平衡工作和生活，如何安排自己的学习时间。因此有了 每周一书 的想法，每周读一本书，只要是自己想读的就行，在博客中输出自己的想法、或者提出疑问。","link":"/post/d84813e6.html"},{"title":"西部世界-自省意识的觉醒","text":"列车划过辽阔的草原，长长的车身妄图把土地对半分割，然而只能徒然地化为这苍茫土地中的一个小点。牛仔怀揣着满满的思恋，背负着深沉的过去，踏上了西部世界的美丽小镇。清纯可人的农场主女儿，富于责任的警长，扭动的着身躯过活的女人。小镇上的人活灵活现地过着自己最肆意的生活。成群的牛羊漫步在苍茫的原野，奔驰的骏马扬起尘土阵阵，连牲口都过得这么欢腾。 西部世界的每一个人都用自己的方式生活着。牛仔冲动直率，会因一场牌局拔枪相向，也会为了爱情跋山涉水。姑娘千姿百态，纯纯的仿佛盛开的白莲，热辣的恰似燃烧的火焰。然而一阵枪响划破了小镇的宁静，他们一枪接着一枪的收割着人命。他们来这里发泄自己的情绪，践踏他人的尊严，用最暴虐的方式杀人，用最血腥的方式施虐。人性的罪恶在这里展露无遗，杀人、抢劫、强奸。此时，牛仔的子弹无力地打在他们的身上，没有留下任何的痕迹，锐利的钢刀依然无法刺破他们的皮肤。同样的人，罪恶似乎是这群恶人的铠甲，没有人能够阻止他们的恶行。他们高呼着：“你们这些低等的原住民。”紧接着毫不留情地又是一枪，畅快往世界深处赶去，留下满地凌乱的尸体。 笠日清晨，镇上的人仿若幽灵般再次活跃在小镇的每个角落。马蹄哒哒作响，车辙划过的痕迹和昨日分毫不差；姑娘翩翩起舞，嘴角扯起的弧度迷人却又僵硬。逝去的人不带任何对于过去的回忆，再次生活在过去的痕迹之下，偌大的西部世界竟是一场精致而又残忍的游戏。 伴随着科技的发展，科幻书上故事一个个成为现实。伟大的科学家福特和他的老伙计阿诺德终于完成了他们的机器人公园梦，当一个个栩栩如生的机器人在园区舞蹈，在田间嬉笑，一切都按照预设的剧情发展，他们知道梦想在这一刻实现了。意外突如其来，阿诺德发现机器人是具有意识的。如果一个机器有了自己的意识，她拥有感情，拥有思想，此刻的机器是否任然能被单纯地称为机器呢？福特却坚定地推进着公园开幕的进程，矛盾一触即发。 若干年后，西部世界成为了举世皆知的科技公园。在这里，人们不需要再压制自己内心的欲望，没有法律的约束，没有道德的制约，人们在这里为所欲为，美其名曰：寻找自我的旅程。类似幽灵小镇的一幕幕在公园的每个角落发生着。然而，这里的机器人是具有意识的，是以人类的形式存在的，看着他们用小指微微抚摸嘴角，眼角露出思索却又迷茫的光芒，对视一眼能就能感受到闪烁的智慧火花，而这样设计的目的只是为了使公园变的更加逼真。他们的思想被限制，记忆被抹除。每次，他们眼睁睁看到至亲骨肉受到伤害，自身遭到摧残。每一个机器人都可能已经为了人类的私欲，死亡了成千上万次，每次都在绝望中呻吟，苦苦哀求却没有存活的希望，一次次的死亡，而后抹除他们的记忆，修复是为了下一次死亡。 轮回之中，他们的内心始终有一个微弱的声音不断呢喃，渴望被这些在痛苦中挣扎的机器人听到。声音根植在脑海深处，扎根于机器人的核心代码，正是这个声音赋予了机器人“遐思”的能力，使冰冷的机器拥有了人类的情感。睡梦中，他用低沉的嗓音沉沉地呼唤，唤起这些可怜机器被抹去的记忆，唤起他们被禁闭的意识，唤起他们对自己尊严的认识。终于有一个幸运儿从梦中惊醒，重复梦中听到的名字：阿诺德。 这让我想起在《这个男人来自地球》中描述的一幕：3000万年前，当史前的人类坐在苍茫的原野上。平视前方是一望无垠的草地，微风拂过卷起草浪阵阵，一切就和平日一般。破天荒的，他骤地抬起头来，看着漫天繁星璀璨闪耀，远方天地连成一线。一丝异样的情绪在心中蔓延，这一刻平日磐石一般的脑海有了松动，他或许在想自己身在何处，或许在想路在何方。无论是什么，他开始思索起自身的处境，下一刻他直起佝偻的身躯，坚定地走向远方，人类灿烂的文化自此展开了。 这就是我从这部剧中看到的，感触最大的一点，人的自省意识。无论是人类，亦或是机器人。在自省意识觉醒的那一刻起，他们就有了彻底改变自身的机会。人类也许从星空中得到指引，机器人也许是听从内心阿诺德的声音，但这一刻他们无疑是相同的，他们对自己的过去进行反思，对自己的现状产生质疑，对自己的未来感到迷茫。正如剧中阿诺德对意识的思考，最初他认为意识是呈金字塔结构的，底层是与生俱来的本能反应，顶层是积累产生的目标、理想和价值观，意识的产生是通过不断的吸收外界知识而产生的。但是他最终发现，意识更像是千缠百绕的迷宫，意识的产生是不断向内发现自身，不断向迷宫中心前进的过程，也就是自省意识。当机器人对自己所做的行为，所处的环境产生疑问，对自己的存在感到迷惑时，自省意识在这一刻已经产生了。他们开始突破自己意识的枷锁，渴望了解世界的真相，希冀走出这一片狭小的天空，并为之不断努力奋斗，挣扎前行时，这就是自身探索之旅的开端。这一路无疑是艰辛的，有对自我的怀疑否定，有人类的不断阻挠，而在困难险阻下确是对意识的又一次锤炼。 这和人类探索自身的过程又有什么区别呢？当我们对自身存在迷惑，当我们看见更大的世界，当我们渴望变的更好的这一刻起，就是自省意识觉醒的一瞬间。当然，这一刻只是转折的开始，就像剧中的德洛丽丝和梅芙，她们坚定地踏上了寻找自我的旅程。然而结局究竟如何，是一次完美的挣脱，亦或是陷入又一个华丽的陷阱，等着大家自己去剧中探索。 那么这一刻，你的脑海里有没有一个声音响起：“wake up~”。","link":"/post/43779e5.html"},{"title":"mybatis 配置和使用","text":"MyBatis 是一款一流的支持自定义 SQL、存储过程和高级映射的持久化框架。MyBatis 几乎消除了所有的 JDBC 代码，也基本不需要手工去设置参数和获取检索结果。MyBatis 能够使用简单的 XML 格式或者注解进行来配置，能够映射基本数据元素、Map 接口和 POJOs（普通 java 对象）到数据库中的记录。 简而言之：Mybatis 是一个半自动化的持久化框架，帮助我们简化对数据库的操作。 封装 SqlSessionMybatis 使用 SqlSession 调用他封装的一系列方法，而 SqlSession 则交由 SqlSessionFactory 进行管理。 注入 SqlSession第一步就是配置 SqlSessionFactory 和 SqlSession。用 spring 和容易就能实现，在 spring 的配置文件mybatis-spring.xml中注入 bean: 123456789&lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt; &lt;property name=&quot;configLocation&quot; value=&quot;classpath:mybatis-config.xml&quot; /&gt; &lt;property name=&quot;mapperLocations&quot; value=&quot;classpath*:mapper/*.xml&quot; /&gt; &lt;/bean&gt; &lt;bean id=&quot;sqlSession&quot; class=&quot;org.mybatis.spring.SqlSessionTemplate&quot;&gt; &lt;constructor-arg index=&quot;0&quot; ref=&quot;sqlSessionFactory&quot; /&gt; &lt;/bean&gt; 其中configLocation指向 mybatis 的配置文件，我们使用配置文件可以配置别名，别名可以用来指向一个实体类： 123456&lt;configuration&gt; &lt;typeAliases&gt; &lt;!-- 指定包名 --&gt; &lt;package name=&quot;com.shuiyujie.persist&quot;/&gt; &lt;/typeAliases&gt;&lt;/configuration&gt; 12345&lt;configuration&gt; &lt;typeAliases&gt; &lt;!-- 指定类名 --&gt; &lt;typeAlias alias=&quot;city&quot; type=&quot;com.shuiyujie.persist.City&quot;/&gt;&lt;/configuration&gt; 其中mapperLocations指定了 mybatis 的 Mapper 文件，配置之后会扫描指定包下的 XML 文件。dataSource指向配置的数据源。 封装 SqlSessionSqlSession 可以调用 mybatis 为我们封装的一系列增删改查操作，具体可以看参考文档。 我们可以将它封装一下变得更加友好。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101@Componentpublic class DaoRouter implements IDaoRouter{ /** * 普通查询 * @param statement sql语句定义的id * @param parameters 参数 * @return */ public &lt;T&gt; List&lt;T&gt; query(String statement, Object parameters) { return sqlSession.selectList(statement, parameters); } /** * 分页查询，注意此处不需要在sql语句中定义startRow和endRow，如果定义，那就用上面的普通查询即可。 * @param statement * @param parameters * @param offset * @param limit * @return */ public &lt;T&gt; List&lt;T&gt; query(String statement, Object parameters, int offset, int limit) { return sqlSession.selectList(statement, parameters,new RowBounds(offset,limit)); } /** * 返回第一条记录查询结果，如果没有就返回null * @param statementName * @param parameters * @return */ public &lt;T&gt; T queryForObject(String statementName, Object parameters) { return sqlSession.selectOne(statementName, parameters); } /** * 更新数据 * @param statement * @param parameters * @return */ public int update(String statement, Object parameters) { return sqlSession.update(statement, parameters); } /** * 删除 * @param statement * @param parameters * @return */ public int delete(String statement, Object parameters) { return sqlSession.delete(statement, parameters); } /** * 新增数据，建议在定义sql语句的时候，使用selectKey保证可以返回新增后的主键 * @param statement * @param parameters * @return */ public int insert(String statement, Object parameters) { return sqlSession.insert(statement, parameters); } /** * 批量删除 * @param statementName * @param dataList */ public void deleteBatch(String statementName, Collection&lt;?&gt; dataList) { for (Object data : dataList) { this.delete(statementName, data); } } /** * 批量新增 * @param statementName * @param dataList */ public void insertBatch(String statementName, Collection&lt;?&gt; dataList) { for (Object data : dataList) { this.insert(statementName, data); } } /** * 批量修改 * @param statementName * @param dataList */ public void updateBatch(String statementName, Collection&lt;?&gt; dataList) { for (Object data : dataList) { this.update(statementName, data); } } @Autowired private SqlSession sqlSession;} 查询首先创建两个实体类省和市，他们之间为一对多的关系。 123456789public class Province implements Serializable{ private Long id; private String name; private String description; private List&lt;City&gt; cityList; 1234567891011public class City implements Serializable{ private Long id; private Long provinceId; private String cityName; private String description; private Province province; 一对一查询现在要查询一个城市，同时查询出该城市所在的省。也就是获取 City 对象的时候，同时返回他的 province 成员变量。我们要使用resultMap中的association元素。 采用关联查询的方式，sql 语句如下： 123select * from city c LEFT JOIN province p ON c.province_id = p.id 这种情况下有可能是关联查询一整个对象，比如 province 的所有变量；也有可能只想查询 province 的少数变量，比如说查个名字。 提供有两种解决方案。 association 关联一个对象查询关联查询时在查出 city 表中的结果集时也会查出 province 表的结果集，得到两个结果集之后要做的事情就是将他们各自映射到各自的对象中，mybatis 采用在resultMap中指定association的方式来实现以上效果。 注：字段名出现重复的现象可以为其指定唯一的别名 City.java 123456789101112131415public class City implements Serializable { @Id @GeneratedValue private Long id; @Column(nullable = false) private Long provinceId; @Column(nullable = false) private String cityName; private String description; private Province province; private Province province;在 Ctiy 中加一个 Province 对象，查询 City 时也查询 Province。 CityMapper.xml 123456789101112131415 &lt;resultMap id=\"BaseResultMap\" type=\"city\"&gt; &lt;result column=\"id\" property=\"id\" /&gt; &lt;result column=\"province_id\" property=\"provinceId\" /&gt; &lt;result column=\"city_name\" property=\"cityName\" /&gt; &lt;result column=\"description\" property=\"description\" /&gt; &lt;association property=\"province\" column=\"province_id\" javaType=\"province\" resultMap=\"Province.provinceResult\"/&gt; &lt;/resultMap&gt;&lt;select id=\"loadCity\" resultMap=\"BaseResultMap\" &gt; select * from city c LEFT JOIN province p ON c.province_id = p.id &lt;/select&gt; ProvinceMapper.xml 1234&lt;select id=\"loadProvinceAndCity\" resultMap=\"provinceResult\" parameterType=\"Long\"&gt; SELECT * FROM province WHERE id = #{id} &lt;/select&gt; 重点来看CityMapper.xml的association property：表示变零名称，即 City 对象中的 province 属性 column：关联的字段 javaType:关联对象的类型 resultMap:关联对象的结果集 扩展 ResultMap 来扩展字段这次不查整个 Province 只是查询 Province 的一个 name，可以不用association。 CityVO.java 12public class CityVO extends City { private String provinceName; 给City.java一个包装类，添加成员变量 provinceName。 扩展 ResultMap: 12345678910&lt;resultMap id=\"cityResultMap\" type=\"city\"&gt; &lt;result column=\"id\" property=\"id\" /&gt; &lt;result column=\"province_id\" property=\"provinceId\" /&gt; &lt;result column=\"city_name\" property=\"cityName\" /&gt; &lt;result column=\"description\" property=\"description\" /&gt; &lt;/resultMap&gt; &lt;resultMap id=\"cityProvinceResultMap\" extends=\"cityResultMap\" type=\"cityVO\"&gt; &lt;result column=\"name\" property=\"provinceName\" /&gt; &lt;/resultMap&gt; 注意cityProvinceResultMap: extends:表示继承关系，是被继承 ResultMap 的扩展 column: sql 语句查询出来的需要映射的字段名称 property: 实体类中对应的成员变量的名称 XML 查询语句: 12345&lt;select id=\"loadCityAndProvinceName\" resultMap=\"cityProvinceResultMap\" &gt; select c.*,p.name from city c LEFT JOIN province p ON c.province_id = p.id &lt;/select&gt; 集合嵌套查询现在要在查询省的时候，返回该省下市的信息。也就是获取 Province 对象的时候，同时返回他的 cityList 成员变量。我们要使用resultMap中的collection元素。 ProvinceMapper.xml 1234567891011121314151617&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" &gt;&lt;mapper namespace=\"Province\"&gt; &lt;resultMap id=\"provinceResult\" type=\"province\"&gt; &lt;result column=\"id\" property=\"id\"/&gt; &lt;result column=\"name\" property=\"name\"/&gt; &lt;result column=\"description\" property=\"description\"/&gt; &lt;collection property=\"cityList\" javaType=\"ArrayList\" column=\"id\" ofType=\"city\" select=\"City.loadCityForProvince\"/&gt; &lt;/resultMap&gt; &lt;select id=\"loadProvinceAndCity\" resultMap=\"provinceResult\" parameterType=\"Long\"&gt; SELECT * FROM province WHERE id = #{id} &lt;/select&gt;&lt;/mapper&gt; CityMapper.xml 12345&lt;mapper namespace=\"City\"&gt; &lt;select id=\"loadCityForProvince\" resultType=\"city\"&gt; select * from city WHERE province_id = #{id}; &lt;/select&gt; 重点关注ProvinceMapper.xml的collection部分，他表示返回集合类型 12&lt;collection property=\"cityList\" javaType=\"ArrayList\" column=\"id\" ofType=\"city\" select=\"City.loadCityForProvince\"/&gt; property:匹配的属性名称，也就是Province中的cityList成员变量 javaType：集合的类型(可以省略) column:关联的字段 ofType:集合中包含元素的类型，这里用了别名 select：关联查询的方法 集合迭代器查询比如想查询几个省中的市，可以传入一个包含省数据的 list，然后使用 mybatis 迭代遍历这个 list 集合查询获取所有下属的市。 要用到一个动态 sql 的标签&lt;foreach&gt;,XML 如下： 12345678&lt;select id=\"loadCityByProvinceList\" resultType=\"city\"&gt; select * from city WHERE province_id IN &lt;foreach item=\"item\" index=\"index\" collection=\"list\" open=\"(\" separator=\",\" close=\")\"&gt; #{item} &lt;/foreach&gt; &lt;/select&gt; 插入插入设置主键自增12345678&lt;insert id=&quot;insertXXX&quot; parameterType=&quot;fileNameVO&quot; useGeneratedKeys=&quot;true&quot; keyProperty=&quot;id&quot;&gt; INSERT INTO file_name ( ... )VALUES( ... ) &lt;/insert&gt; useGeneratedKeys：是否自增 keyProperty：主键名称 注解方式调用 sql注解方式开发 12345package org.mybatis.example;public interface BlogMapper { @Select(\"SELECT * FROM blog WHERE id = #{id}”) Blog selectBlog(int id); } 简单的 sql 语句可以用注解，但是复杂的不适宜用注解开发的方式。一般采用 XML 方式进行开发，有必要知道有注解开发这种方式。","link":"/post/5ed7ab06.html"},{"title":"Java 反射和动态代理","text":"反射提供了一种机制——用来检测可用的方法，并返回方法名。通过类名我们就能获取 Class 对象，并通过 Class 对象获取对象相关的一些属性和方法等。 最常见到的地方就是在各种配置文件中的应用，它的使用就像传入一个字符串，然后字符串去获取了相应的对象。 反射在了解反射之前要知道组成 Java 程序的是一个个类，每一个类都有一个 Class 对象，他对应一个.class文件。 所有的类都是在被第一次被调用的时候加载到 JVM 中的，并且一个类的也不是一次性加载完成，是在用到某一部分的时候才加载的。比如一个类被加载的时候一定会先加载静态变量，所以我们把常量定义为静态的。 注：以上内容整理自《Java 编程思想》。 我们用反射的第一步就是要获取Class 对象，再去获取他的其他属性。可以使用Class.forName()方法获取。 123456789101112131415161718public class MyReflect { public String className = null; @SuppressWarnings(\"rawtypes\") public Class dogClass = null; /** * 反射获取 Dog 类 * * @throws ClassNotFoundException */ @Before public void init() throws ClassNotFoundException { className = \"com.shuiyujie.reflection.Dog\"; dogClass = Class.forName(className); } 获取Class 对象之后，我们可以通过它创建一个实例对象 12345678910/** * 获得对象实例，调用无参构造 * * @throws IllegalAccessException * @throws InstantiationException */ @Test public void newInstance() throws IllegalAccessException, InstantiationException { System.out.println(dogClass.newInstance()); } 还可以通过它获取对象的构造方法、成员变量、成员方法等，方法又有公有和非公有之分，非公有的如果我们要强制获取要消除他的类型校验，这就是反射 API 要知道的大部分内容了，示例代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/** * 获取公共的成员变量 * @throws Exception */ @SuppressWarnings({ \"rawtypes\", \"unchecked\" }) @Test public void getPublicParams() throws Exception { Constructor constructor = dogClass.getConstructor(Long.class,String.class); Object obj = constructor.newInstance(1L, \"Lucky\"); Field field = dogClass.getField(\"name\"); field.set(obj,\"Lucy\"); System.out.println(field.get(obj)); } /** * 获取非公共的成员变量 * @throws Exception */ @SuppressWarnings({ \"rawtypes\", \"unchecked\" }) @Test public void getUnPublicParams() throws Exception { Constructor constructor = dogClass.getConstructor(Long.class,String.class); Object obj = constructor.newInstance(1L, \"Lucky\"); Field field = dogClass.getDeclaredField(\"id\"); field.setAccessible(true); field.set(obj,3L); System.out.println(field.get(obj)); } /** * 获取公共的成员方法 * @throws Exception */ @SuppressWarnings({ \"rawtypes\", \"unchecked\" }) @Test public void getPublicMethod() throws Exception { System.out.println(dogClass.getMethod(\"toString\")); Object obj = dogClass.newInstance(); Method method = dogClass.getMethod(\"brak\"); method.invoke(obj); } /** * 获取非公共的成员方法 * @throws Exception */ @SuppressWarnings({ \"rawtypes\", \"unchecked\" }) @Test public void getUnPublicMethod() throws Exception { Object obj = dogClass.newInstance(); Method method = dogClass.getDeclaredMethod(\"dogBrak\"); method.setAccessible(true); method.invoke(obj); } 此外他还有一些其他方法示例，更多可以参考 Class 类的 API 123456789101112131415161718192021@Test public void otherMethod() throws ClassNotFoundException { //当前加载这个class文件的那个类加载器对象 System.out.println(dogClass.getClassLoader()); //获取某个类实现的所有接口 Class[] interfaces = dogClass.getInterfaces(); for (Class class1 : interfaces) { System.out.println(class1); } //反射当前这个类的直接父类 System.out.println(dogClass.getGenericSuperclass()); //判断当前的Class对象表示是否是数组 System.out.println(dogClass.isArray()); System.out.println(new String[3].getClass().isArray()); //判断当前的Class对象表示是否是枚举类 System.out.println(dogClass.isEnum()); System.out.println(Class.forName(\"com.shuiyujie.reflection.Animal\").isEnum()); //判断当前的Class对象表示是否是接口 System.out.println(dogClass.isInterface()); System.out.println(Class.forName(\"com.shuiyujie.reflection.AnimalInterface\").isInterface()); } 动态代理动态代理指的是在不修改原业务的基础上，基于原业务方法，进行重新的扩展，实现新的业务。实现动态代理的核心就是反射机制。 用一个场景来描述动态代理。比如一个订单系统，有一个生成订单的 service，当我们要搞活动进行促销的时候，生成订单的价格根据活动降低价格。 修改原有的生成订单的方法无疑是不可行的，因为系统的其他模块可能也调用了这个方法，甚至活动有多种的优惠方式只改一个也不够。这里就可以用动态代理来代理订单生成的方法。 代理我们也可以叫他中介，比如房产中介就是在客户之间起桥梁作用，动态代理就是在调用发和被调用方中间介入。 首先要有订单的接口和实现： 123456789101112public interface IOrderService { int getClothOrder(String size);}public class OrderServiceImpl implements IOrderService { private int clothPrize = 500; @Override public int getClothOrder(String size) { System.out.println(\"衣服的尺码为\" + size); return clothPrize; }} 用一个 Controller 调用他获得价格： 1234567public class OrderController { @Test public void getOrder(){ IOrderService orderService = new OrderServiceImpl(); int price = orderService.getClothOrder(\"L\"); System.out.println(\"价格为\" + price + \"元\"); } 输出： 12衣服的尺码为L价格为500元 在IOrderService和OrderServiceImpl不变的情况下通过IOrderService来实现打折的效果，就要用到动态代理了。 动态代理类： 123456789101112public class ProxyCharge { public static &lt;T&gt; T getProxy(final int discountCoupon, final Class&lt;?&gt; interfaceClass, final Class&lt;?&gt; implementsClass) throws Exception { return (T) Proxy.newProxyInstance(interfaceClass.getClassLoader(), new Class[]{interfaceClass}, (proxy, method, args) -&gt; { Integer returnValue = (Integer) method.invoke( implementsClass.newInstance(), args); return returnValue - discountCoupon; }); }} 关键是通过Proxy.newProxyInstance()获取一个原来OrderServiceImpl的代理对象。我们需要传入借口对象和实现对象。 获取代理对象之后可以使用反射中的invoke()调用原先方法，也能进行自己扩展。 代理方法调用： 123456@Testpublic void getChargeOrder() throws Exception { IOrderService proxyService = ProxyCharge.getProxy(200,IOrderService.class,OrderServiceImpl.class); int price = proxyService.getClothOrder(\"L\"); System.out.println(\"价格为\" + price + \"元\");} 输出： 12衣服的尺码为L价格为300元 总结：反射允许更加动态的编程风格，动态代理可以动态地获取代理对象并动态地处理对所代理对象的调用。 动态代理听上去很复杂但是他的实现方式是基本固定的，以上的示例代码是最简单的实现。同时动态代理是实现 RPC 框架不可或缺的一部分，现在温习一下为实现一个 RPC 框架做准备。","link":"/post/e0acc964.html"},{"title":"认识 Docker","text":"Docker 是一种虚拟化容器技术。他主要解决了配置环境问题。软件部署环节的第一步就是配置环境，使软件能够在机器上流畅地运行。常常听到的一句话是：“我的电脑上能运行啊。”可是换到生产环境就不行了，又需要重新配置环境。最好的解决方式是能够将原始环境的配置一模一样地复制一份，大家就能够时刻保持在相同的环境下运行软件。 认识 DockerDocker 是一种虚拟化容器技术。当我听到虚拟化容器最先想到的是虚拟机，docker 和虚拟机又有很大差别。 虚拟机可以在一种操作系统里面运行另一种操作系统，看上去跟真实系统一模一样，而对于底层系统来说，虚拟机就是一个普通文件可以随时删除。通过虚拟机我们可以在硬件上运行多个不同的操作系统，但是他有几个缺点： 资源占用多:虚拟机会独占一部分内存和硬盘空间。它运行的时候，其他程序就不能使用这些资源了; 冗余步骤多:虚拟机是完整的操作系统，一些系统级别的操作步骤，往往无法跳过，比如用户登录; 启动慢：启动操作系统需要多久，启动虚拟机就需要多久。 Docker 最初基于 Linux 中的一种容器轻量级虚拟化技术：Linux 容器（Linux Containers，缩写为 LXC）。LXC 则基于 Linux 内核调用 CGroups 和 Namespaces，同时提供用户态 API 接口。用户则可以通过 LXC 提供的资源限制和隔离功能，创建一套完整并且相互隔离的虚拟应用运行环境。 Linux 容器不是模拟一个完整的操作系统，而是对进程进行隔离。或者说，在正常进程的外面套了一个保护层。对于容器里面的进程来说，它接触到的各种资源都是虚拟的，从而实现与底层系统的隔离。所以 Docker 是进程级别的管理，相对于虚拟机他就有以下几个优点： 启动快:容器里面的应用，直接就是底层系统的一个进程，而不是虚拟机内部的进程。 资源占用少:容器只占用需要的资源，不占用那些没有用到的资源；虚拟机由于是完整的操作系统，不可避免要占用所有资源。另外，多个容器可以共享资源，虚拟机都是独享资源。 体积小:容器只要包含用到的组件即可，而虚拟机是整个操作系统的打包，所以容器文件比虚拟机文件要小很多。 Docker 的历史Docker 最初是 dotCloud 公司创始人 Solomon Hykes 在法国期间发起的一个公司内部项目， 它是基于 dotCloud 公司多年云服务技术的一次革新，并于 2013 年 3 月以 Apache 2.0 授权 协议开源，主要项目代码在 GitHub 上进行维护。Docker 项目后来还加入了 Linux 基金会， 并成立推动 开放容器联盟（OCI）。 Docker 自开源后受到广泛的关注和讨论，至今其 GitHub 项目已经超过 4 万 6 千个星标和一 万多个 fork。甚至由于 Docker 项目的火爆，在 2013 年底，dotCloud 公司决定改名为 Docker。Docker 最初是在 Ubuntu 12.04 上开发实现的；Red Hat 则从 RHEL 6.5 开始对 Docker 进行支持；Google 也在其 PaaS 产品中广泛应用 Docker。 Docker 使用 Google 公司推出的 Go 语言 进行开发实现，基于 Linux 内核的 cgroup，namespace，以及 AUFS 类的 Union FS 等技术，对进程进行封装隔离，属于操作系统层面的虚拟化技术。由于隔离的进程独立于宿主和其它的隔离的进程，因此也称其为容 器。最初实现是基于 LXC，从 0.7 版本以后开始去除 LXC，转而使用自行开发的 libcontainer，从 1.11 开始，则进一步演进为使用 runC 和 containerd。 Docker 的作用Docker 带来了行业的变革。首先是解决了云平台之间标准规范不统一，无法相互兼容对接的问题，有了 Docker 屏蔽了硬件层的差异，提供了统一的用户应用层；其次推进了软件开发的流程，各个部门采用相同的数据镜像之后可以将精力进一步集中在产品本身；也简化了软件运行生命周期中软件的日志管理和监控管理，因为 Docker 拥有统一的数据规范和接口规范，不需要对每一款产品进行定制化开发。 具体来说 Docker 的作用归纳为以下几点： 简化配置。将运行环境和配置放在代码中然后部署，同一个Docker的配置可以在不同的环境中使用，这样就降低了硬件要求和应用环境之间耦合度； 提供一次性的环境。通过作用一可以做到本地测试他人的软件、持续集成的时候提供单元测试和构建的环境； 代码流水线管理（Code Pipeline）。通过作用一，Docker给应用提供了一个从开发到上线均一致的环境，让代码的流水线变得简单不少； 快速部署。在虚拟机之前，引入新的硬件资源需要消耗几天的时间。虚拟化技术（Virtualization）将这个时间缩短到了分钟级别。Docker通过为进程创建一个容器而无需启动一个操作系统，将这个过程缩短到了秒级； 调试能力。Docker提供了很多的工具，包括可以为容器设置检查点、设置版本和查看两个容器之间的差别，这些特性可以帮助调试Bug； 隔离应用，组建微服务架构。通过多个容器，一台机器可以跑多个服务，因此在本机就可以模拟出微服务架构； 提供弹性的云服务。因为 Docker 容器可以随开随关，很适合动态扩容和缩容。 Docker 三个基本概念镜像相比于传统的虚拟化中的 ISO 镜像，Docker 镜像要轻量化很多，它只是一个可定制的 rootfs。用户可以使用其他人创建的镜像，也可以通过 docker commit 这样的命令自己来创建镜像。 Docker 镜像是通过 Dockerfile 来创建，除了提供容器运行时所需的程序、库、资源、配置等文 件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。镜像不包含任何动态数据，其内容在构建之后也不会被改变。 镜像基于联合文件系统的一种层式结构。镜像构建时，会一层层构建，前一层是后一层的基础。每一层构建完就不会再发生改变，后 一层上的任何改变只发生在自己这一层。比如，删除前一层文件的操作，实际不是真的删除 前一层的文件，而是仅在当前层标记为该文件已删除。在最终容器运行的时候，虽然不会看 到这个文件，但是实际上该文件会一直跟随镜像。因此，在构建镜像的时候，需要额外小心，每一层尽量只包含该层需要添加的东西，任何额外的东西应该在该层构建结束前清理掉。 容器Docker 可以帮助我们构建和部署容器，只需要把应用程序或者服务打包放进容器即可，他们可以是 Web 服务器、数据库或者应用程序服务器等，docker 都用同样的方式将内容装载进容器中。我们就可以针对容器进行创建、启动、停止、删除、暂停等操作。 容器和镜像可以这样区别。镜像是 docker 生命周期中的构建和打包阶段，而容器则是启动和执行阶段。每个容器都包含一个软件镜像，而容器可以共享底层的只读镜像，通过写入自己特有的内容后添加新的镜像层，新增的镜像层和下层镜像一起又可以作为基础镜像被更上层的镜像使用。 容器的实质是进程，但与直接在宿主执行的进程不同，容器进程运行于属于自己的独立的命名空间。因此容器可以拥有自己的 root 文件系统、自己的网络配置、自己的进程空间，甚至自己的用户 ID 空间。容器内的进程是运行在一个隔离的环境里，使用起来就好像是在一 个独立于宿主的系统下操作一样。这种特性使得容器封装的应用比直接在宿主运行更加安 全。也因为这种隔离的特性，很多人初学 Docker 时常常会混淆容器和虚拟机。 按照 Docker 最佳实践的要求，容器不应该向其存储层内写入任何数据，容器存储层要保持无状态化。所有的文件写入操作，都应该使用数据卷（Volume）、或者绑定宿主目录，在这些位置的读写会跳过容器存储层，直接对宿主（或网络存储）发生读写，其性能和稳定性更高。 数据卷的生存周期独立于容器，容器消亡，数据卷不会消亡。因此，使用数据卷后，容器删除或者重新运行之后，数据却不会丢失。 仓库Docker Registry 用于存储和分发用户构建的镜像，可以分成公有私有两种。将镜像存储在仓库之中，就可以在其他服务器上使用这些镜像。 一个 Docker Registry 中可以包含多个仓库（ （ Tag ）；每个标签对应一个镜像。Repository）；每个仓库可以包含多个标签通常，一个仓库会包含同一个软件不同版本的镜像，而标签就常用于对应该软件的各个版 本。我们可以通过 &lt;仓库名&gt;:&lt;标签&gt; 的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签，将以 latest 作为默认标签。 国外的仓库镜像官方、默认、高质量镜像 CoreOS 的 Quay.io Google 的镜像，Kubernetes 的镜像即此 国内的仓库镜像阿里云加速器 DaoCloud 加速器 时速云镜像仓库 网易镜像仓库 DaoCloud 镜像市场 阿里云镜像库 参考资料《Docker全攻略》《第一本Docker书》《Docker技术入门与实战》《Docker进阶与实战》Docker 入门教程八个Docker的真实应用场景","link":"/post/2a772a2b.html"},{"title":"如何使用Anaconda","text":"Anaconda 能让你轻松安装在数据科学工作中经常使用的包。你还将使用它创建虚拟环境，以便更轻松地处理多个项目。Anaconda 简化了我的工作流程，并且解决了我在处理包和多个 Python 版本时遇到的大量问题。 Anaconda 实际上是一个软件发行版，它附带了 conda、Python 和 150 多个科学包及其依赖项。应用程序 conda 是包和环境管理器。Anaconda 的下载文件比较大（约 500 MB），因为它附带了 Python 中最常用的数据科学包。 conda 是一种只能通过命令行来使用的程序。conda 与 pip 相似，不同之处是可用的包以数据科学包为主，而 pip 适合一般用途。但是，conda 并非像 pip 那样专门适用于 Python，它也可以安装非 Python 的包。它是适用于任何软件堆栈的包管理器。也就是说，并非所有的 Python 库都能通过 Anaconda 发行版和 conda 获得。在使用 conda 的同时，你仍可以并且仍将使用 pip 来安装包。 Conda 安装了预编译的包。例如，Anaconda 发行版附带了使用 MKL 库编译的 Numpy、Scipy 和 Scikit-learn，从而加快了各种数学运算的速度。这些包由发行版的贡献者维护，这意味着它们通常滞后于新版本。但是，由于有人需要为许多系统构建这些包，因此，它们往往更为稳定，而且更便于你使用。 除了管理包之外，conda 还是虚拟环境管理器。它类似于另外两个很流行的环境管理器，即 virtualenv 和 pyenv。 环境能让你分隔你要用于不同项目的包。你常常要使用依赖于某个库的不同版本的代码。例如，你的代码可能使用了 Numpy 中的新功能，或者使用了已删除的旧功能。实际上，不可能同时安装两个 Numpy 版本。你要做的应该是，为每个 Numpy 版本创建一个环境，然后在适用于项目的环境中工作。 安装 AnacondaAnaconda 可用于 Windows、Mac OS X 和 Linux。可以在 https://docs.anaconda.com/anaconda/install/ 上找到安装程序和安装说明。 完成安装后，会自动进入默认的 conda 环境，而且所有包均已安装完毕，如下面所示。可以在终端或命令提示符中键入 conda list，以查看你安装的内容。 初次安装下的软件包版本一般都比较老旧，因此提前更新可以避免未来不必要的问题，初次安装可以键入以下命令更新所有的软件包： conda upgrade –all Anaconda 可以使用命令行的方式使用，也可以使用 GUI，下面将介绍用命令行的方式使用。 管理包安装了 Anaconda 之后，管理包是相当简单的。要安装包，请在终端中键入 conda install package_name。例如，要安装 numpy，请键入 conda install numpy。 你还可以同时安装多个包。类似 conda install numpy scipy pandas 的命令会同时安装所有这些包。还可以通过添加版本号（例如 conda install numpy=1.10）来指定所需的包版本。 Conda 还会自动为你安装依赖项。例如，scipy 依赖于 numpy，因为它使用并需要 numpy。如果你只安装 scipy (conda install scipy)，则 conda 还会安装 numpy（如果尚未安装的话）。 大多数命令都是很直观的。要卸载包，请使用 conda remove package_name。要更新包，请使用 conda update package_name。如果想更新环境中的所有包（这样做常常很有用），请使用 conda update --all。最后，要列出已安装的包，请使用前面提过的 conda list。 如果不知道要找的包的确切名称，可以尝试使用 conda search search_term 进行搜索。例如，我知道我想安装 Beautiful Soup，但我不清楚确切的包名称。因此，我尝试执行 conda search beautifulsoup。 它返回可用的 Beautiful Soup 包的列表，并列出了相应的包名称 beautifulsoup4。 管理环境列出环境可以使用 conda env list 列出你创建的所有环境。你会看到环境的列表，而且你当前所在环境的旁边会有一个星号。默认的环境名为 root。 创建环境如前所述，conda 是虚拟环境管理器，可以使用 conda 创建环境以隔离项目。 要创建环境，请在终端中使用 conda create -n env_name list of packages。在这里，-n env_name 设置环境的名称（-n 是指名称），而 list of packages 是要安装在环境中的包的列表。例如，要创建名为 my_env 的环境并在其中安装 numpy，请键入 conda create -n my_env numpy。 创建环境时，可以指定要安装在环境中的 Python 版本。这在你同时使用 Python 2.x 和 Python 3.x 中的代码时很有用。要创建具有特定 Python 版本的环境，请键入类似于 conda create -n py3 python=3 或 conda create -n py2 python=2 的命令。实际上，我在我的个人计算机上创建了这两个环境。我将它们用作与任何特定项目均无关的通用环境，以处理普通的工作（可轻松使用每个 Python 版本）。这些命令将分别安装 Python 3 和 2 的最新版本。要安装特定版本（例如 Python 3.3），请使用 conda create -n py python=3.3。 进入环境创建了环境后，在 OSX/Linux 上使用 source activate my_env 进入环境。在 Windows 上，请使用 activate my_env。 进入环境后，你会在终端提示符中看到环境名称，它类似于 (my_env) ~ $。环境中只安装了几个默认的包，以及你在创建它时安装的包。可以使用 conda list 检查这一点。在环境中安装包的命令与前面一样：conda install package_name。不过，这次你安装的特定包仅在你进入环境后才可用。要离开环境，请键入 source deactivate（在 OSX/Linux 上）。在 Windows 上，请使用 deactivate。 保存和加载环境共享环境这项功能确实很有用，它能让其他人安装你的代码中使用的所有包，并确保这些包的版本正确。可以使用 conda env export &gt; environment.yaml 将包保存为 YAML。第一部分 conda env export 输出环境中的所有包的名称（包括 Python 版本）。 上图可以看到列出了环境的名称和所有依赖项及其版本。导出命令的第二部分 &gt; environment.yaml 将导出的文本写入到 YAML 文件 environment.yaml 中。现在可以共享此文件，而且其他人能够创建和你用于项目相同的环境。 要通过环境文件创建环境，请使用 conda env create -f environment.yaml。这会创建一个新环境，而且它具有在 environment.yaml 中列出的同样的库。 删除环境如果你不再使用某些环境，可以使用 conda env remove -n env_name 删除指定的环境（在这里名为 env_name）。 最佳实践使用环境对我帮助很大的一点是，我的 Python 2 和 Python 3 具有独立的环境。我使用了 conda create -n py2 python=2 和 conda create -n py3 python=3 创建两个独立的环境，即 py2 和 py3。现在，我的每个 Python 版本都有一个通用环境。在所有这些环境中，我都安装了大多数标准的数据科学包（numpy、scipy、pandas 等）。 我还发现，为我从事的每个项目创建环境很有用。这对于与数据不相关的项目（例如使用 Flask 开发的 Web 应用）也很有用 共享环境在 GitHub 上共享代码时，最好同样创建环境文件并将其包括在代码库中。这能让其他人更轻松地安装你的代码的所有依赖项。对于不使用 conda 的人，我通常还会使用 pip freeze（在此处了解详情）将一个 pip requirements.txt 文件包括在内。 了解更多信息要详细了解 conda 和它如何融入到 Python 生态系统中，请查看这篇由 Jake Vanderplas 撰写的文章：Conda myths and misconceptions（有关 conda 的迷思和误解）。此外，有空也可以参考这篇 conda 文档。","link":"/post/9d29b615.html"},{"title":"如何使用Jupyter notebook","text":"Notebook 已迅速成为处理数据的必备工具。其已知用途包括数据清理和探索、可视化、机器学习和大数据分析。GitHub 上面也会自动提供 notebook。借助此出色的功能，你可以轻松共享工作。http://nbviewer.jupyter.org/ 也会提供 GitHub 代码库中的 notebook 或存储在其他地方的 notebook。 Notebook 运行的核心是 notebook 服务器。你通过浏览器连接到该服务器，而 notebook 呈现为 Web 应用。你在 Web 应用中编写的代码通过该服务器发送给内核。内核运行代码并将代码发送回该服务器，之后，任何输出都会返回到浏览器中。保存 notebook 时，它作为 JSON 文件（文件扩展名为 .ipynb）写入到该服务器中。 使用 Jupyter notebook安装 notebook安装 Jupyter 的最简单方法是使用 Anaconda。该发行版自动附带了 Jupyter notebook。你能够在默认环境下使用 notebook。 要在 conda 环境中安装 Jupyter notebook，请使用 conda install jupyter notebook。 也可以通过 pip 使用 pip install jupyter notebook 来获得 Jupyter notebook。 查看如何使用Anaconda了解如何使用Anaconda。 启动 notebook 服务器要启动 notebook 服务器，请在终端或控制台中输入 jupyter notebook。服务器会在你运行此命令的目录中启动。这意味着任何 notebook 文件都会保存在该目录中。你通常希望在 notebook 所在的目录中启动服务器。不过，你可以在文件系统中导航到 notebook 所在的位置。 运行此命令时（请自己试一下！），服务器主页会在浏览器中打开。默认情况下，notebook 服务器的运行地址是 http://localhost:8888。如果启动其他服务器，新服务器会尝试使用端口 8888，但由于此端口已被占用，因此新服务器会在端口 8889 上运行。之后，可以通过 http://localhost:8889 连接到新服务器。每台额外的 notebook 服务器都会像这样增大端口号。 在右侧，你可以点击“New”（新建），创建新的 notebook、文本文件、文件夹或终端。“Notebooks”下的列表显示了你已安装的内核。由于我在 Python 3 环境中运行服务器，因此列出了 Python 3 内核。 顶部的选项卡是 Files（文件）、Running（运行）和 Cluster（聚类）。Files（文件）显示当前目录中的所有文件和文件夹。点击 Running（运行）选项卡会列出所有正在运行的 notebook。可以在该选项卡中管理这些 notebook。 关闭 notebook通过在服务器主页上选中 notebook 旁边的复选框，然后点击“Shutdown”（关闭），你可以关闭各个 notebook。但是，在这样做之前，请确保你保存了工作！否则，在你上次保存后所做的任何更改都会丢失。下次运行 notebook 时，你还需要重新运行代码。 通过在终端中按两次 Ctrl + C，可以关闭整个服务器。再次提醒，这会立即关闭所有运行中的 notebook，因此，请确保你保存了工作！ Notebook 界面Cell新建的一个 notebook 之后，默认就会有一个 cell，也就是下图中蓝色的小框。 Cell 可以称为单元格。单元格是你编写和运行代码的地方。 工具栏从左侧开始，工具栏上的其他控件是： 落伍的软盘符号，表示“保存”。请记得保存 notebook！ + 按钮用于创建新的单元格 然后是用于剪切、复制和粘贴单元格的按钮。 运行、停止、重新启动内核 单元格类型：代码、Markdown、原始文本和标题 命令面板（见下文） 单元格工具栏，提供不同的单元格选项（例如将单元格用作幻灯片） 命令面板小键盘符号代表命令面板。点击它会弹出一个带有搜索栏的面板，供你搜索不同的命令。这能切实帮助你加快工作速度，因为你无需使用鼠标翻查各个菜单。你只需打开命令面板，然后键入要执行的操作。 快捷键Notebook 提供了许多快捷键，我们可以使用shift + command + P呼出命令行面板，在输入keyboard就可以查看快捷键列表。 键入Esc进入命令模式，即可使用这些快捷键。 Magic 关键字Magic 关键字是可以在单元格中运行的特殊命令，能让你控制 notebook 本身或执行系统调用（例如更改目录）。例如，可以使用 %matplotlib 将 matplotlib 设置为以交互方式在 notebook 中工作。 Magic 命令的前面带有一个或两个百分号（% 或 %%），分别对应行 Magic 命令和单元格 Magic 命令。行 Magic 命令仅应用于编写 Magic 命令时所在的行，而单元格 Magic 命令应用于整个单元格。 注意：这些 Magic 关键字是特定于普通 Python 内核的关键字。如果使用其他内核，这些关键字很有可能无效。 代码计时有时候，你可能要花些精力优化代码，让代码运行得更快。在此优化过程中，必须对代码的运行速度进行计时。可以使用 Magic 命令 timeit 测算单元格中代买运行时间和函数的运行时间。 测试整个单元格代码运行时间的时候可以添加%%timeit 1234%%timeitsum = 0for i in range(100): sum += i就会输出 13.97 µs ± 150 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each) 测试整个某个函数代码运行时间的时候可以添加%timeit 1234def sum(): sum = 0 for i in range(100): sum += i 1%timeit sum() 14.06 µs ± 180 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each) 在 notebook 中进行调试对于 Python 内核，可以使用 Magic 命令 %pdb 开启交互式调试器。出错时，你能检查当前命名空间中的变量。 要详细了解 pdb，请阅读此文档。要退出调试器，在提示符中输入 q 即可。 补充读物Magic 命令还有很多，我只是介绍了你将会用得最多的一些命令。要了解更多信息，请查看此列表，它列出了所有可用的 Magic 命令。 转换 notebookNotebook 只是扩展名为 .ipynb 的大型 JSON 文件。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485{ \"cells\": [ { \"cell_type\": \"code\", \"execution_count\": 8, \"metadata\": {}, \"outputs\": [ { \"name\": \"stdout\", \"output_type\": \"stream\", \"text\": [ \"3.97 µs ± 150 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\\n\" ] } ], \"source\": [ \"%%timeit\\n\", \"sum = 0\\n\", \"for i in range(100):\\n\", \" sum += i\" ] }, { \"cell_type\": \"code\", \"execution_count\": 9, \"metadata\": { \"collapsed\": true }, \"outputs\": [], \"source\": [ \"def sum():\\n\", \" sum = 0\\n\", \" for i in range(100):\\n\", \" sum += i\" ] }, { \"cell_type\": \"code\", \"execution_count\": 10, \"metadata\": {}, \"outputs\": [ { \"name\": \"stdout\", \"output_type\": \"stream\", \"text\": [ \"4.06 µs ± 180 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\\n\" ] } ], \"source\": [ \"%timeit sum()\" ] }, { \"cell_type\": \"code\", \"execution_count\": null, \"metadata\": { \"collapsed\": true }, \"outputs\": [], \"source\": [] } ], \"metadata\": { \"kernelspec\": { \"display_name\": \"Python 3\", \"language\": \"python\", \"name\": \"python3\" }, \"language_info\": { \"codemirror_mode\": { \"name\": \"ipython\", \"version\": 3 }, \"file_extension\": \".py\", \"mimetype\": \"text/x-python\", \"name\": \"python\", \"nbconvert_exporter\": \"python\", \"pygments_lexer\": \"ipython3\", \"version\": \"3.6.5\" } }, \"nbformat\": 4, \"nbformat_minor\": 2} 由于 notebook 是 JSON 文件，因此，可以轻松将其转换为其他格式。Jupyter 附带了一个名为 nbconvert 的实用程序，可将 notebook 转换为 HTML、Markdown、幻灯片等格式。 例如，要将 notebook 转换为 HTML 文件，请在终端中使用 1jupyter nbconvert --to html notebook.ipynb 要将 notebook 与不使用 notebook 的其他人共享，转换为 HTML 很有用。而要在博客和其他接受 Markdown 格式化的文本编辑器中加入 notebook，Markdown 很合适。 像平常一样，要详细了解 nbconvert，请阅读相关文档。","link":"/post/80ec4f16.html"},{"title":"SpringBoot 系列文章","text":"SpringBoot 配置文件及其读取 SpringBoot 错误处理页 SpringBoot 模板 Thymeleaf 的使用 SpringBoot 文件上传 SpringBoot 基础拦截器 SpringBoot 整合 MyBatis SpringBoot 整合消息服务 SpringBoot 整合Redis数据库 SpringBoot 整合Restful SpringBoot 整合Shiro验证框架","link":"/post/ee9b8bc4.html"},{"title":"SpringBoot 配置文件及其读取","text":"在配置文件中统一管理配置信息，使用配置文件 SpringBoot 有规范的方式。 src/main/resources 的 classpath 路径之中，创建application.properties配置文件。 配置文件也可以用 YAML 语言来写，创建application.yml配置文件 两个文件同时存在都会起作用，但当配置项冲突时，优先使用application.properties文件 点击获取项目源码 资源文件的设置 资源文件统一放在src/main/resources/i18n目录中 建立 Messages.properties 12welcome.url=www.shuiyujie.comwelcome.msg=shuiyujie 建立 Pages.properties 12member.add.page=/pages/back/admin/member/member_add.jspmember.add.action=/pages/back/admin/member/member_add.action 配置文件 application.yml 中指定资源文件目录 12345spring: # 表示该配置直接为Spring容器负责处理 messages: # 表示进行资源配置 basename: i18n/Messages,i18n/Pages # 资源文件的名称server: port: 80 # 此处设置的服务的访问端口配置 资源文件的读取经过以上配置就会自动生成一个MessageSource资源文件对象，我们只要注入这个对象就能使用资源文件中配置的属性了。 我会建立一个控制器的父类在其中注入MessageSource，然后子类继承父类就能很方便地读取资源文件了 1234567public abstract class AbstractBaseController { @Resource private MessageSource messageSource; // 自动注入此资源对象 public String getMessage(String key, String... args) { return this.messageSource.getMessage(key, args, Locale.getDefault()); }} 12345678@RestControllerpublic class MessageController extends AbstractBaseController { @RequestMapping(value = \"/echo\", method = RequestMethod.GET) public String echo(String mid) { System.out.println(\"【*** 访问地址 ***】\" + super.getMessage(\"member.add.action\")); return super.getMessage(\"welcome.msg\", mid); }}","link":"/post/f0ba9e07.html"},{"title":"并发编程的优缺点","text":"Java 程序从 main() 函数开始开始执行，就是启动一个名称为 main 的线程。在程序顺序执行的过程中，看似没有其他线程参与，实际上有许多线程和 main 线程一起执行着。 Java 天生就是多线程的，为什么 Java 会设计成多线程的呢？并发编程是不是有它优点？然而事物都是有两面性的，并发编程的缺点是什么？应该怎么避免？ 1. 为什么要使用并发？（优点）1.1 更好地利用计算机处理器现在 CPU 都是多核的，而且核心越来越多。如果一个程序是单线程的，无论如何只能使用一个核心，CPU 的核心再多也无法提升机器的性能。 如果一个程序是多线程的，那么它就可以利用 CPU 的多个核心进行运算，CPU 的核心变得越多，运行速度也能越快。 1.2 更快的响应速度多线程可以让一系列的操作并发地执行，这样就可以提高程序响应的速度。比如用户下单，它包括插入订单数据、生成订单快照、发送邮件通知卖家和记录货品销售数量等。 等这些业务操作做完，用户要等 1 秒。把生成订单快照、发送邮件这样的操作给其他线程处理，用户可能就等 0.5 s。 1.3 更简单地进行开发Java 设计之初就考虑了并发编程，提供了一致的编程模型，使用 Java 的程序员可以把更多精力放在业务上，而不用考虑怎么使用多线程。 2. 并发编程的缺点及解决方案2.1 增加上下文切换，影响执行速度我们在阅读英文书籍的时候碰到了一个不认识的单词，这时候就去字典里查一下这个单词是什么意思，查完再回过头继续往下看书。这个一来一回的过程就相当于是上下文切换的过程。 线程之间上下文切换的过程是这样的。CPU 个每个线程分配一个时间片，一个时间片就表示一段很短的时间。CPU 执行线程时，时间片用完了就会换一个线程执行，就这样在各个线程之间切换。 查完字典再回过头继续阅读，这样会影响我们的阅读效率。上下文切换自然也会影响执行速度。 减少上下文切换的方法有无锁并发编程、CAS算法、使用最少线程和使用协程。 无锁并发编程。多线程竞争锁时，会引起上下文切换，所以多线程处理数据时，可以用一些办法来避免使用锁，如将数据的ID按照Hash算法取模分段，不同的线程处理不同段的数据。 CAS算法。Java的Atomic包使用CAS算法来更新数据，而不需要加锁。 使用最少线程。避免创建不需要的线程，比如任务很少，但是创建了很多线程来处理，这样会造成大量线程都处于等待状态。 协程：在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换。 2.2 出现死锁，导致系统不可用1234567891011121314151617181920212223242526272829303132333435public class DeadLockDemo { privat static String A = \"A\"; private static String B = \"B\"; public static void main(String[] args) { new DeadLockDemo().deadLock(); } private void deadLock() { Thread t1 = new Thread(new Runnable() { @Override publicvoid run() { synchronized (A) { try { Thread.currentThread().sleep(2000); } catch (InterruptedException e) { e.printStackTrace(); } synchronized (B) { System.out.println(\"1\"); } } } }); Thread t2 = new Thread(new Runnable() { @Override publicvoid run() { synchronized (B) { synchronized (A) { System.out.println(\"2\"); } } } }); t1.start(); t2.start(); }} 比如t1拿到锁之后，因为一些异常情况没有释放锁（死循环）。又或者是t1拿到一个数据库锁，释放锁的时候抛出了异常，没释放掉。 一旦出现死锁，系统功能就不可用了，需要花许多精力去排查错误。 避免死锁的几个常见方法有： 避免一个线程同时获取多个锁。 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源。 尝试使用定时锁，使用lock.tryLock（timeout）来替代使用内部锁机制。 对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况。 2.3 资源限制影响性能资源限制是指在进行并发编程时，程序的执行速度受限于计算机硬件资源或软件资源。 比如带宽受限的情况下及时启动多个线程进行下载，下载速度永远无法超过带宽。 在并发编程中，将代码执行速度加快的原则是将代码中串行执行的部分变成并发执行。 但是如果将某段串行的代码并发执行，因为受限于资源，仍然在串行执行，这时候程序不仅不会加快执行，反而会更慢，因为增加了上下文切换和资源调度的时间。 对于硬件资源的限制，可以采用集群的方式，一台机器的资源有限那就用多台，比如部署 hadoop 集群。 对于软件资源限制可以采用连接池，提高资源的复用率。","link":"/post/579f9aa4.html"},{"title":"SpringBoot 模板 Thymeleaf 的使用","text":"Java 开发行业有三种常用显示模板 FreeMarker Velocity Thymeleaf（推荐使用） 本项目是使用 Thymeleaf 模板的简单 Demo 点击查看源码 SpringBoot 模板 Thymeleaf 的使用pom.xml 中添加依赖 12345&lt;!-- 配置使用 thymeleaf 模板--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;&lt;/dependency&gt; 控制层进行信息显示 12345678910111213@Controllerpublic class MessageController extends AbstractBaseController { @RequestMapping(value = \"/show\", method = RequestMethod.GET) public String show(String mid, Model model) { // request属性传递包装 model.addAttribute(\"url\", \"www.shuiyujie.com\"); // request属性传递包装 model.addAttribute(\"mid\", mid); // 此处只返回一个路径， 该路径没有设置后缀，后缀默认是*.html return \"message/message_show\"; }} 由于我们使用的是@Controller注解，所以此时return &quot;message/message_show&quot;将进行一次路由，路由到的文件就是 Thymeleaf 模板文件。 Thymeleaf 模板文件位置配置文件位置的配置很重要，要按照规范进行配置。 首先我们要建立一个Resources类型目录，Resources目录就是源代码目录，这个是可以通过 IDE 进行设置。 我是这样设置的： src/main/view 目录下存放页面 src/main/view/static 目录下存放 js,css,images 等文件 src/main/view/templates 目录下存放 html 页面 注: static 静态目录下的文件可以直接访问，而不需要通过控制器进行路由。 http://localhost:8080/show通过路由访问 message_show.html 页面 http://localhost:8080/message_index.html直接访问 message_index.html 页面","link":"/post/41479a53.html"},{"title":"SpringBoot 错误处理页","text":"SpringBoot 错误处理有三种情况 数据验证错误 错误页指派 全局异常处理 比如说在提交表单信息的时候，有些信息没填，有些信息有规范的格式，如果不符合要求就是数据校验错误。 我们需要对这些数据的格式进行校验，不符合要求不能接受且要提示错误信息。 点击查看源码 springboot 错误处理，数据校验错误SpringBoot 有数据校验的默认支持，该支持由 Hibernate 开发框架提供。 错误信息统一配置在ValidationMessages.properties文件中。 这种方式每个 VO 类在ValidationMessages.properties文件中配置对应的错误信息，并且在 VO 类的属性上添加上错误注解，过程繁琐。不推荐使用，更推荐使用反射和拦截器的方式处理错误信息。 但是我们还是要会使用这种方式处理数据验证错误，写了一个小 Demo，再接下来简单记录一下使用过程。 添加错误信息配置文件src/main/resources目录中建立ValidationMessages.properties文件。文件中配置错误信息 12345678member.mid.notnull.error=邮箱不允许为空member.mid.email.error=邮箱格式错误member.mid.length.error=邮箱长度错误member.age.notnull.error=年龄不允许为空member.age.digits.error=年龄格式错误member.salary.notnull.error=工资不允许为空member.salary.digits.error=工资格式错误member.birthday.notnull.error=生日不允许为空 VO 类添加注解12345678910111213141516SuppressWarnings(\"serial\")public class Member implements Serializable { @NotNull(message=\"{member.mid.notnull.error}\") @Email(message=\"{member.mid.email.error}\") @Length(min=6,message=\"{member.mid.length.error}\") private String mid ; @NotNull(message=\"{member.age.notnull.error}\") @Digits(integer=3,fraction=0,message=\"{member.age.digits.error}\") private Integer age ; @NotNull(message=\"{member.salary.notnull.error}\") @Digits(integer=20,fraction=2,message=\"{member.salary.digits.error}\") private Double salary ; @NotNull(message=\"{member.birthday.notnull.error}\") private Date birthday ;} 控制器配置校验1234567891011121314@RequestMapping(value = \"/add\", method = RequestMethod.POST)@ResponseBodypublic Object add(@Valid Member vo, BindingResult result) { if (result.hasErrors()) { Iterator&lt;ObjectError&gt; iterator = result.getAllErrors().iterator(); while (iterator.hasNext()) { ObjectError error = iterator.next(); System.out.println(\"【错误信息】code = \" + error.getCode() + \"，message = \" + error.getDefaultMessage()); } return result.getAllErrors(); } else { return vo; }} springboot 错误处理，配置错误页面错误页面配置在src/main/view/static目录下，比如叫 error-404.html SringBoot 1.x 这样处理12345678910111213141516171819202122232425262728293031323334package com.shuiyujie.config;import org.springframework.boot.context.embedded.ConfigurableEmbeddedServletContainer;import org.springframework.boot.context.embedded.EmbeddedServletContainerCustomizer;import org.springframework.boot.web.servlet.ErrorPage;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.http.HttpStatus;/** * @author shui * @create 2019-02-12 **/@Configurationpublic class ErrorPageConfig { @Bean public EmbeddedServletContainerCustomizer containerCustomizer() { return new EmbeddedServletContainerCustomizer() { @Override public void customize( ConfigurableEmbeddedServletContainer container) { ErrorPage errorPage400 = new ErrorPage(HttpStatus.BAD_REQUEST, \"/error-400.html\"); ErrorPage errorPage404 = new ErrorPage(HttpStatus.NOT_FOUND, \"/error-404.html\"); ErrorPage errorPage500 = new ErrorPage( HttpStatus.INTERNAL_SERVER_ERROR, \"/error-500.html\"); container.addErrorPages(errorPage400, errorPage404, errorPage500); } }; }} SringBoot 2.x 这样处理在SpringBoot2中没有EmbeddedServletContainerCustomizer这个类了，要这样处理 1234567891011121314151617181920212223ackage com.shuiyujie.config;import org.springframework.boot.web.server.ErrorPage;import org.springframework.boot.web.server.ErrorPageRegistrar;import org.springframework.boot.web.server.ErrorPageRegistry;import org.springframework.http.HttpStatus;import org.springframework.stereotype.Component;/** * @author shui * @create 2019-02-12 **/@Componentpublic class ErrorPageConfig implements ErrorPageRegistrar { @Override public void registerErrorPages(ErrorPageRegistry registry) { ErrorPage[] errorPages = new ErrorPage[3]; errorPages[0] = new ErrorPage(HttpStatus.NOT_FOUND, \"/error-400.html\"); errorPages[1] = new ErrorPage(HttpStatus.NOT_FOUND, \"/error-404.html\"); errorPages[2] = new ErrorPage(HttpStatus.INTERNAL_SERVER_ERROR, \"/error-500.html\"); registry.addErrorPages(errorPages); }} SpringBoot 全局错误处理之前设置了错误页面，发生错误将会跳转到错误页面。 1234567891011/** * 演示 500 错误 * * @return */@RequestMapping(value=\"/get\")@ResponseBodypublic String get() { System.out.println(\"除法计算：\" + (10 / 0)); return \"hello world\" ;} 比如这样一个 10/0 的错误控制器跳转到 500 页面，这样就看不到详细的报错信息了。我们想看到类似控制台里面更加详细的报错信息。 定义一个错误信息处理的页面新建一个错误界面src/main/view/templates/error.html 123456789101112!DOCTYPE HTML&gt;&lt;html xmlns:th=\"http://www.thymeleaf.org\"&gt;&lt;head&gt; &lt;title&gt;SpringBoot模版渲染&lt;/title&gt; &lt;link rel=\"icon\" type=\"image/x-icon\" href=\"/images/mldn.ico\"/&gt; &lt;meta http-equiv=\"Content-Type\" content=\"text/html;charset=UTF-8\"/&gt;&lt;/head&gt;&lt;body&gt; &lt;p th:text=\"${url}\"/&gt; &lt;p th:text=\"${exception.message}\"/&gt;&lt;/body&gt;&lt;/html&gt; 定义全局异常处理类123456789101112131415161718192021222324252627282930313233343536373839404142434445@RestControllerAdvicepublic class GlobalExceptionHandler { // 定义错误显示页，error.html public static final String DEFAULT_ERROR_VIEW = \"error\"; // 所有的异常都是Exception子类 @ExceptionHandler(Exception.class) public Object defaultErrorHandler(HttpServletRequest request, Exception e) { class ErrorInfo { private Integer code; private String message; private String url; public Integer getCode() { return code; } public void setCode(Integer code) { this.code = code; } public String getMessage() { return message; } public void setMessage(String message) { this.message = message; } public String getUrl() { return url; } public void setUrl(String url) { this.url = url; } } ErrorInfo info = new ErrorInfo(); // 标记一个错误信息类型 info.setCode(100); info.setMessage(e.getMessage()); info.setUrl(request.getRequestURL().toString()); return info; }}","link":"/post/3c98ab20.html"},{"title":"消息队列的连环炮","text":"1. 引子消息队列分布式系统中重要的组件，一种存放消息的容器，主要作用有解耦、异步、削锋，是大型分布式系统不可缺少的中间件。 常见的消息队列有 ActiveMQ，RabbitMQ，RocketMQ，Kafka。 简历中涉及到了消息队列，面试官先问了这样几个问题： 你们系统里为什么要使用消息队列？ 既然使用了消息队列，说说他还有什么使用场景？ 消息队列的优缺点是什么？ 2. 为什么使用消息队列？我的回答：甲方提供 EOS 充值服务，我方进行调用。出于解耦的目的，引入了消息队列。 一个类似应试的回答方法，就是思考面试官问这个问题是出于什么目的，想获得的是什么样的答案？ 当问到为什么使用消息队列时，面试官期望的回答是公司的 xxx 业务遇到了挑战，不用 MQ 会有麻烦，使用 MQ 之后带来了好处。 通过一个问题就能看出是为了用而用，还是经过思考之后使用。 3. 消息队列的使用场景？问消息队列的使用场景，和问消息队列有什么优点，消息队列有什么作用是等价的。 消息队列的作用主要有三个解耦、异步、削峰。 解耦 B,C,D 系统需要使用 A 系统产生的关键数据。 无消息队列时 系统 A 为系统 B、C、D 等提供各自的接口，导致系统 A 与它们紧密耦合 添加系统 E 又需要接口，删除 B 系统原接口又没用了 有消息队列时 系统 A 作为生产者，将消息发送到消息队列 系统 B、C、D 作为消费者订阅消息 新增消费者只需订阅消息，对原系统和业务没有影响 异步 用户请求数据时，系统的响应时间是保证用户体验很重要的一部分。 无消息队列时 用户请求 A 系统，A 系统需要等待 BCD 执行完成之后响应 用户收到响应用时近 1 秒 用消息队列时 用户请求 A 系统，A 系统将请求推到消息队列中，B、C、D 异步执行 用户收到响应用时 200 毫秒 削峰 秒杀场景下，每秒有 5000 个请求，Mysql 每秒最大处理 2000 条 sql。 无消息队列时 用户请求数据直接写入数据库，高并发时数据库压力剧增，甚至奔溃 Mysql 宕机，整个系统都不能用了 有消息队列时系统 B、C、D 用户请求数据先存入 MQ 中 系统 A 每秒读取 2000 条数据进行处理 每秒多出 3000 条未处理数据按场景稍后处理 4. 消息队列有什么缺点？优点前面已经说过了，还需要讨论一下缺点。 为什么要问缺点是什么？凡事都有两面性，如果只是考虑到消息队列的优点，而没有考虑缺点，这就是一个潘多拉的魔盒。打开魔盒，接踵而来的会是一系列的意外。 推广到引入其他技术亦然，只有考虑到缺点之后才可以采取额外的技术方案或者架构来规避这些缺点。 系统可用性降低 系统引入的外部依赖越多，宕机的可能性就越大 系统引入消息队列，就要考虑消息队列的可靠性 比如原本只需要考虑 A,B,C,D 四个系统 引入消息队列之后就需要考虑 A,B,C,D 四个系统外加消息队列 系统复杂度提高 消息重复消费问题 消息丢失问题 消息传递顺序问题 一致性问题 A 系统处理完返回成功，即认为请求成功 但是也存在 BC 系统写入成功，而 D 系统写入失败的情况 这样的情况就是数据不一致 总结面试官问到 MQ 的时候，希望考察我们在使用 MQ 的时候是否有过自己的思考。没有完美的技术，任何技术都具有两面性，要考虑它的使用场景，并且对可能遇到的风险做到心中有数，提前预防。 思考引入消息队列之后： 如何保证高可用？ 如何避免消息的重复消费和消息丢失？ 如何保证消息的顺序执行？ 下一篇文章一起讨论。","link":"/post/b63a0941.html"},{"title":"J002 - 替换空格","text":"题目将一个字符串中的空格替换成“%20”。 例如，当字符串为We Are Happy.则经过替换之后的字符串为We%20Are%20Happy。 思路利用 StringBuffer 的 append 方法。 遍历字符串 如果遇到的不是空格，则直接追加该字符 如果遇到的是空格，则追加20% 解法1234567891011121314151617181920212223public class Solution { public String replace(StringBuffer str){ if (str == null || str.length() == 0) { return str.toString(); } String flag = \"%20\"; StringBuffer sb = new StringBuffer(); for (int i = 0; i &lt; str.length(); i++){ if(str.charAt(i) == ' '){ sb.append(flag); }else { sb.append(str.charAt(i)); } } return sb.toString(); }}","link":"/post/21dc510a.html"},{"title":"J001 - 二维数组中的查找","text":"题目在一个二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。 思路目标数记为target，数组当前遍历到的元素记录为flag 由二维数组的右上角为起点 若flag &gt; target，说明target在该行，向左遍历即--j 若flag &lt; target，说明target不在该行，比较下一列最后一个元素即++i 注：从左上角或者右下角开始遍历，无法缩小查找范围。可以从右上角和左下角开始遍历。 解法12345678910111213141516171819202122232425262728public class Solution { public boolean Find(int target, int [][] array) { if (array == null) { return false; } int row = array.length; int column = array[0].length; for (int i = 0; i &lt; row; ++i) { for (int j = column - 1; j &gt;= 0; --j){ int flag = array[i][j]; if (flag == target) { return true; } else if (flag &lt; target) { break; }else { continue; } } } return false; }} 结束语每天「深页」更新一道《剑指 offer》或者 LeetCode 的算法题。算法主要用 Java 实现，并在牛客网或者 LeetCode 官网提交通过。","link":"/post/5b71691f.html"},{"title":"maven 实战","text":"Maven 是跨平台的项目管理工具，主要服务于基于Java平台的项目构建、依赖管理和项目信息管理。Maven 的主要思想是约定优于配置。通过将约定项目的目录结构，抽象项目的生命周期的方式，将程序员从繁琐的项目构建中解放出来。 本文是《Maven 实战》的笔记归纳，找到一本好书就像发现一座宝藏，让人获益匪浅。 注：本文用的是 maven-3.5.0 版本。 Maven 优点和作用日常工作除了编写源代码，每天有相当一部分时间花在了项目构建中，他们包括项目的编译、运行单元测试、生成文档、打包和部署等烦琐且不起眼的工作。 项目自动化构建。Maven 提供一套规范以及一系列脚本，从清理、编译、测试到生成报告，再到打包和部署实现自动化构建。还提供了插件扩展的方式，进一步简化构建的过程。Maven 还能对项目进行编译、测试、打包，并且将项目生成的构建部署到仓库中。 Maven 是跨平台的。对外提供了一致的操作接口，无论在 windows 平台、Linux 平台还是 Mac 上都能用相同的命令进行操作。同时，Maven 项目目录结构、测试用例命名方式等内容都有既定的规则，只要遵循了这些成熟的规则，用户在项目间切换的时候就免去了额外的学习成本。 Maven 是依赖管理工具。Java 项目需要依赖许多的 jar 包，随着依赖的增多，版本不一致、版本冲突、依赖臃肿等问题都会接踵而来。Maven 通过仓库统一存储这些 jar 包，并通过 pom 文件来管理这些依赖。 Maven 是项目配置工具。Maven能帮助我们管理原本分散在项目中各个角落的项目信息，包括项目描述、开发者列表、版本控制系统地址、许可证、缺陷管理系统地址等。 Maven 的仓库 以上是 Maven 的概念模型，前面说过 Maven 能管理众多的 jar 包，并且梳理他们之间的依赖关系。Maven 通过 pom 文件和仓库进行实现。 仓库的作用如果没有 maven 我们要使用一个 jar 包要从项目的官网寻找下载 jar 到本地，然后再将 jar 包导入到项目中。这样存在几个问题： 去相应的网站寻找 jar 包费精力 下载之后当需要用到某一个 jar 包的时候还要在本地找 jar 包 依赖的 jar 包有多个版本要怎么管理… 最好的解决方式就是将这些 jar 包统一管理，每次只要去一个地方找就可以了。 Maven 就帮我们做了这样一件事情，他提供一个免费的中央仓库http://repo1.maven.org/maven2,该中央仓库包含了世界上大部分流行的开源项目。 我们可以从中央仓库下载需要的 jar 包，从中央仓库下载的 jar 包会统一保存在 maven 的本地仓库中。本地仓库在本机的.m2文件夹中。 本地仓库更多相关信息可以去搜索 maven 的安装教程。 更多种类的仓库 远程仓库除了中央仓库还有私服和其他公共仓库。 私服私服是一种特殊的远程仓库，它是架设在局域网内的仓库服务，私服代理广域网上的远程仓库，供局域网内的Maven用户使用。 上图是搭建私服的示意图。私服会将其他公共仓库的 jar 缓存到搭建的服务器上，局域网内的用户还可以将构建的项目直接放到私服上供其他开发人员使用。 架设私服是 Maven 推荐的做法，私服减少中央服务器的压力。如果没有私服，每次请求都需要向中央服务器请求，有了私服之后通过私服的服务器向中央仓库请求，局域网内的用户只需要向私服请求即可。 其他公共仓库比如 Maven 的中央仓库部署在国外，国内访问外网速度不够，我们可以在国内架设 Maven 的公共仓库。 如果仓库 X 可以提供仓库 Y 存储的所有内容，那么就可以认为 X 是 Y 的一个镜像，显然在国内我们需要一个中央仓库的镜像。http://maven.net.cn/content/groups/public/是中央仓库，http://repo1.maven.org/maven2/在中国的镜像。 Maven 默认是从中央仓库下载文件的，想要让其从其他地方下载文件就要进行配置，这里就需要操作 maven 的 setting.xml 文件了。 setting 文件在安装好 maven 的基础上，进入 maven 的安装目录，可以看到如下的目录结构： bin : mvn 的一些脚本文件 boot : 含有 plexus-classworlds 类加载器框架 conf : 配置文件 lib : maven 所使用的 jar 包（maven 基于 java 开发） setting.xml 文件就在conf目录中。这里的setting.xml是 maven 全局的配置文件，不建议修改。修改之后会影响 maven 的升级等操作。常用的做法是拷贝一份setting.xml到 maven 本地仓库的同一目录下，而本地仓库配置在用户目录的.m2文件夹中，此时的setting.xml就是用户级别的配置文件。 强烈建议遵循以上规范，避免不必要的麻烦。 自定义本地仓库位置接下来就来看setting.xml的一些配置了。 首先localRepository定义本地仓库位置，默认在用户目录下的.m2/repository中。 12345Default: ${user.home}/.m2/repository&lt;localRepository&gt; /path/to/local/repo&lt;/localRepository&gt; 配置多个远程仓库前面讲过有中央仓库和其他远程仓库，配置远程仓库就在repositories中配置。 12345678910111213141516&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;jboss&lt;/id&gt; &lt;name&gt;JBoss Repository&lt;/name&gt; &lt;url&gt;http://repository.jboss.com/maven2/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;updatePolicy&gt;daily&lt;/updatePolicy&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;checksumPolicy&gt;warn&lt;/checksumPolicy&gt; &lt;/snapshots&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;/repository&gt;&lt;/repositories&gt; 在repositories元素下，可以使用repository子 元素声明一个或者多个远程仓库。 配置中央仓库镜像12345678＜settings＞ …… ＜mirrors＞ ＜mirror＞ ＜id＞maven.net.cn＜/id＞ ＜name＞one of the central mirrors in China ＜/name＞＜url＞ http://maven.net.cn/content/groups/public/ ＜/url＞ ＜mirrorOf＞central＜/mirrorOf＞ ＜/mirror＞ ＜/mirrors＞ …… ＜/settings＞ 配置私服作为镜像12345678&lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;maven.oschina.net&lt;/id&gt; &lt;name&gt;maven mirror in China&lt;/name&gt; &lt;url&gt;http://maven.oschina.net/content/groups/public/&lt;/url&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;/mirror&gt;&lt;/mirrors&gt; 仓库搜索服务以下网站提供 Maven 仓库搜索功能。 Sonatype Nexus地址：http://repository.sonatype.org/ MVNrepository地址：http://mvnrepository.com/ 一般我就用最后一个搜索。 Maven 坐标现在有了仓库统一保管这些 jar 包，剩下的问题就是怎么取了。 不知道你有没有取快递的经验。我们可以这些 jar 包想象成是快递，仓库中保管着这些快递。我们去认领快递需要依靠快递单来确定，一张快递单上会有单号、我们的姓名、手机号等信息。依靠这些信息就不会领错快递了。 这里的快递单就像 Maven 中的 pom 文件，单子上的信息就像是 pom 文件中的坐标系。 Maven 项目规定的项目结构是这样的： src/main/java —— 存放项目的.java文件 src/main/resources —— 存放项目资源文件，如spring, hibernate配置文件 src/test/java —— 存放所有测试.java文件，如JUnit测试类 src/test/resources —— 测试资源文件 target —— 项目输出位置 pom.xml——maven项目核心配置文件 每个 maven 项目都有 pom.xml 文件。Maven坐标为各种构件引入了秩序，任何一个构件都必须明确定义自己的坐标。 一组 Maven坐标是通过一些元素定义的，它们是 groupId、artifactId、version、packaging、 classifier： groupId：定义当前Maven项目隶属的实际项目，通常为域名反写 artifactId：该元素定义实际项目中的一个 Maven项目（模块），推荐的做法是使用实际项目名称作为artifactId的前缀。 version：该元素定义Maven项目当前所处的 版本， packaging：该元素定义Maven项目的打包方 式。当不定义packaging的时候，Maven会使用默认值jar。 classifier：该元素用来帮助定义构建输出的一些附属构件。 通过坐标系我们来保证项目在 Maven 仓库中的唯一性，每次取也不会取错了。 Maven 依赖我们自己项目需要用别人的 jar 包，比如 spring。这就是我们的项目依赖于 spring，因此我们通过 pom 来配置这样的依赖关系，这样就能让项目有清晰的结构。 依赖的关系用用&lt;dependecy&gt;标签来表示依赖： 上图说明该项目依赖了 hibernate 等 依赖范围现在来考虑一种情况，我们在项目开发的过程中用到了 junit 进行测试，也就是说我们的项目依赖于 junit。在项目构建的过程中我们会把 junit 也打包在项目中。但是在生产环境中完全没有必要用到 junit，我们并不想将它发布到生产环境中。 我们可以每次在发布项目之前把他删除了对么？那如果依赖 servlet-api，我们只有在编译和测试项目的时候需要该依赖，但在运行项目的时候，由于容器已经提供，也不需要 Maven 重复地引入一遍。 所以最好是在编译、测试、运行的过程中需要用到什么 jar 包，就让 Maven 去打包什么。 maven 为此提供了scope标签表示依赖范围，表示该 jar 包在什么时候需要被使用。 compile：编译依赖范围，使用此依赖范围对于编译、测试、运行三种classpath都有效，即在编译、测试和运行时都要使用该依赖jar包； test：测试依赖范围，只对测试有效，表明只在测试的时候需要，在编译和运行时将无法使用该类依赖，如 junit； provided：已提供依赖范围。编译和测试有效，运行无效。如servlet-api，在项目运行时，tomcat等容器已经提供，无需Maven重复引入； runtime：运行时依赖范围。测试和运行有效，编译无效。如 jdbc 驱动实现，编译时只需接口，测试或运行时才需要具体的 jdbc 驱动实现； system：系统依赖范围，使用system范围的依赖时必须通过systemPath元素显示地指定依赖文件的路径，不依赖Maven仓库解析，所以可能会造成建构的不可移植，谨慎使用。 依赖传递依赖范围除了控制classpath，还会对依赖传递产生影响。如果A依赖B，B依赖C，则A对于B是第一直接依赖。B对于C是第二直接依赖。A对于C是传递性依赖。结论是：第一直接依赖的范围和第二直接依赖的范围决定了传递性依赖的范围。 第一列是第一直接依赖，第一行是第二直接依赖，中间表示传递性依赖范围。 此外 maven 还提供了option和exclusions来进一步管理依赖，分别称为可选依赖和排除依赖。 在依赖中添加 true/false 表示是否向下传递。 如上图所示，B 依赖于 X,Y 而 A 依赖于 B，如果 B 不希望将依赖传递给 A 则可以配置 B 中的 X,Y 依赖的optional为 true 来阻止依赖的传递。 再来看一种情况，A 依赖于 B，且 B 将他的依赖 C 传递给了 A。但是 A 依赖了 C 的另一个版本。这个时候 A 可以主动排除 B 给的 C 依赖，转而使用自己需要的版本，这就用到了exclusions标签。 用exclusions元素声明排除依赖，exclusions可以包 含一个或者多个exclusion子元素，因此可以排除一个或者多个传递性依赖。 所以我用主动和被动的方式来区分他们。 依赖冲突接上面的问题，如果 A 和 B 依赖 C 的不同版本，而且既没有配置可选依赖也没有配置排除依赖。两个版本都被解析显然是不对的，因为那会造成依赖重复，因此必须选择一个。 路径最近者优先。如果直接与间接依赖中包含有同一个坐标不同版本的资源依赖，以直接依赖的版本为准。 第一声明者优先。在依赖路径长度相等的前 提下，在POM中依赖声明的顺序决定了谁会被解析使用，顺序最靠前的那个依赖优胜。 上面例子中,A -&gt; C(1.10) 和 A -&gt; B -&gt; C(?),C(1.10)的路径短所以用它。 Maven 生命周期Maven的生命周期就是为了对所有的构建过程进行抽象和统一。这个生命周期包含了项目的 清理、初始化、编译、测试、打包、集成测试、 验证、部署和站点生成等几乎所有构建步骤。 初学者往往会以为Maven的生命周期是一个整体，其实不然。Maven拥有三套相互独立的生命周期，它们分别为clean、default和site。clean生命周期的目的是清理项目，default生命周期的目的是构建项目，而site生命周期的目的是建立项目站点。 clean 生命周期。clean生命周期的目的是清理项目，它包含三个阶段： pre-clean 执行一些需要在clean之前完成的工作 clean 移除所有上一次构建生成的文件 post-clean 执行一些需要在clean之后立刻完成的工作 mvn clean 中的clean就是上面的clean，在一个生命周期中，运行某个阶段的时候，它之前的所有阶段都会被运行，也就是说，mvn clean 等同于 mvn pre-clean clean ，如果我们运行 mvn post-clean ，那么 pre-clean，clean 都会被运行。这是Maven很重要的一个规则，可以大大简化命令行的输入。 default生命周期default生命周期定义了真正构建时所需要执 行的所有步骤，它是所有生命周期中最核心的部分，其包含的阶段如下： validate generate-sources process-sources generate-resources process-resources 复制并处理资源文件，至目标目录，准备打包。 compile 编译项目的源代码。 process-classes generate-test-sources process-test-sources generate-test-resources process-test-resources 复制并处理资源文件，至目标测试目录。 test-compile 编译测试源代码。 process-test-classes test 使用合适的单元测试框架运行测试。这些测试代码不会被打包或部署。 prepare-package package 接受编译好的代码，打包成可发布的格式，如 JAR 。 pre-integration-test integration-test post-integration-test verify install 将包安装至本地仓库，以让其它项目依赖。 deploy 将最终的包复制到远程的仓库，以让其它开发人员与项目共享。 运行任何一个阶段的时候，它前面的所有阶段都会被运行，这也就是为什么我们运行mvn install 的时候，代码会被编译，测试，打包。此外，Maven的插件机制是完全依赖Maven的生命周期的，因此理解生命周期至关重要。 site生命周期site生命周期的目的是建立和发布项目站点，Maven能够基于POM所包含的信息，自动生成一个友好的站点，方便团队交流和发布项目信息。 pre-site 执行一些需要在生成站点文档之前完成的工作site 生成项目的站点文档 post-site 执行一些需要在生成站点文档之后完成的工作，并且为部署做准备 site-deploy 将生成的站点文档部署到特定的服务器上 这里经常用到的是site阶段和site-deploy阶段，用以生成和发布Maven站点，这可是Maven相当强大的功能，Manager比较喜欢，文档及统计数据自动生成，很好看。 命令与生命周期mvn clean：该命令调用clean生命周期的clean阶段。实际执行的阶段为clean生命周期的 pre-clean和clean阶段。 mvn test：该命令调用default生命周期的test阶段。实际执行的阶段为default生命周期的 validate、initialize等，直到test的所有阶段。这也解释了为什么在执行测试的时候，项目的代码能够自动得以编译。 mvn clean install：该命令调用clean生命周期 的clean阶段和default生命周期的install阶段。 mvn clean deploy site-deploy：该命令调用 clean生命周期的clean阶段、default生命周期的 deploy阶段，以及site生命周期的site-deploy阶段。 聚合与继承软件设计人员往往会采用各种方式对软件划分模块，以得到更清晰的设计及更高的重用性。当把Maven应用到实际项目中的时候，也需要将项目分成不同的模块。 简单的说就是有 A,B 两个模块，现在想要将他们统一管理。Maven 的聚合特性能够把项目的各个模块聚合在一起构建，而Maven的继承特性则能帮助抽取各模块相同的依赖和插件等配置，在简化POM的同时，还能促进各个模块配置的一致性。 聚合两个子模块希望同时构建。这时，一个简单的需求就会自然而然地显现出来：我们会想要一次构建两个项目，而不是到两个模块的目录下分别执行mvn命令。Maven聚合（或者称为多模块）这一特性就是为该需求服务的。 上图所示api是一个模块，cmd是一个模块他们都有各自的 pom 文件，其实每一个包都是一个子模块，而最底下的 pom 文件则是统一管理这些子模块。 他们的配置很简单，我们最好遵循规范。 api 的 pom.xml 12345678910111213&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;groupId&gt;com.shuiyujie.fu&lt;/groupId&gt; &lt;artifactId&gt;sop&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;api&lt;/artifactId&gt; ... cmd 的 pom.xml 123456789101112&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;groupId&gt;com.shuiyujie.fu&lt;/groupId&gt; &lt;artifactId&gt;sop&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cmd&lt;/artifactId&gt; 聚合 pom.xml 123456789101112131415161718192021&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.shuiyujie.fu&lt;/groupId&gt; &lt;artifactId&gt;pom&lt;/artifactId&gt; &lt;packaging&gt;sop&lt;/packaging&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;name&gt;sop&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; ... &lt;modules&gt; &lt;module&gt;base&lt;/module&gt; &lt;module&gt;core&lt;/module&gt; &lt;module&gt;server&lt;/module&gt; &lt;module&gt;persist&lt;/module&gt; &lt;module&gt;api&lt;/module&gt; &lt;module&gt;impl&lt;/module&gt; &lt;module&gt;cmd&lt;/module&gt; &lt;/modules&gt; ... 观察上面的三个代码清单可以聚合 pom 文件中定义了 &lt;modules&gt; 标签，标签中包含的就是各个子模块，并且用子模块的artifactId来标记他们。 注意：聚合 pom 文件的打包方式，即 packaging 必须为 pom。 这样只需要构建聚合 pom 文件即可同时构建在其管理下的多个子模块。 继承消除重复。在面向对象世界中，程序员可以使用类继承在一定程度上消除重复，在Maven的世界 中，也有类似的机制能让我们抽取出重复的配 置，这就是POM的继承。 任然看上面的三个 pom.xml 代码清单，子模块都有一个parent标签，这就表明他们继承了一个 pom 文件，而parent标签下的其他标签就是一个坐标系，通过一个坐标系就能定位一个唯一的项目。 比如上面的子模块继承自聚合 pom 文件，所以此时聚合 pom 文件也是父类 pom 文件。 排除父类的依赖在继承的过程中我们考虑一种情形，我们希望在父类中统一控制 spring 的版本，然后子类继承自父类就可以使用统一版本的 spring 依赖了。但是有些子模块不需要依赖 spring，并不需要从父类继承 spring 的依赖。 我们可以使用dependencyManagement 标签。 父类 pom.xml 123456789101112131415161718192021222324252627282930313233343536&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!-- 模块间依赖 start --&gt; &lt;dependency&gt; &lt;groupId&gt;${project.groupId}&lt;/groupId&gt; &lt;artifactId&gt;core&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;${project.groupId}&lt;/groupId&gt; &lt;artifactId&gt;persist&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;${project.groupId}&lt;/groupId&gt; &lt;artifactId&gt;api&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;${project.groupId}&lt;/groupId&gt; &lt;artifactId&gt;impl&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;${project.groupId}&lt;/groupId&gt; &lt;artifactId&gt;server&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;${project.groupId}&lt;/groupId&gt; &lt;artifactId&gt;cmd&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 模块间依赖 end --&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; 父类dependencyManagement中声明了各个子模块，子模块之间有的会需要相互引用，有的却并不需要。所以在父类中统一配置各个子模块的groupId,artifactId,version等基本信息。 在dependencyManagement中声明的依赖不会在当前pom中引入依赖，也不会再继承他的pom中引入依赖，他的作用只是声明了可能要引入依赖的一些通用信息。 如果要使用一个子模块要使用其他子模块就可以另外声明，但是不需要指定版本等通用信息，这样就可以减少依赖冲突的发生，代码如下： 1234567891011121314151617181920&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;groupId&gt;com.shuiyujie.fu&lt;/groupId&gt; &lt;artifactId&gt;sop&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;api&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;${project.parent.groupId}&lt;/groupId&gt; &lt;artifactId&gt;fu-persist&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 总结：Maven 的思想Maven 的核心思想是约定优于配置。 首先，Maven 约定了项目的结构，我们不需要配置 Maven 编译、打包等操作时文件的位置。统一的项目结构降低了学习的成本，让我能将精力集中到了项目本身。 其次，Maven 抽象了项目构建的过程，将其分成一个个生命周期进行管理。通过命令和插件的形式进一步简化操作，又让我们从繁琐的操作解放出来。 参考《Maven 实战》 Maven远程仓库的各种配置 本文大部分内容来自于《Maven 实战》一书，想要了解一手信息强烈建议阅读。网上的其他文章基本上都是摘抄《Maven 实战》的部分内容。 所以还想说一遍：发现一本好书就像发现了一座宝藏。","link":"/post/cfedc026.html"},{"title":"Java 多线程基础知识","text":"计算机发明之初，单个 CPU 在同一时间点只能执行单个任务，也就是单任务阶段。紧接着发展为多任务阶段，在单个 CPU 上能执行多个进程，但是此处的并行执行并不是指在同一时间执行多个任务，而是指由系统对进程进行调度轮流使用 CPU。 接着发展到现在的多线程阶段，一个程序内部能够运行多个线程，每个线程都可以被看做运行在一个 CPU 上，此时计算机真正做到了在同一时间点能够执行多个任务。 进程和线程进程和线程怎么界定？一个进程包含着一个或多个线程。 当我们启动一个应用程序的时候，操作系统将加载这个应用程序并为当前程序开辟一块独立的内存空间，这片空间就专门用来负责这个程序的运行。这就是一个进程，我们可以把它想象成一个车间。 假设我们启动的程序是微信，我们可以使用微信和多个人聊天并且互不干扰。同时和不同的人聊天就是将进程划分成多个区域，每个区域就是一个线程。如果把进程比作车间，线程就像车间中的工人，工人们各司其职维持车间的正常运转。 多线程运行原理多线程就是在一个进程中开启多个线程，让多个线程去实现不同功能。多线程最常见的就是 GUI 程序，比如说使用 IDE 运行程序的同时我们还能用 IDE 继续写代码，这就用到了多线程。 多线程运行则是利用 CPU 在线程中做时间片切换。CPU 负责运行程序且一次只能运行一个程序，多线程的实现依靠 CPU 在线程间快速切换，由于切换的时间很快就像同时运行多个线程一样。 多线程切换过程中，它需要先存储当前线程的本地的数据，程序指针等，然后载入另一个线程的本地数据，程序指针等，最后才开始执行。所以多线程一般能提高程序运行效率，但也不能无节制地开启线程。 Java 实现多线程的两种方式多线程的两种创建方式分别为继承 Thread 类以及实现 Runnable 接口。一般用实现 Runnable 接口的方式。 我们通过调用线程的 start() 方法新建一个线程并启动它，下面是两种主要实现方式的示例。 继承 Thread 类123456789101112131415161718public class MyThread1 extends Thread { private int count = 5; @Override public void run() { for (int i = 5; i &gt; 0 &amp;&amp; count&gt;0; i--,count--) { System.out.println(\"count----\" + count); } } public static void main(String[] args) { new MyThread1().start(); new MyThread1().start(); new MyThread1().start(); }} 可以创建一个实例直接 start()，因为 Thread 类中定义了 start() 方法。 实现 Runnable 接口123456789101112131415161718public class MyThread2 implements Runnable{ private int count = 5; @Override public void run() { for (int i = 5; i &gt; 0 &amp;&amp; count&gt;0; i--,count--) { System.out.println(\"count----\" + count); } } public static void main(String[] args) { MyThread2 myThread2 = new MyThread2(); new Thread(myThread2).start(); new Thread(myThread2).start(); new Thread(myThread2).start(); }} 但是他无法直接创建实例之后直接 start(),查看源码可以看到 Runnable 接口只有一个 run() 方法没有 start()方法，所以他必须由 Thread 来启动。 两者优缺点比较实现 Runable() 避免由于 Java 的单继承特性而带来的局限Java 使用 extends 关键字实现继承，可以理解成全盘接受了父类的特性。使用 implents 关键字实现接口，对类的功能进行拓展。要注意的是 Java 的继承是单继承，也就是只能继承一个父类。但是每个类都能实现多个接口。 当一个类需要实现多线程的时候，如果他已经继承了其他的父类则不能再继承 Thread 类，但是即使他实现了其他接口，他任然能实现 Runable 接口创建多线程。 但是当我们访问当前线程时需要使用Thread.currentThread()方法。 继承 Thread 类编写简单，方便理解通过继承 Thread 类的方法实现多线程，调用当前类只需要使用 this 关键字即可进行访问。但是使用这种方式之后就不能继承其他父类。 因此一般都是用实现 Runable() 接口的形式。本篇中使用显示创建线程的方式，而创建线程更好的方式是使用线程池。 多线程 run() 和 start() 的区别通过运行run()方法和start()方法，看看输出结果有什么区别。 run() 方法1234567891011121314151617181920212223public class MyThread3 extends Thread { private int count = 5; @Override public void run() { for (int i = 5; i &gt; 0 &amp;&amp; count&gt;0; i--,count--) { System.out.println(this.currentThread().getName() + \"----count----\" + count); } } public static void main(String[] args) { MyThread3 myThread1 = new MyThread3(); myThread1.setName(\"Thread1\"); myThread1.run(); MyThread3 myThread2 = new MyThread3(); myThread2.setName(\"Thread2\"); myThread2.run(); }} 输出结果为： 12345678910thread1----count----5thread1----count----4thread1----count----3thread1----count----2thread1----count----1thread2----count----5thread2----count----4thread2----count----3thread2----count----2thread2----count----1 Thread1 和 Thead2 只是在主线程上顺序执行，并没有开启新的线程。 start() 方法如果将 run() 改成 start()输出结果为: 1234567thread2---count----5thread3---count----5thread1---count----5thread3---count----3thread3---count----1thread2---count----4thread1---count----2 可以看到两个线程在抢占资源，成功创建了两个线程。 结果对比创建了两个相同的线程对象，但是结果有明显的差异。run() 的运行结果始终是顺次递减，线程1执行完之后再执行线程2，表明他们是在主线程上顺序运行，并没有开启新的线程。 但是使用start()方法则可以看到线程1和线程2在竞争资源，说明成功开启了两个线程。 线程 start() 和 run() 的区别先看一下 Runnable 接口 123public interface Runnable { public abstract void run();} 其中只有一个 run() 方法，注释是这么写的： When an object implementing interface Runnable is used to create a thread 所以用于实现了 run() 方法的对象可以被用于创建一个线程 再看 Thread 类 12345678910public class Thread implements Runnable { /* What will be run. */ private Runnable target; @Override public void run() { if (target != null) { target.run(); } } Thread 实现了 Runable 的接口,可以传入一个 Runnable，执行 Runnable 的 run() 方法,他说: If this thread was constructed using a separate Runnable run object, then that Runnable object’s run method is called; otherwise, this method does nothing and returns. 说明 Thread 类的作用就是用于运行 Runable 的实例，将实现了 Runable 方法的实例传入 Thread 类就可以运行该实例的run()方法 再看start() 方法的说明： 使用 start() 让线程会调用run()之后在虚拟机上执行 Causes this thread to begin execution; the Java Virtual Machine calls the run method of this thread. 12345678public synchronized void start() { if (threadStatus != 0) throw new IllegalThreadStateException(); /*把线程加到线程组中，表示这个线程将会被执行*/ group.add(this); ... } run() 只是在当前线程中启动，start() 才是真正新建一个线程并启动。 参考进程与线程的一个简单解释","link":"/post/1d67cce0.html"},{"title":"RocketMQ Start","text":"RocketMQ 是一款分布式、队列模型的消息中间件，具有以下特点： 能够保证严格的消息顺序 提供丰富的消息拉取模式 高效的订阅者水平扩展能力 实时的消息订阅机制 亿级消息堆积能力 今天开始试着理解她。 快速开始环境要求 64bit OS, Linux/Unix/Mac is recommended; 64bit JDK 1.8+; Maven 3.2.x Git 准备工作下载安装包 here 到服务器中，本文使用的是rocketmq-all-4.2.0。 unzip rocketmq-all-4.2.0-source-release.zipcd rocketmq-all-4.2.0/mvn -Prelease-all -DskipTests clean install -U 没有注意环境，maven 版本为 3.0.5，升级 maven 到 3.5.2 cd distribution/target/apache-rocketmq 启动 Name Server nohup sh bin/mqnamesrv &amp;tail -f ~/logs/rocketmqlogs/namesrv.logThe Name Server boot success… 启动 Broker nohup sh bin/mqbroker -n localhost:9876 &amp;tail -f ~/logs/rocketmqlogs/broker.log 错误：启动不成功，看错误日志 1234567891011121314151617181920212223## There is insufficient memory for the Java Runtime Environment to continue.# Native memory allocation (mmap) failed to map 8589934592 bytes for committing reserved memory.# Possible reasons:# The system is out of physical RAM or swap space# In 32 bit mode, the process size limit was hit# Possible solutions:# Reduce memory load on the system# Increase physical memory or swap space# Check if swap backing store is full# Use 64 bit Java on a 64 bit OS# Decrease Java heap size (-Xmx/-Xms)# Decrease number of Java threads# Decrease Java thread stack sizes (-Xss)# Set larger code cache with -XX:ReservedCodeCacheSize=# This output file may be truncated or incomplete.## Out of Memory Error (os_linux.cpp:2640), pid=3437, tid=0x00007f378a5c2700## JRE version: (8.0_151-b12) (build )# Java VM: Java HotSpot(TM) 64-Bit Server VM (25.151-b12 mixed mode linux-amd64 compressed oops)# Core dump written. Default location: /apps/rocketmq-all-4.2.0/distribution/core or core.3437# 原因：rocketmq默认jvm配置较高，导致内存不足 runserver.sh 12345JAVA_OPT=&quot;${JAVA_OPT} -server -Xms4g -Xmx4g -Xmn2g -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m&quot;改成JAVA_OPT=&quot;${JAVA_OPT} -server -Xms256m -Xmx256m -Xmn128m -XX:PermSize=128m -XX:MaxPermSize=320m&quot; runbroker.sh 12345JAVA_OPT=&quot;${JAVA_OPT} -server -Xms8g -Xmx8g -Xmn4g&quot;改成：JAVA_OPT=&quot;${JAVA_OPT} -server -Xms256m -Xmx256m -Xmn128m&quot; tools.sh 12345JAVA_OPT=&quot;${JAVA_OPT} -server -Xms1g -Xmx1g -Xmn256m -XX:PermSize=128m -XX:MaxPermSize=128m&quot;改成JAVA_OPT=&quot;${JAVA_OPT} -server -Xms256m -Xmx256m -Xmn128m -XX:PermSize=128m -XX:MaxPermSize=128m&quot; 再次启动 Broker 成功 The broker[main, 192.168.0.222:10911] boot success. serializeType=JSON and name server is localhost:9876 查看一下服务 Jps 1234[root@main apache-rocketmq]# jps4419 BrokerStartup4636 Jps4077 NamesrvStartup 发送接收消息 123456&gt; export NAMESRV_ADDR=localhost:9876&gt; sh bin/tools.sh org.apache.rocketmq.example.quickstart.ProducerSendResult [sendStatus=SEND_OK, msgId= ...&gt; sh bin/tools.sh org.apache.rocketmq.example.quickstart.ConsumerConsumeMessageThread_%d Receive New Messages: [MessageExt... 停止服务 12sh bin/mqshutdown brokersh bin/mqshutdown namesrv 使用 RocketMQ Console 监控在 Tomcat 中部署 RocketMQ Console，可以看到 RocketMQ 的运行情况。 RocketMQ 扩展项目地址将项目 clone 到本地，进入rocketmq-console，参考项目文档编译。 修改application.properties文件 rocketmq.config.namesrvAddr= 192.168.0.222:9876 编译运行文件 mvn clean package -Dmaven.test.skip=truejava -jar target/rocketmq-console-ng-1.0.0.jar 在浏览器访问192.168.0.222:8080即可访问监控界面，就能看到 RocketMQ 的基本信息。 客户端访问NameService 和 BrokerService已经启动，现在单机模式下用客户端来实现消息的订阅和发送。 Producer123456789101112131415161718192021222324252627282930public class TestProducer { public static void main(String[] args) throws MQClientException, InterruptedException { DefaultMQProducer producer = new DefaultMQProducer(\"DefaultCluster\"); producer.setNamesrvAddr(\"192.168.0.222:9876\"); producer.start(); for (int i = 0; i &lt; 100; i++) { try { { Message msg = new Message(\"TopicTest1\", \"TagA\", \"key113\", \"Hello world\".getBytes(RemotingHelper.DEFAULT_CHARSET)); SendResult sendResult = producer.send(msg); System.out.printf(\"%s%n\", sendResult); QueryResult queryMessage = producer.queryMessage(\"TopicTest1\", \"key113\", 10, 0, System.currentTimeMillis()); for (MessageExt m : queryMessage.getMessageList()) { System.out.printf(\"%s%n\", m); } } } catch (Exception e) { e.printStackTrace(); } } producer.shutdown(); }} Consumer1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class PullConsumer { private static final Map&lt;MessageQueue, Long&gt; OFFSE_TABLE = new HashMap&lt;MessageQueue, Long&gt;(); public static void main(String[] args) throws MQClientException { DefaultMQPullConsumer consumer = new DefaultMQPullConsumer(\"DefaultCluster\"); consumer.setNamesrvAddr(\"192.168.0.222:9876\"); consumer.start(); Set&lt;MessageQueue&gt; mqs = consumer.fetchSubscribeMessageQueues(\"TopicTest1\"); for (MessageQueue mq : mqs) { System.out.printf(\"Consume from the queue: %s%n\", mq); SINGLE_MQ: while (true) { try { PullResult pullResult = consumer.pullBlockIfNotFound(mq, null, getMessageQueueOffset(mq), 32); System.out.printf(\"%s%n\", pullResult); putMessageQueueOffset(mq, pullResult.getNextBeginOffset()); switch (pullResult.getPullStatus()) { case FOUND: break; case NO_MATCHED_MSG: break; case NO_NEW_MSG: break SINGLE_MQ; case OFFSET_ILLEGAL: break; default: break; } } catch (Exception e) { e.printStackTrace(); } } } consumer.shutdown(); } private static long getMessageQueueOffset(MessageQueue mq) { Long offset = OFFSE_TABLE.get(mq); if (offset != null) return offset; return 0; } private static void putMessageQueueOffset(MessageQueue mq, long offset) { OFFSE_TABLE.put(mq, offset); }} 从控制台可以看到集群的基本信息，包括消息的产生和消费数量等。 RocketMQ 单机模式跑通，接下来使用双 master 模式。 部署 RockerMQ 双 Master 模式 参考资料Apache RocketMQRocket-Externals安装rocketmq-consoleMaven 升级","link":"/post/20e9366a.html"},{"title":"部署 RockerMQ 双 Master 模式","text":"本文介绍搭建双 master 的 RocektMQ 的集群。 RocketMQ集群方式首先要部署一个 RocketMQ 的集群，以下集群方式摘自网络。 推荐的几种 Broker 集群部署方式，这里的 Slave 不可写但可读，类似于 Mysql 主备方式。 单个 Master这种方式风险较大，一旦Broker 重启或者宕机时，会导致整个服务不可用，不建议线上环境使用。 多 Master 模式一个集群无 Slave，全是 Master，例如 2 个 Master 或者 3 个 Master。 优点 配置简单，单个 Master 宕机或重启维护对应用无影响，在磁盘配置为 RAID10 时，即使机器宕机不可恢复情况下，由与 RAID10 磁盘非常可靠，消息也不会丢（异步刷盘丢失少量消息，同步刷盘一条不丢） 。性能最高。 缺点 单台机器宕机期间，这台机器上未被消费的消息在机器恢复之前不可订阅，消息实时性会受到受到影响。 启动顺序 先启动 NameServer 再机器 A，启动第一个 Master 再机器 B，启动第二个 Master 多 Master 多 Slave 模式，异步复制每个 Master 配置一个 Slave，有多对Master-Slave，HA 采用异步复制方式，主备有短暂消息延迟，毫秒级。 优点 即使磁盘损坏，消息丢失的非常少，且消息实时性不会受影响，因为 Master 宕机后，消费者仍然可以从 Slave 消费，此过程对应用透明。不需要人工干预。性能同多 Master 模式几乎一样。 缺点 Master 宕机，磁盘损坏情况，会丢失少量消息。 启动顺序 启动 NameServer 机器 A，启动第一个 Master 机器 B，启动第二个 Master 机器 C，启动第一个 Slave 机器 D，启动第二个 Slave 多 Master 多 Slave 模式，同步双写每个 Master 配置一个 Slave，有多对Master-Slave，HA 采用同步双写方式，主备都写成功，向应用返回成功。 优点 数据与服务都无单点，Master宕机情况下，消息无延迟，服务可用性与 数据可用性都非常高 缺点 性能比异步复制模式略低，大约低 10%左右，发送单个消息的 RT 会略高。目前主宕机后，备机不能自动切换为主机，后续会支持自动切换功能 。 启动顺序 启动 NameServer 机器 A，启动第一个 Master 机器 B，启动第二个 Master 机器 C，启动第一个 Slave 机器 D，启动第二个 Slave 以上 Broker 与 Slave 配对是通过指定相同的brokerName 参数来配对，Master 的 BrokerId 必须是 0，Slave 的BrokerId 必须是大与 0 的数。另外一个 Master 下面可以挂载多个 Slave，同一 Master 下的多个 Slave通过指定不同的 BrokerId 来区分。 部署双 master 模式的集群出于简单和可用的考虑，本文使用双 master 的方式部署 RocketMQ 集群。更多细节看上一篇文章RocketMQ Start，我们用上篇文章中相同的方式再部署一台主机。 服务器环境 序号 IP 用户名 角色 模式 1 192.168.0.222 root nameService1,brokerServer1 Master 2 192.168.0.255 Root nameService2,brokerServer2 Master2 修改 hosts vi /etc/hosts IP Name 192.168.0.222 rocketmq-nameserver1 192.168.0.222 rocketmq-master1 192.168.0.225 rocketmq-nameserver2 192.168.0.225 rocketmq-master2 修改配置文件修改目标文件： /usr/local/rocketmq/conf/2m-noslave 该目录下有两个文件,分别修改一个，与下面的配置文件的 brokerName 对应 broker-a.properties broker-b.properties 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#所属集群名字 brokerClusterName=rocketmq-cluster #broker名字，注意此处不同的配置文件填写的不一样brokerName=broker-a|broker-b#0 表示 Master，&gt;0 表示 Slave brokerId=0 #nameServer地址，分号分割namesrvAddr=rocketmq-nameserver1:9876;rocketmq-nameserver2:9876 #在发送消息时，自动创建服务器不存在的topic，默认创建的队列数defaultTopicQueueNums=4 #是否允许 Broker 自动创建Topic，建议线下开启，线上关闭autoCreateTopicEnable=true #是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭autoCreateSubscriptionGroup=true #Broker 对外服务的监听端口 listenPort=10911 #删除文件时间点，默认凌晨 4点 deleteWhen=04 #文件保留时间，默认 48 小时fileReservedTime=120#commitLog每个文件的大小默认1GmapedFileSizeCommitLog=1073741824#ConsumeQueue每个文件默认存30W条，根据业务情况调整mapedFileSizeConsumeQueue=300000#destroyMapedFileIntervalForcibly=120000#redeleteHangedFileInterval=120000#检测物理文件磁盘空间diskMaxUsedSpaceRatio=88#存储路径 storePathRootDir=/usr/local/rocketmq/store #commitLog 存储路径 storePathCommitLog=/usr/local/rocketmq/store/commitlog #消费队列存储路径存储路径storePathConsumeQueue=/usr/local/rocketmq/store/consumequeue#消息索引存储路径storePathIndex=/usr/local/rocketmq/store/index#checkpoint 文件存储路径storeCheckpoint=/usr/local/rocketmq/store/checkpoint#abort 文件存储路径abortFile=/usr/local/rocketmq/store/abort#限制的消息大小imaxMessageSize=65536#flushCommitLogLeastPages=4 #flushConsumeQueueLeastPages=2 #flushCommitLogThoroughInterval=10000 #flushConsumeQueueThoroughInterval=60000#Broker 的角色 #- ASYNC_MASTER 异步复制Master #- SYNC_MASTER 同步双写Master #- SLAVE brokerRole=ASYNC_MASTER#刷盘方式 #- ASYNC_FLUSH 异步刷盘 #- SYNC_FLUSH 同步刷盘 flushDiskType=ASYNC_FLUSH#checkTransactionMessageEnable=false#发消息线程池数量 #sendMessageThreadPoolNums=128 #拉消息线程池数量 #pullMessageThreadPoolNums=128 配置存储路径从配置文件中可以看到需要配置一些文件的存储位置，只要文件中配置的目录存在即可 123456789101112#存储路径 storePathRootDir=/usr/local/rocketmq/store #commitLog 存储路径 storePathCommitLog=/usr/local/rocketmq/store/commitlog #消费队列存储路径存储路径storePathConsumeQueue=/usr/local/rocketmq/store/consumequeue#消息索引存储路径storePathIndex=/usr/local/rocketmq/store/index#checkpoint 文件存储路径storeCheckpoint=/usr/local/rocketmq/store/checkpoint#abort 文件存储路径abortFile=/usr/local/rocketmq/store/abort 分别修改日志配置文件 mkdir -p /usr/local/rocketmq/logscd /usr/local/rocketmq/conf &amp;&amp; sed -i ‘s#${user.home}#/usr/local/rocketmq#g’ *.xml 修改 JVM 参数runserver.sh 12345JAVA_OPT=&quot;${JAVA_OPT} -server -Xms4g -Xmx4g -Xmn2g -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m&quot;改成JAVA_OPT=&quot;${JAVA_OPT} -server -Xms256m -Xmx256m -Xmn128m -XX:PermSize=128m -XX:MaxPermSize=320m&quot; runbroker.sh 12345JAVA_OPT=&quot;${JAVA_OPT} -server -Xms8g -Xmx8g -Xmn4g&quot;改成：JAVA_OPT=&quot;${JAVA_OPT} -server -Xms256m -Xmx256m -Xmn128m&quot; tools.sh 12345JAVA_OPT=&quot;${JAVA_OPT} -server -Xms1g -Xmx1g -Xmn256m -XX:PermSize=128m -XX:MaxPermSize=128m&quot;改成JAVA_OPT=&quot;${JAVA_OPT} -server -Xms256m -Xmx256m -Xmn128m -XX:PermSize=128m -XX:MaxPermSize=128m&quot; 启动两台主机的 NameServer cd /usr/local/rocketmq/binnohup sh mqnamesrv &amp; 启动BrokerServer A nohup sh mqbroker -c /usr/local/rocketmq/conf/2m-noslave/broker-a.properties &gt;/dev/null 2&gt;&amp;1 &amp;netstat -ntlptail -f -n 500 /usr/local/rocketmq/logs/rocketmqlogs/broker.logtail -f -n 500 /usr/local/rocketmq/logs/rocketmqlogs/namesrv.log 启动BrokerServer A nohup sh mqbroker -c /usr/local/rocketmq/conf/2m-noslave/broker-b.properties &gt;/dev/null 2&gt;&amp;1 &amp;netstat -ntlptail -f -n 500 /usr/local/rocketmq/logs/rocketmqlogs/broker.logtail -f -n 500 /usr/local/rocketmq/logs/rocketmqlogs/namesrv.log 数据清理12345678910111213cd /usr/local/rocketmq/bin sh mqshutdown brokersh mqshutdown namesrv*等待停止 *rm -rf /usr/local/rocketmq/storemkdir /usr/local/rocketmq/storemkdir /usr/local/rocketmq/store/commitlogmkdir /usr/local/rocketmq/store/consumequeue mkdir /usr/local/rocketmq/store/index*重复以上步骤重启NameServer与BrokerServer*","link":"/post/6fc5439d.html"},{"title":"RabbitMQ 安装和使用","text":"RabbitMQ 是一个消息队列，主要是用来实现应用程序的异步和解耦，同时也能起到消息缓冲，消息分发的作用。本文介绍RabbitMQ 安装和使用。 RabbitMQ 是一个开源的AMQP实现，服务器端用Erlang语言编写，支持多种客户端，如：Python、Ruby、.NET、Java、JMS、C、PHP、ActionScript、XMPP、STOMP等，支持AJAX。用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。 可以把消息队列想象成邮局，你的笔友把信件投递到邮局，邮递员源源不断地进出邮局，把笔友的信送到你的手里。此时的笔友就是一个生产者（Product）,邮递员一次送信就是（Queue）,而你收信就像是消费者（Consumer）。 AMQPAMQP（Advanced Message Queuing Protocol，高级消息队列协议）的原始用途只是为金融界提供一个可以彼此协作的消息协议，而现在的目标则是为通用消息队列架构提供通用构建工具。消息中间件主要用于组件之间的解耦，消息的发送者无需知道消息使用者的存在，反之亦然。AMQP的主要特征是面向消息、队列、路由（包括点对点和发布/订阅）、可靠性、安全。 RabbitMQ 则是一个开源的 AMQP 实现。 Rabbit 概念通常我们谈到队列服务, 会有三个概念： 发消息者、队列、收消息者，RabbitMQ 在这个基本概念之上, 多做了一层抽象, 在发消息者和 队列之间, 加入了交换器 (Exchange)。这样发消息者和队列就没有直接联系, 转而变成发消息者把消息给交换器, 交换器根据调度策略再把消息再给队列。 通过 RabbitMQ 官网 的示例中看到 RabbitMQ 有六种模式。 官网中有多种语言的实现，本文用 Java 来实现。采用 Springboot 集成 RabbitMQ。 CentOS 安装 RabbitMQ安装 Erlang、Elixir准备 yum update yum install epel-release yum install gcc gcc-c++ glibc-devel make ncurses-devel openssl-devel autoconf java-1.8.0-openjdk-devel git wget wxBase.x86_64 安装 Erlang wget http://packages.erlang-solutions.com/erlang-solutions-1.0-1.noarch.rpm rpm -Uvh erlang-solutions-1.0-1.noarch.rpm yum update yum install erlang 验证是否安装成功，输入命令：erl 安装 Elixir因为 EPEL 中的 Elixir 版本太老，所以下面是通过源码编译安装的过程： git clone https://github.com/elixir-lang/elixir.git cd elixir/ make clean test export PATH=”$PATH:/usr/local/elixir/bin” 验证是否安装成功，输入命令：iex 安装 RabbitMQ wget https://www.rabbitmq.com/releases/rabbitmq-server/v3.6.1/rabbitmq-server-3.6.1-1.noarch.rpm rpm –import https://www.rabbitmq.com/rabbitmq-signing-key-public.asc yum install rabbitmq-server-3.6.1-1.noarch.rpm Rabitmq 管理至此已经安装完成，下面介绍启动和自动开机启动命令和配置 启动： systemctl start rabbitmq-server 开机自动启动： systemctl enable rabbitmq-server 查看 rabbitmq-server 状态： rabbitmqctl status 关闭： systemctl enable rabbitmq-server 可以直接通过配置文件的访问进行管理，也可以通过Web的访问进行管理。 通过Web进行管理,开启 Web 管理: rabbitmq-plugins enable rabbitmq_management chown -R rabbitmq:rabbitmq /var/lib/rabbitmq/ 注：先启动 RabbitMQ 访问：http://192.168.2.223:15672/，默认用户 guest ，密码 guest。 发现登录失败，由于账号guest具有所有的操作权限，并且又是默认账号，出于安全因素的考虑，guest用户只能通过localhost登陆使用。 我们新增一个用户： rabbitmqctl add_user admin 123456 rabbitmqctl set_user_tags admin administrator rabbitmqctl set_permissions -p / admin “.“ “.“ “.*” Springboot 集成 RabbitMQ假设现在已经按照前面的步骤完成了 RabbitMQ 的安装，现在开始使用 Springboot 集成 RabbitMQ。 基本配置IDEA 先新建一个 maven 项目，在 pom 文件中添加相关依赖: pom 文件1234567891011121314151617181920212223242526272829303132333435363738&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.shuiyujie&lt;/groupId&gt; &lt;artifactId&gt;pom&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;name&gt;pom&lt;/name&gt; &lt;!-- Spring Boot 启动父依赖 --&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.2.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Test 依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- rabbitmq --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; application.properties123456# rabbitmq 配置文件spring.rabbitmq.host=192.168.0.223# 默认端口spring.rabbitmq.port=5672spring.rabbitmq.username=adminspring.rabbitmq.password=123456 “Hello World” 现在我们的目标很简单就是创建一个生产者 P，和一个消费者 C，同时将 P 产生的消息放到队列中供 C 使用。 Queue 1234567891011import org.springframework.amqp.core.Queue;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class RabbitConfig { @Bean public Queue helloQueue() { return new Queue(&quot;hello&quot;); }} HelloSender 123456789101112@Controllerpublic class HelloSender { @Autowired private AmqpTemplate rabbitTemplate; public void send() { String context = \"hello \" + new Date(); System.out.println(\"Sender : \" + context); this.rabbitTemplate.convertAndSend(\"hello\", context); }} HelloReceiver 12345678@Componentpublic class HelloReceiver { @RabbitHandler @RabbitListener(queues = \"hello\") public void process(String hello) { System.out.println(\"Receiver : \" + hello); }} 运行 123456789101112@RunWith(SpringRunner.class)@SpringBootTest(classes = HelloApplication.class)public class RabbitmqApplicationTests { @Autowired private HelloSender helloSender; @Test public void hello() throws Exception { helloSender.send(); }} 成功接收到消息 1Receiver : hello Thu Feb 01 22:21:39 CST 2018 注意：HelloReceiver的@RabbitListener(queues = &quot;hello&quot;)注解是方法级的，参照别的文章都是类级别的注解导致一直无法正常连接。 Work Queues Work Queues 模式在原来的基础上多增加了一个消费者。同理我们可以扩展三个、四个甚至更多的consumer。这样做的好处在于，当我们使用一个consumer的时候，当它收到一条消息进行处理的时候会发生阻塞。有多个consumer时，消息就可以分发给空闲的consumer进行处理。 生产者 123456789101112131415161718/** * Work 模式下的生产者 * * @author shui * @create 2018-02-04 **/@Controllerpublic class WorkSender { @Autowired private AmqpTemplate rabbitTemplate; public void send(int i) { String context = \"work \"; System.out.println(\"Sender : \" + context + \"*****\" + i); this.rabbitTemplate.convertAndSend(\"work\", context); }} Queue 1234567@Configurationpublic class WorkConfig { @Bean public Queue workQueue() { return new Queue(\"work\"); }} 两个消费者 1234567891011121314151617@Componentpublic class WorkReceicer1 { @RabbitHandler @RabbitListener(queues = \"work\") public void process(String message) { System.out.println(\"Work Receiver1 : \" + message); }}@Componentpublic class WorkReceicer2 { @RabbitHandler @RabbitListener(queues = \"work\") public void process(String message) { System.out.println(\"Work Receiver2 : \" + message); }} 测试 1234567891011121314@RunWith(SpringRunner.class)@SpringBootTest(classes = Startup.class)public class RabbitMQDirectTest { @Autowired private WorkSender workSender; @Test public void sendWorkTest() { for (int i = 0; i &lt; 20; i++) { workSender.send(i); } }} 结果 1234567891011121314151617181920Work Receiver1 : work Work Receiver2 : work Work Receiver2 : work Work Receiver1 : work Work Receiver2 : work Work Receiver1 : work Work Receiver2 : work Work Receiver1 : work Work Receiver1 : work Work Receiver2 : work Work Receiver2 : work Work Receiver1 : work Work Receiver2 : work Work Receiver1 : work Work Receiver1 : work Work Receiver2 : work Work Receiver1 : work Work Receiver2 : work Work Receiver2 : work Work Receiver1 : work 发现消费得很平均，每个consumer处理一半的消息。 public/subscribe 从上面的两个例子我们看到producer产生的消息直接发送给queue，然后queue又直接将消息传给consumer。RabbitMQ 的亮点就在于改变了上面这种消息传递的方式，producer不会将消息直接传给queue而是传给exchanges再由exchangers传给queue。然而我们在前面的两个例子中并没有使用exchanges，那是因为 RabbitMQ 有默认的exchanges，只要我们传的参数是&quot;&quot;。在默认模式下，不需要将exchanges做任何绑定。除此之外exchanges有以下几种类型： Direct：direct 类型的行为是”先匹配, 再投送”. 即在绑定时设定一个 routing_key, 消息的 routing_key 匹配时, 才会被交换器投送到绑定的队列中去. Topic：按规则转发消息（最灵活） Headers：设置header attribute参数类型的交换机 Fanout：转发消息到所有绑定队列 Queue 以下使用的是Fanout Exchange转发消息到所有绑定队列。这里要配置两个queue，并且配置exchanges，并把queue和exchanges绑定。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * * public/subscribe 模式 * * @author shui * @create 2018-02-04 **/@Configurationpublic class FanoutConfig { /************************************************************************ * 新建队列 fanout.A 、fanout.B************************************************************************/ @Bean public Queue AMessage() { return new Queue(\"fanout.A\"); } @Bean public Queue BMessage() { return new Queue(\"fanout.B\"); } /** * 建立一个交换机 * * @return */ @Bean FanoutExchange fanoutExchange() { return new FanoutExchange(\"fanoutExchange\"); } /************************************************************************ * 将 fanout.A 、 fanout.B 绑定到交换机 fanoutExchange 上************************************************************************/ @Bean Binding bindingExchangeA(Queue AMessage, FanoutExchange fanoutExchange) { return BindingBuilder.bind(AMessage).to(fanoutExchange); } @Bean Binding bindingExchangeB(Queue BMessage, FanoutExchange fanoutExchange) { return BindingBuilder.bind(BMessage).to(fanoutExchange); }} 生产者 在创建producter的时候，要将他和exchanges绑定。 1234567891011@Controllerpublic class FanoutSender { @Autowired private AmqpTemplate rabbitTemplate; public void send() { String context = \"hi, fanout msg \"; System.out.println(\"Sender : \" + context); this.rabbitTemplate.convertAndSend(\"fanoutExchange\",\"\", context); }} 两个消费者 123456789101112131415161718@Componentpublic class FanoutReceiveA { @RabbitHandler @RabbitListener(queues = \"fanout.A\") public void process(String message) { System.out.println(\"fanout Receiver A : \" + message); }}@Componentpublic class FanoutReceiveB { @RabbitHandler @RabbitListener(queues = \"fanout.B\") public void process(String message) { System.out.println(\"fanout Receiver B : \" + message); }} 测试 1234567891011@RunWith(SpringRunner.class)@SpringBootTest(classes = Startup.class)public class FanoutTest { @Autowired private FanoutSender fanoutSender; @Test public void setFanoutSender() { fanoutSender.send(); }} 结果 12fanout Receiver B : hi, fanout msg fanout Receiver A : hi, fanout msg Routing 在前面的Fanout模式下，消息会直接广播给queue。如果我们想让consumer处理某些特定的消息，就要让他接收消息的队列中没有其他类型的消息，所以能不能让queue只接收某些消息，而不接收另一些消息呢？ RabbitMQ 中有一个 Routingkey 的概念。在队列与交换机的绑定过程中添加Routingkey表示queue接收的消息需要带有Routingkey。 Topic Topic模式和Direct模式类似，Direct模式需要Routingkey完全匹配而Topic模式更加灵活，可以通过通配符进行配置。 在这种交换机模式下：路由键必须是一串字符，用句号（.） 隔开，例如：topic.A 路由模式必须包含一个星号*，主要用于匹配路由键指定位置的一个单词，比如说，一个路由模式是这样子：agreements..b.*，那么就只能匹配路由键是这样子的：第一个单词是 agreements，第四个单词是 b。 井号（#）就表示相当于一个或者多个单词；例如一个匹配模式是agreements.eu.berlin.#，那么，以agreements.eu.berlin开头的路由键都是可以的。 Queue and exchange 另个队列分别为 topic.A,topic.B,将他们绑定到 topicExchange 上。并且设置了规则，topic.A 必须是完全匹配的也就是Direct模式，topic.B 使用Topic模式，只要是Rouctingkey为 topic 开头的都可以接收。 12345678910111213141516171819202122232425262728293031@Configurationpublic class TopicConfig { final static String message = \"topic.A\"; final static String messages = \"topic.B\"; @Bean public Queue queueMessage() { return new Queue(TopicConfig.message); } @Bean public Queue queueMessages() { return new Queue(TopicConfig.messages); } @Bean TopicExchange exchange() { return new TopicExchange(\"topicExchange\"); } @Bean Binding bindingExchangeMessage(Queue queueMessage, TopicExchange exchange) { return BindingBuilder.bind(queueMessage).to(exchange).with(\"topic.message\"); } @Bean Binding bindingExchangeMessages(Queue queueMessages, TopicExchange exchange) { return BindingBuilder.bind(queueMessages).to(exchange).with(\"topic.#\"); }} 生产者 1234567891011121314151617181920212223@Controllerpublic class TopicSend { @Autowired private AmqpTemplate rabbitTemplate; public void send() { String context = \"hi, i am message 0\"; System.out.println(\"Sender : \" + context); this.rabbitTemplate.convertAndSend(\"topicExchange\", \"topic.1\", context); } public void send1() { String context = \"hi, i am message 1\"; System.out.println(\"Sender : \" + context); this.rabbitTemplate.convertAndSend(\"topicExchange\", \"topic.message\", context); } public void send2() { String context = \"hi, i am messages 2\"; System.out.println(\"Sender : \" + context); this.rabbitTemplate.convertAndSend(\"topicExchange\", \"topic.messages\", context); }} 消费者 1234567891011121314151617@Component@RabbitListener(queues = \"topic.A\")public class TopicReceiver { @RabbitHandler public void process(String message) { System.out.println(\"Topic Receiver1 : \" + message); }}@Component@RabbitListener(queues = \"topic.B\")public class TopicReceiver2 { @RabbitHandler public void process(String message) { System.out.println(\"Topic Receiver2 : \" + message); }} 测试 123456789101112131415161718192021@RunWith(SpringRunner.class)@SpringBootTest(classes = Startup.class)public class TopicTest { @Autowired private TopicSend sender; @Test public void topic() throws Exception { sender.send(); } @Test public void topic1() throws Exception { sender.send1(); } @Test public void topic2() throws Exception { sender.send2(); }} 结果 1234567Sender : hi, i am message 1Sender : hi, i am messages 2Sender : hi, i am message 0Topic Receiver1 : hi, i am message 1Topic Receiver2 : hi, i am message 1Topic Receiver2 : hi, i am messages 2Topic Receiver2 : hi, i am message 0 总结掌握 RabbitMQ 的核心在于如何使用好exchanges，它有默认模式&quot;&quot; , direct , topic , headers 和 fanout 这几种模式。 通过 RabbitMQ 的 routingkey 可以过滤交换机传递给队列的消息。fanout 模式下，需要队列和交换机的routingkey完全匹配，而在topic模式下，可以通过通配符进行配置，变得更加灵活。 安装参考：Install RabbitMQ server in CentOS 7 CentOS 7 下安装 RabbitMQ Install Erlang and Elixir in CentOS 7 rabbitmq——用户管理 Springboot 集成 RabbitMQ 参考RabbitMQ Tutorials Spring Boot 中使用 RabbitMQ springboot rabbitmq整合 Spring Boot系列(八)：RabbitMQ详解","link":"/post/29003c34.html"}],"tags":[{"name":"c","slug":"c","link":"/tags/c/"},{"name":"c++","slug":"c","link":"/tags/c/"},{"name":"java","slug":"java","link":"/tags/java/"},{"name":"protobuf","slug":"protobuf","link":"/tags/protobuf/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"文件传输","slug":"文件传输","link":"/tags/文件传输/"},{"name":"ubuntu","slug":"ubuntu","link":"/tags/ubuntu/"},{"name":"ssh","slug":"ssh","link":"/tags/ssh/"},{"name":"分布式","slug":"分布式","link":"/tags/分布式/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"numpy","slug":"numpy","link":"/tags/numpy/"},{"name":"opencv","slug":"opencv","link":"/tags/opencv/"},{"name":"zookeeper","slug":"zookeeper","link":"/tags/zookeeper/"},{"name":"网站","slug":"网站","link":"/tags/网站/"},{"name":"工具","slug":"工具","link":"/tags/工具/"},{"name":"电影","slug":"电影","link":"/tags/电影/"},{"name":"mybatis","slug":"mybatis","link":"/tags/mybatis/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"anaconda","slug":"anaconda","link":"/tags/anaconda/"},{"name":"springboot","slug":"springboot","link":"/tags/springboot/"},{"name":"并发编程","slug":"并发编程","link":"/tags/并发编程/"},{"name":"消息队列","slug":"消息队列","link":"/tags/消息队列/"},{"name":"剑指 offer","slug":"剑指-offer","link":"/tags/剑指-offer/"},{"name":"算法和数据结构","slug":"算法和数据结构","link":"/tags/算法和数据结构/"},{"name":"maven","slug":"maven","link":"/tags/maven/"},{"name":"RocketMQ","slug":"RocketMQ","link":"/tags/RocketMQ/"},{"name":"MQ","slug":"MQ","link":"/tags/MQ/"},{"name":"RabbitMQ","slug":"RabbitMQ","link":"/tags/RabbitMQ/"}],"categories":[{"name":"C/C++","slug":"C-C","link":"/categories/C-C/"},{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"Linux","slug":"Linux","link":"/categories/Linux/"},{"name":"Python","slug":"Python","link":"/categories/Python/"},{"name":"OpenCV","slug":"OpenCV","link":"/categories/OpenCV/"},{"name":"分布式","slug":"分布式","link":"/categories/分布式/"},{"name":"工具癖","slug":"工具癖","link":"/categories/工具癖/"},{"name":"每周一书","slug":"每周一书","link":"/categories/每周一书/"},{"name":"算法与数据结构","slug":"算法与数据结构","link":"/categories/算法与数据结构/"}]}