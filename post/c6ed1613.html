<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  
  <title>【TensorFlow2.0】手撕前向传播算法 | 深页</title>
  
  

  
  <link rel="alternate" href="/atom.xml" title="深页">
  

  <meta name="HandheldFriendly" content="True">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <!-- meta -->
  

  <!-- link -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.css">
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.10.1/css/all.min.css">
  

  

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-material-x@19.9.9/css/style.css">
  

  <script>
    function setLoadingBarProgress(num) {
      document.getElementById('loading-bar').style.width=num+"%";
    }
  </script>

  
  
</head>

<body>
  
  
  <div class="cover-wrapper">
    <cover class="cover post half">
      
        
  <h1 class="title">弄浪的鱼</h1>


  <div class="m_search">
    <form name="searchform" class="form u-search-form">
      <input type="text" class="input u-search-input" placeholder>
      <i class="icon fas fa-search fa-fw"></i>
    </form>
  </div>

<div class="menu navgation">
  <ul class="h-list">
    
  </ul>
</div>

      
    </cover>
    <header class="l_header pure">
  <div id="loading-bar-wrapper">
    <div id="loading-bar" class="pure"></div>
  </div>

	<div class="wrapper">
		<div class="nav-main container container--flex">
      <a class="logo flat-box" href="/">
        
          深页
        
      </a>
			<div class="menu navgation">
				<ul class="h-list">
          
  					
  						<li>
								<a class="nav flat-box" href="/" id="home">
									<i class="fas fa-grin fa-fw"></i>&nbsp;首页
								</a>
							</li>
      			
  						<li>
								<a class="nav flat-box" href="/blog/categories/" rel="nofollow" id="blogcategories">
									<i class="fas fa-folder-open fa-fw"></i>&nbsp;分类
								</a>
							</li>
      			
  						<li>
								<a class="nav flat-box" href="/blog/tags/" rel="nofollow" id="blogtags">
									<i class="fas fa-hashtag fa-fw"></i>&nbsp;标签
								</a>
							</li>
      			
  						<li>
								<a class="nav flat-box" href="/blog/archives/" rel="nofollow" id="blogarchives">
									<i class="fas fa-archive fa-fw"></i>&nbsp;归档
								</a>
							</li>
      			
      		
				</ul>
			</div>

			
				<div class="m_search">
					<form name="searchform" class="form u-search-form">
						<input type="text" class="input u-search-input" placeholder="搜索">
						<i class="icon fas fa-search fa-fw"></i>
					</form>
				</div>
			
			<ul class="switcher h-list">
				
					<li class="s-search"><a class="fas fa-search fa-fw" href="javascript:void(0)"></a></li>
				
				<li class="s-menu"><a class="fas fa-bars fa-fw" href="javascript:void(0)"></a></li>
			</ul>
		</div>

		<div class="nav-sub container container--flex">
			<a class="logo flat-box"></a>
			<ul class="switcher h-list">
				<li class="s-comment"><a class="flat-btn fas fa-comments fa-fw" href="javascript:void(0)"></a></li>
        
          <li class="s-toc"><a class="flat-btn fas fa-list fa-fw" href="javascript:void(0)"></a></li>
        
			</ul>
		</div>
	</div>
</header>
	<aside class="menu-phone">
    <header>
		<nav class="menu navgation">
      <ul>
        
          
            <li>
							<a class="nav flat-box" href="/" id="home">
								<i class="fas fa-clock fa-fw"></i>&nbsp;近期文章
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="/blog/archives/" rel="nofollow" id="blogarchives">
								<i class="fas fa-archive fa-fw"></i>&nbsp;文章归档
							</a>
            </li>
          
       
      </ul>
		</nav>
    </header>
	</aside>
<script>setLoadingBarProgress(40);</script>

  </div>


  <div class="l_body">
    <div class='body-wrapper'>
      <div class="l_main">
  

  <article id="post" class="post white-box article-type-post" itemscope itemprop="blogPost">
    


  <section class="meta">
    
    
    <div class="meta" id="header-meta">
      
        
  
    <h1 class="title">
      <a href="/post/c6ed1613.html">
        【TensorFlow2.0】手撕前向传播算法
      </a>
    </h1>
  


      
      <div class="new-meta-box">
        
          
        
          
            
  <div class="new-meta-item author">
    
      <a href="http://shuiyujie.com" rel="nofollow">
        
          <i class="fas fa-user" aria-hidden="true"></i>
        
        <p>深页</p>
      </a>
    
  </div>


          
        
          
            <div class="new-meta-item date">
  <a class="notlink">
    <i class="fas fa-calendar-alt" aria-hidden="true"></i>
    <p>2019-09-05</p>
  </a>
</div>

          
        
          
            
  
  <div class="new-meta-item category">
    <a href="/categories/DeepLearning/" rel="nofollow">
      <i class="fas fa-folder-open" aria-hidden="true"></i>
      <p>DeepLearning</p>
    </a>
  </div>


          
        
          
            
  
    <div class="new-meta-item browse busuanzi">
      <a class="notlink">
        <i class="fas fa-eye" aria-hidden="true"></i>
        <p>
          <span id="busuanzi_value_page_pv">
            <i class="fas fa-spinner fa-spin fa-fw" aria-hidden="true"></i>
          </span>
        </p>
      </a>
    </div>
  


          
        
          
            

          
        
      </div>
      
        <hr>
      
    </div>
  </section>


    <section class="article typo">
      <div class="article-entry" itemprop="articleBody">
        <p><img src="https://image.shuiyujie.com/tensorflow2_coming_soon" alt="TensorFlow2.0"></p>
<p>本文介绍如何使用 TensorFlow2.0 实现前向传播,先介绍用 TensorFlow 普通的 API 来实现前向传播,将会介绍:如何加载数据集,如何完成参数初始化和构建前向传播网络,如何计算 accuracy.</p>
<p>由于神经网络的训练流程大同小异,就可以使用 tf.keras 封装的 API 来简化模型训练和测试的流程.本文第二部分将会介绍如何使用 tf.keras 来定义神经网络以及优化器,如何用<code>tf.keras.metrics</code>来计算 accuracy 和 loss.</p>
<a id="more"></a>
<h1 id="安装-TensorFlow2-0"><a href="#安装-TensorFlow2-0" class="headerlink" title="安装 TensorFlow2.0"></a>安装 TensorFlow2.0</h1><p>本文的开发环境是 Ubuntu16.04 + CUDA10 + Anaconda + TensorFlow2.0，目前 conda 不支持安装 TensorFlow2.0 的包，所以需要用 pip 来安装 TensorFlow2.0。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install tensorflow-gpu==2.0.0-rc0 numpy matplotlib pandas -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure>
<p>截止到现在，TensorFlow 发布了最新的 rc 版本，与以后的正式发行版差别不大了。</p>
<h1 id="完成一次前向传播"><a href="#完成一次前向传播" class="headerlink" title="完成一次前向传播"></a>完成一次前向传播</h1><p><img src="https://image.shuiyujie.com/mnist_front_forward.gif" alt="mnist前向传播"></p>
<h2 id="如何加载数据集"><a href="#如何加载数据集" class="headerlink" title="如何加载数据集"></a>如何加载数据集</h2><ul>
<li>第1步: 使用 keras.datasets 加载 mnist 数据集,将会返回两组数据</li>
<li>第2步: 将 Numpy 类型的数据转换为 tensor</li>
<li>第3步: 将 tensor 转换为 datasets</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 需要引入的包</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置 TensorFlow 的日志级别,避免输出过多提示信息</span></span><br><span class="line">os.environ[<span class="string">'TF_CPP_MIN_LOG_LEVEL'</span>] = <span class="string">'2'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 第1步: 使用 keras.datasets 加载 mnist 数据集,将会返回两组数据</span></span><br><span class="line"><span class="comment"># x: [60000,28,28], x_test:[10000,28,28]</span></span><br><span class="line"><span class="comment"># y: [60000], y_test:[10000]</span></span><br><span class="line">(x, y), (x_text, y_text) = datasets.mnist.load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第2步: 将 Numpy 类型的数据转换为 tensor</span></span><br><span class="line"><span class="comment"># keras.datasets 加载到的是 Numpy 类型的数据,将其转换为 tensor</span></span><br><span class="line"><span class="comment"># convert to tensor</span></span><br><span class="line"><span class="comment"># x:[0~255] =&gt; [0~1]</span></span><br><span class="line">x = tf.convert_to_tensor(x, dtype=tf.float32) / <span class="number">255.</span></span><br><span class="line">y = tf.convert_to_tensor(y, dtype=tf.int32)</span><br><span class="line"></span><br><span class="line">x_text = tf.convert_to_tensor(x_text, dtype=tf.float32) / <span class="number">255.</span></span><br><span class="line">y_text = tf.convert_to_tensor(y_text, dtype=tf.int32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看数据分布情况,shape,dype,min,max</span></span><br><span class="line">print(x.shape, y.shape, x.dtype, y.dtype)</span><br><span class="line">print(tf.reduce_min(x), tf.reduce_max(y))</span><br><span class="line">print(tf.reduce_min(y), tf.reduce_max(y))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第3步: 将 tensor 转换为 datasets</span></span><br><span class="line"><span class="comment"># tensorflow 推荐使用 tf.data.Dataset 来加载数据集</span></span><br><span class="line"><span class="comment"># tensor =&gt; datasets</span></span><br><span class="line"><span class="comment"># 128个为一个batch返回datasets</span></span><br><span class="line">train_db = tf.data.Dataset.from_tensor_slices((x,y)).batch(<span class="number">128</span>)</span><br><span class="line">test_db = tf.data.Dataset.from_tensor_slices((x_text,y_text)).batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">train_iter = iter(train_db)</span><br><span class="line">sample = next(train_iter)</span><br><span class="line">print(<span class="string">"batch:"</span>, sample[<span class="number">0</span>].shape, sample[<span class="number">1</span>].shape)</span><br></pre></td></tr></table></figure>
<h2 id="前向传播参数初始化"><a href="#前向传播参数初始化" class="headerlink" title="前向传播参数初始化"></a>前向传播参数初始化</h2><p>前面创建的 train_db 是 shape = [128, 28, 28],表示 128 张 28x28 的灰度图像.在输入的时候我将其展开成 shape = [128, 28*28],接着用全连接层降维到 shape = 10 的 tensor,对应 mnist 共 10 类的标签.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># [b, 784] =&gt; [b, 256] =&gt; [b, 128] =&gt; [b, 10]</span></span><br><span class="line"><span class="comment"># w:[dim_in, dim_out]; b:[dim_out]</span></span><br><span class="line">w1 = tf.Variable(tf.random.truncated_normal([<span class="number">784</span>, <span class="number">256</span>], stddev=<span class="number">0.1</span>))</span><br><span class="line">b1 = tf.Variable(tf.zeros([<span class="number">256</span>]))</span><br><span class="line">w2 = tf.Variable(tf.random.truncated_normal([<span class="number">256</span>, <span class="number">128</span>], stddev=<span class="number">0.1</span>))</span><br><span class="line">b2 = tf.Variable(tf.zeros([<span class="number">128</span>]))</span><br><span class="line">w3 = tf.Variable(tf.random.truncated_normal([<span class="number">128</span>, <span class="number">10</span>], stddev=<span class="number">0.1</span>))</span><br><span class="line">b3 = tf.Variable(tf.zeros([<span class="number">10</span>]))</span><br></pre></td></tr></table></figure>
<h2 id="前向传播-amp-自动求导"><a href="#前向传播-amp-自动求导" class="headerlink" title="前向传播 &amp; 自动求导"></a>前向传播 &amp; 自动求导</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 学习率</span></span><br><span class="line">lr = <span class="number">1e-3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># train_db 将会被计算 10 次</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">10</span>): <span class="comment"># iterate db for 10</span></span><br><span class="line">    <span class="comment"># 遍历 train_db</span></span><br><span class="line">    <span class="keyword">for</span> step, (x, y) <span class="keyword">in</span> enumerate(train_db, <span class="number">1</span>):</span><br><span class="line">        <span class="comment"># x:[128,28,28]</span></span><br><span class="line">        <span class="comment"># y:[128]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将28x28的张量展开成784</span></span><br><span class="line">        <span class="comment"># x:[128,28,28] =&gt; [128,784]</span></span><br><span class="line">        x = tf.reshape(x, [<span class="number">-1</span>,<span class="number">28</span>*<span class="number">28</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 使用 tf.GradientTape() 自动求导</span></span><br><span class="line">        <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">            <span class="comment"># 构建前向传播的网络</span></span><br><span class="line">            <span class="comment"># x:[b,28*28]</span></span><br><span class="line">            <span class="comment"># h1 = x@w1+b1</span></span><br><span class="line">            <span class="comment"># [b,784]@[784,256]+[256] =&gt; [b,256] + [256] =&gt; []</span></span><br><span class="line">            h1 = tf.nn.relu(x@w1 + b1)</span><br><span class="line">            h2 = tf.nn.relu(h1@w2 + b2)</span><br><span class="line">            out = h2@w3 + b3</span><br><span class="line">			</span><br><span class="line">            <span class="comment"># y 使用 one_hot 编码,与神经网络的输出对应</span></span><br><span class="line">            <span class="comment"># y: [b] =&gt; [b, 10]</span></span><br><span class="line">            y_onehot = tf.one_hot(y, depth=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 计算均方误差 mse = mean(sum(y-out)^2)</span></span><br><span class="line">            <span class="comment"># loss:[b,10]</span></span><br><span class="line">            loss = tf.square(y_onehot-out)</span><br><span class="line">            <span class="comment"># 求误差的请平均值</span></span><br><span class="line">            <span class="comment"># loss:[b,10] =&gt; scalar</span></span><br><span class="line">            loss = tf.reduce_mean(loss)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 借助于 tensorflow 自动求导</span></span><br><span class="line">        grads = tape.gradient(loss, [w1, b1, w2, b2, w3, b3])</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 根据梯度更新参数</span></span><br><span class="line">        <span class="comment"># w1 = w1 - lr * w1_grad</span></span><br><span class="line">        w1.assign_sub(lr * grads[<span class="number">0</span>])</span><br><span class="line">        b1.assign_sub(lr * grads[<span class="number">1</span>])</span><br><span class="line">        w2.assign_sub(lr * grads[<span class="number">2</span>])</span><br><span class="line">        b2.assign_sub(lr * grads[<span class="number">3</span>])</span><br><span class="line">        w3.assign_sub(lr * grads[<span class="number">4</span>])</span><br><span class="line">        b3.assign_sub(lr * grads[<span class="number">5</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 每迭代100次输出一次loss</span></span><br><span class="line">        <span class="keyword">if</span> step % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            print(epoch+<span class="number">1</span>, (epoch+<span class="number">1</span>)*step, <span class="string">'loss:'</span>, float(loss))</span><br></pre></td></tr></table></figure>
<h2 id="计算准确率-accuracy"><a href="#计算准确率-accuracy" class="headerlink" title="计算准确率 accuracy"></a>计算准确率 accuracy</h2><p>我们需要通过模型的准确率来评估模型,模型评估需要在 test_db 上进行.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">total_number = <span class="number">0</span></span><br><span class="line">   total_correct = <span class="number">0</span></span><br><span class="line">   <span class="comment"># 遍历 test_db</span></span><br><span class="line">   <span class="keyword">for</span> step, (x, y) <span class="keyword">in</span> enumerate(test_db):</span><br><span class="line">	</span><br><span class="line">       <span class="comment"># [b, 28, 28] =&gt; [b, 28*28]</span></span><br><span class="line">       x = tf.reshape(x,[<span class="number">-1</span>,<span class="number">28</span>*<span class="number">28</span>])</span><br><span class="line">       </span><br><span class="line">       <span class="comment"># 利用最新的参数完成一次前向传播</span></span><br><span class="line">       <span class="comment"># [b, 784] =&gt; [b, 256] =&gt; [b, 128] =&gt; [b, 10]</span></span><br><span class="line">       h1 = tf.nn.relu(x@w1 + b1)</span><br><span class="line">       h2 = tf.nn.relu(h1@w2 + b2)</span><br><span class="line">       out = h2@w3 + b3</span><br><span class="line"></span><br><span class="line">       <span class="comment"># 使用 softmax() 输出每个分类的概率值</span></span><br><span class="line">       <span class="comment"># [b, 10] ~ R</span></span><br><span class="line">       <span class="comment"># [b, 10] ~ [0,1]</span></span><br><span class="line">       prob = tf.nn.softmax(out, axis=<span class="number">1</span>)</span><br><span class="line">       </span><br><span class="line">       <span class="comment"># 概率最大的值就是模型的预测值</span></span><br><span class="line">       <span class="comment"># [b, 10] =&gt; [b]</span></span><br><span class="line">       preb = tf.argmax(prob, axis=<span class="number">1</span>)</span><br><span class="line">       preb = tf.cast(preb, dtype=tf.int32)</span><br><span class="line">       </span><br><span class="line">       <span class="comment"># 预测值与真实值比较</span></span><br><span class="line">       <span class="comment"># [b] int32</span></span><br><span class="line">       <span class="comment"># print(y.dtype, preb.dtype)</span></span><br><span class="line">       correct = tf.cast(tf.equal(y, preb), dtype=tf.int32)</span><br><span class="line">       correct = tf.reduce_sum(correct)</span><br><span class="line">       total_correct += int(correct)</span><br><span class="line">       total_number += x.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">   acc = total_correct / total_number</span><br><span class="line">   print(<span class="string">"accuracy:"</span>, acc)</span><br></pre></td></tr></table></figure>
<h1 id="前向传播过程优化"><a href="#前向传播过程优化" class="headerlink" title="前向传播过程优化"></a>前向传播过程优化</h1><p><img src="https://image.shuiyujie.com/mnist_in_csv.png" alt="mnist in csv"></p>
<h2 id="构建数据集时添加数据预处理"><a href="#构建数据集时添加数据预处理" class="headerlink" title="构建数据集时添加数据预处理"></a>构建数据集时添加数据预处理</h2><p>Tensorflow 鼓励使用 <code>tf.data.Dataset</code>加载数据集,它给我封装了许多处理数据集的方法,比如<code>train_db = train_db.map(preprocess).shuffle(60000).batch(128)</code></p>
<p>在<code>preprocess(x,y)</code>中进行数据预处理,利用<code>map(preprocess)</code>调用预处理函数,再用<code>shuffle()</code>随机成对打乱数据集,最后用<code>batch()</code>将数据集按照 128 一份来分隔.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess</span><span class="params">(x, y)</span>:</span></span><br><span class="line">    <span class="comment"># 数据预处理,归一化,类型转换</span></span><br><span class="line">    x = tf.cast(x, dtype=tf.float32) / <span class="number">255.</span></span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line">    <span class="keyword">return</span> x,y</span><br><span class="line"></span><br><span class="line"><span class="comment"># x: [60000,28,28], x_test:[10000,28,28]</span></span><br><span class="line"><span class="comment"># y: [60000], y_test:[10000]</span></span><br><span class="line">(x, y), (x_text, y_text) = datasets.mnist.load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># tensor =&gt; datasets</span></span><br><span class="line">train_db = tf.data.Dataset.from_tensor_slices((x,y))</span><br><span class="line">train_db = train_db.map(preprocess).shuffle(<span class="number">60000</span>).batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">test_db = tf.data.Dataset.from_tensor_slices((x_text,y_text))</span><br><span class="line">test_db = test_db.map(preprocess).shuffle(<span class="number">10000</span>).batch(<span class="number">128</span>)</span><br></pre></td></tr></table></figure>
<h2 id="使用-tf-keras-来构建模型"><a href="#使用-tf-keras-来构建模型" class="headerlink" title="使用 tf.keras 来构建模型"></a>使用 tf.keras 来构建模型</h2><p>TensorFlow2.0 降低了使用者的门槛,利用 <code>tf.keras</code> 可以直接使用 Keras 的一系列 API,这样就可以更加方便地定义模型,比如说前面定义参数 [w,b] 的过程就可以简化成下面这样</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用 Sequential 构建 3 层的全连接</span></span><br><span class="line">network = Sequential([layers.Dense(<span class="number">256</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">            layers.Dense(<span class="number">128</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">            layers.Dense(<span class="number">10</span>)</span><br><span class="line">            ])</span><br><span class="line"></span><br><span class="line"><span class="comment"># build 并制定 input</span></span><br><span class="line">network.build(input_shape=[<span class="keyword">None</span>, <span class="number">28</span>*<span class="number">28</span>])</span><br><span class="line"><span class="comment"># 查看模型参数</span></span><br><span class="line">network.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定优化器</span></span><br><span class="line">optimizer = optimizers.Adam(lr=<span class="number">0.01</span>)</span><br></pre></td></tr></table></figure>
<h2 id="使用-metrics-自动计算-loss-和-accuracy"><a href="#使用-metrics-自动计算-loss-和-accuracy" class="headerlink" title="使用 metrics 自动计算 loss 和 accuracy"></a>使用 metrics 自动计算 loss 和 accuracy</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Step1.Build a meter</span></span><br><span class="line">acc_meter = metrics.Accuracy()</span><br><span class="line">loss_meter = metrics.Mean()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">10</span>): <span class="comment"># iterate db for 10</span></span><br><span class="line">    <span class="keyword">for</span> step, (x, y) <span class="keyword">in</span> enumerate(train_db, <span class="number">1</span>):</span><br><span class="line">        </span><br><span class="line">        x = tf.reshape(x, [<span class="number">-1</span>,<span class="number">28</span>*<span class="number">28</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">         </span><br><span class="line">            <span class="comment"># [b,784] =&gt; [b,10]</span></span><br><span class="line">            out = network(x)</span><br><span class="line">            y_onehot = tf.one_hot(y, depth=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">            loss = tf.reduce_mean(tf.losses.categorical_crossentropy(y_onehot, out, from_logits=<span class="keyword">True</span>))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Step2.Update data</span></span><br><span class="line">            loss_meter.update_state(loss)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># compute gradients</span></span><br><span class="line">        <span class="comment"># grads = tape.gradient(loss, [w1, b1, w2, b2, w3, b3])</span></span><br><span class="line">        grads = tape.gradient(loss, network.trainable_variables)</span><br><span class="line">        optimizer.apply_gradients(zip(grads, network.trainable_variables))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> step % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="comment"># Step3.Get Average data</span></span><br><span class="line">            print(step, <span class="string">'loss:'</span>, loss_meter.result().numpy())</span><br><span class="line">            <span class="comment"># Clear buffer</span></span><br><span class="line">            loss_meter.reset_states()</span><br><span class="line"></span><br><span class="line">    total_number = <span class="number">0</span></span><br><span class="line">    total_correct = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> step, (x, y) <span class="keyword">in</span> enumerate(test_db):</span><br><span class="line">        acc_meter.reset_states()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># [b, 28, 28] =&gt; [b, 28*28]</span></span><br><span class="line">        x = tf.reshape(x,[<span class="number">-1</span>,<span class="number">28</span>*<span class="number">28</span>])</span><br><span class="line">        <span class="comment"># [b, 784] =&gt; [b, 256] =&gt; [b, 128] =&gt; [b, 10]</span></span><br><span class="line">        <span class="comment"># h1 = tf.nn.relu(x@w1 + b1)</span></span><br><span class="line">        <span class="comment"># h2 = tf.nn.relu(h1@w2 + b2)</span></span><br><span class="line">        <span class="comment"># out = h2@w3 + b3</span></span><br><span class="line">        </span><br><span class="line">		<span class="comment"># 输出调用 network 就可以获得</span></span><br><span class="line">        out = network(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># [b, 10] ~ R</span></span><br><span class="line">        <span class="comment"># [b, 10] ~ [0,1]</span></span><br><span class="line">        prob = tf.nn.softmax(out, axis=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># [b, 10] =&gt; [b]</span></span><br><span class="line">        pred = tf.argmax(prob, axis=<span class="number">1</span>)</span><br><span class="line">        pred = tf.cast(pred, dtype=tf.int32)</span><br><span class="line">        <span class="comment"># [b] int32</span></span><br><span class="line">        <span class="comment"># print(y.dtype, preb.dtype)</span></span><br><span class="line">        <span class="comment"># correct = tf.cast(tf.equal(y, pred), dtype=tf.int32)</span></span><br><span class="line">        <span class="comment"># correct = tf.reduce_sum(correct)</span></span><br><span class="line">        <span class="comment"># total_correct += int(correct)</span></span><br><span class="line">        <span class="comment"># total_number += x.shape[0]</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># metrics 能快速计算 acc 和 loss</span></span><br><span class="line">        acc_meter.update_state(y, pred)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># acc = total_correct / total_number</span></span><br><span class="line">    print(step, <span class="string">'Evaluate Acc:'</span>, acc_meter.result().numpy())</span><br></pre></td></tr></table></figure>
<h2 id="tf-keras-版"><a href="#tf-keras-版" class="headerlink" title="tf.keras 版"></a>tf.keras 版</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">'TF_CPP_MIN_LOG_LEVEL'</span>] = <span class="string">'2'</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess</span><span class="params">(x, y)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    x is a simple image, not a batch</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    x = tf.cast(x, dtype=tf.float32) / <span class="number">255.</span></span><br><span class="line">    x = tf.reshape(x, [<span class="number">28</span>*<span class="number">28</span>])</span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line">    y = tf.one_hot(y, depth=<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">return</span> x,y</span><br><span class="line"></span><br><span class="line"><span class="comment"># x: [60000,28,28], x_test:[10000,28,28]</span></span><br><span class="line"><span class="comment"># y: [60000], y_test:[10000]</span></span><br><span class="line">(x, y), (x_text, y_text) = datasets.mnist.load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># tensor =&gt; datasets</span></span><br><span class="line">train_db = tf.data.Dataset.from_tensor_slices((x,y))</span><br><span class="line">train_db = train_db.map(preprocess).shuffle(<span class="number">60000</span>).batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">test_db = tf.data.Dataset.from_tensor_slices((x_text,y_text))</span><br><span class="line">test_db = test_db.map(preprocess).shuffle(<span class="number">10000</span>).batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 tf.Sequential 定义上面的这些参数</span></span><br><span class="line">network = Sequential([layers.Dense(<span class="number">256</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">            layers.Dense(<span class="number">128</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">            layers.Dense(<span class="number">10</span>)</span><br><span class="line">            ])</span><br><span class="line"></span><br><span class="line">network.build(input_shape=(<span class="keyword">None</span>, <span class="number">28</span>*<span class="number">28</span>))</span><br><span class="line">network.summary()</span><br><span class="line"></span><br><span class="line">network.compile(optimizer=optimizers.Adam(lr=<span class="number">0.01</span>),</span><br><span class="line">                loss=tf.losses.CategoricalCrossentropy(from_logits=<span class="keyword">True</span>),</span><br><span class="line">                metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"></span><br><span class="line">network.fit(train_db, epochs=<span class="number">10</span>, validation_data=test_db, validation_freq=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">network.evaluate(test_db)</span><br><span class="line"></span><br><span class="line">sample = next(iter(ds_val))</span><br><span class="line">x = sample[<span class="number">0</span>]</span><br><span class="line">y = sample[<span class="number">1</span>] <span class="comment"># one-hot</span></span><br><span class="line">pred = network.predict(x) <span class="comment"># [b, 10]</span></span><br><span class="line"><span class="comment"># convert back to number</span></span><br><span class="line">y = tf.argmax(y, axis=<span class="number">1</span>)</span><br><span class="line">pred = tf.argmax(pred, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">print(pred)</span><br><span class="line">print(y)</span><br></pre></td></tr></table></figure>

      </div>
      
        <br>
        


  <section class="meta" id="footer-meta">
    <div class="new-meta-box">
      
        
          <div class="new-meta-item date" itemprop="dateUpdated" datetime="2019-09-30T22:48:01+08:00">
  <a class="notlink">
    <i class="fas fa-clock" aria-hidden="true"></i>
    <p>更新于 2019年9月30日</p>
  </a>
</div>

        
      
        
          
  
  <div class="new-meta-item meta-tags"><a class="tag" href="/tags/deeplearning/" rel="nofollow"><i class="fas fa-tag" aria-hidden="true"></i><p>deeplearning</p></a></div> <div class="new-meta-item meta-tags"><a class="tag" href="/tags/tensorflow/" rel="nofollow"><i class="fas fa-tag" aria-hidden="true"></i><p>tensorflow</p></a></div>


        
      
        
          
  <div class="new-meta-item share -mob-share-list">
  <div class="-mob-share-list share-body">
    
      
        <a class="-mob-share-qq" title="QQ好友" rel="external nofollow noopener noreferrer" href="http://connect.qq.com/widget/shareqq/index.html?url=http://shuiyujie.com/post/c6ed1613.html&title=【TensorFlow2.0】手撕前向传播算法 | 深页&summary=
本文介绍如何使用 TensorFlow2.0 实现前向传播,先介绍用 TensorFlow 普通的 API 来实现前向传播,将会介绍:如何加载数据集,如何完成参数初始化和构建前向传播网络,如何计算 accuracy.
由于神经网络的训练流程大同小异,就可以使用 tf.keras 封装的 API 来简化模型训练和测试的流程.本文第二部分将会介绍如何使用 tf.keras 来定义神经网络以及优化器,如何用tf.keras.metrics来计算 accuracy 和 loss.">
          
            <img src="https://cdn.jsdelivr.net/gh/xaoxuu/assets@19.1.9/logo/128/qq.png">
          
        </a>
      
    
      
        <a class="-mob-share-qzone" title="QQ空间" rel="external nofollow noopener noreferrer" href="https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=http://shuiyujie.com/post/c6ed1613.html&title=【TensorFlow2.0】手撕前向传播算法 | 深页&summary=
本文介绍如何使用 TensorFlow2.0 实现前向传播,先介绍用 TensorFlow 普通的 API 来实现前向传播,将会介绍:如何加载数据集,如何完成参数初始化和构建前向传播网络,如何计算 accuracy.
由于神经网络的训练流程大同小异,就可以使用 tf.keras 封装的 API 来简化模型训练和测试的流程.本文第二部分将会介绍如何使用 tf.keras 来定义神经网络以及优化器,如何用tf.keras.metrics来计算 accuracy 和 loss.">
          
            <img src="https://cdn.jsdelivr.net/gh/xaoxuu/assets@19.1.9/logo/128/qzone.png">
          
        </a>
      
    
      
        <a class="-mob-share-weibo" title="微博" rel="external nofollow noopener noreferrer" href="http://service.weibo.com/share/share.php?url=http://shuiyujie.com/post/c6ed1613.html&title=【TensorFlow2.0】手撕前向传播算法 | 深页&summary=
本文介绍如何使用 TensorFlow2.0 实现前向传播,先介绍用 TensorFlow 普通的 API 来实现前向传播,将会介绍:如何加载数据集,如何完成参数初始化和构建前向传播网络,如何计算 accuracy.
由于神经网络的训练流程大同小异,就可以使用 tf.keras 封装的 API 来简化模型训练和测试的流程.本文第二部分将会介绍如何使用 tf.keras 来定义神经网络以及优化器,如何用tf.keras.metrics来计算 accuracy 和 loss.">
          
            <img src="https://cdn.jsdelivr.net/gh/xaoxuu/assets@19.1.9/logo/128/weibo.png">
          
        </a>
      
    
  </div>
</div>



        
      
    </div>
  </section>


      
      
          <div class="prev-next">
              
                  <section class="prev">
                      <span class="art-item-left">
                          <h6><i class="fas fa-chevron-left" aria-hidden="true"></i>&nbsp;上一页</h6>
                          <h4>
                              <a href="/post/3a297e7b.html" rel="prev" title="【TensorFlow2.0】实现ResNet">
                                
                                    【TensorFlow2.0】实现ResNet
                                
                              </a>
                          </h4>
                          
                              
                              <h6 class="tags">
                                  <a class="tag" href="/tags/deeplearning/"><i class="fas fa-tag fa-fw" aria-hidden="true"></i> deeplearning</a> <a class="tag" href="/tags/tensorflow/"><i class="fas fa-tag fa-fw" aria-hidden="true"></i> tensorflow</a>
                              </h6>
                          
                      </span>
                  </section>
              
              
                  <section class="next">
                      <span class="art-item-right" aria-hidden="true">
                          <h6>下一页&nbsp;<i class="fas fa-chevron-right" aria-hidden="true"></i></h6>
                          <h4>
                              <a href="/post/7b2629fd.html" rel="prev" title="【TensorFlow2.0】TensorFlow的安装">
                                  
                                      【TensorFlow2.0】TensorFlow的安装
                                  
                              </a>
                          </h4>
                          
                              
                              <h6 class="tags">
                                  <a class="tag" href="/tags/deeplearning/"><i class="fas fa-tag fa-fw" aria-hidden="true"></i> deeplearning</a> <a class="tag" href="/tags/tensorflow/"><i class="fas fa-tag fa-fw" aria-hidden="true"></i> tensorflow</a>
                              </h6>
                          
                      </span>
                  </section>
              
          </div>
      
    </section>
  </article>



  <!-- 显示推荐文章和评论 -->



  






<!-- 根据页面mathjax变量决定是否加载MathJax数学公式js -->



  <script>
    window.subData = {
      title: '【TensorFlow2.0】手撕前向传播算法',
      tools: true
    }
  </script>


</div>
<aside class="l_side">
  
    
    
      
      
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
      
        
          
          
            
              
  <section class="widget toc-wrapper">
    
<header class="pure">
  <div><i class="fas fa-list fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;本文目录</div>
  
    <!-- <div class='wrapper'><a class="s-toc rightBtn" rel="external nofollow noopener noreferrer" href="javascript:void(0)"><i class="fas fa-thumbtack fa-fw"></i></a></div> -->
  
</header>

    <div class="content pure">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#安装-TensorFlow2-0"><span class="toc-text">安装 TensorFlow2.0</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#完成一次前向传播"><span class="toc-text">完成一次前向传播</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#如何加载数据集"><span class="toc-text">如何加载数据集</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#前向传播参数初始化"><span class="toc-text">前向传播参数初始化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#前向传播-amp-自动求导"><span class="toc-text">前向传播 &amp; 自动求导</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#计算准确率-accuracy"><span class="toc-text">计算准确率 accuracy</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#前向传播过程优化"><span class="toc-text">前向传播过程优化</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#构建数据集时添加数据预处理"><span class="toc-text">构建数据集时添加数据预处理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#使用-tf-keras-来构建模型"><span class="toc-text">使用 tf.keras 来构建模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#使用-metrics-自动计算-loss-和-accuracy"><span class="toc-text">使用 metrics 自动计算 loss 和 accuracy</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#tf-keras-版"><span class="toc-text">tf.keras 版</span></a></li></ol></li></ol>
    </div>
  </section>


            
          
        
          
          
        
          
          
        
          
          
        
          
          
        
      
        
          
          
        
          
          
            
              <section class="widget grid">
  
<header class="pure">
  <div><i class="fas fa-map-signs fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;站内导航</div>
  
</header>

  <div class="content pure">
    <ul class="grid navgation">
      
        <li><a class="flat-box" title="/" href="/" id="home">
          
            <i class="fas fa-clock fa-fw" aria-hidden="true"></i>
          
          近期文章
        </a></li>
      
        <li><a class="flat-box" title="/blog/categories/" href="/blog/categories/" rel="nofollow" id="blogcategories">
          
            <i class="fas fa-folder fa-fw" aria-hidden="true"></i>
          
          文章分类
        </a></li>
      
        <li><a class="flat-box" title="/blog/archives/" href="/blog/archives/" rel="nofollow" id="blogarchives">
          
            <i class="fas fa-archive fa-fw" aria-hidden="true"></i>
          
          文章归档
        </a></li>
      
    </ul>
  </div>
</section>

            
          
        
          
          
        
          
          
        
          
          
        
      
        
          
          
        
          
          
        
          
          
            
              
  <section class="widget category">
    
<header class="pure">
  <div><i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;文章分类</div>
  
    <a class="rightBtn" rel="nofollow" href="/blog/categories/" title="blog/categories/">
    <i class="fas fa-expand-arrows-alt fa-fw"></i></a>
  
</header>

    <div class="content pure">
      <ul class="entry">
        
          <li><a class="flat-box" title="/categories/C-C/" href="/categories/C-C/"><div class="name">C/C++</div><div class="badge">(26)</div></a></li>
        
          <li><a class="flat-box" title="/categories/DeepLearning/" href="/categories/DeepLearning/"><div class="name">DeepLearning</div><div class="badge">(17)</div></a></li>
        
          <li><a class="flat-box" title="/categories/Docker-K8s/" href="/categories/Docker-K8s/"><div class="name">Docker&K8s</div><div class="badge">(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/Framework/" href="/categories/Framework/"><div class="name">Framework</div><div class="badge">(13)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/Framework/Mybatis/" href="/categories/Framework/Mybatis/"><div class="name">Mybatis</div><div class="badge">(2)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/Framework/Spring-Boot/" href="/categories/Framework/Spring-Boot/"><div class="name">Spring Boot</div><div class="badge">(4)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/Framework/Spring-Cloud/" href="/categories/Framework/Spring-Cloud/"><div class="name">Spring Cloud</div><div class="badge">(3)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/Framework/Spring/" href="/categories/Framework/Spring/"><div class="name">Spring</div><div class="badge">(4)</div></a></li>
        
          <li><a class="flat-box" title="/categories/Java/" href="/categories/Java/"><div class="name">Java</div><div class="badge">(28)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/Java/JVM/" href="/categories/Java/JVM/"><div class="name">JVM</div><div class="badge">(10)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/Java/Java并发编程/" href="/categories/Java/Java并发编程/"><div class="name">Java并发编程</div><div class="badge">(8)</div></a></li>
        
          <li><a class="flat-box" title="/categories/Linux/" href="/categories/Linux/"><div class="name">Linux</div><div class="badge">(10)</div></a></li>
        
          <li><a class="flat-box" title="/categories/OpenCV/" href="/categories/OpenCV/"><div class="name">OpenCV</div><div class="badge">(5)</div></a></li>
        
          <li><a class="flat-box" title="/categories/Python/" href="/categories/Python/"><div class="name">Python</div><div class="badge">(3)</div></a></li>
        
          <li><a class="flat-box" title="/categories/computer-science/" href="/categories/computer-science/"><div class="name">computer science</div><div class="badge">(11)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/computer-science/计算机网络/" href="/categories/computer-science/计算机网络/"><div class="name">计算机网络</div><div class="badge">(7)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/computer-science/设计模式/" href="/categories/computer-science/设计模式/"><div class="name">设计模式</div><div class="badge">(4)</div></a></li>
        
          <li><a class="flat-box" title="/categories/分布式/" href="/categories/分布式/"><div class="name">分布式</div><div class="badge">(14)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/分布式/Redis/" href="/categories/分布式/Redis/"><div class="name">Redis</div><div class="badge">(3)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/分布式/zookeeper/" href="/categories/分布式/zookeeper/"><div class="name">zookeeper</div><div class="badge">(5)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/分布式/消息队列/" href="/categories/分布式/消息队列/"><div class="name">消息队列</div><div class="badge">(6)</div></a></li>
        
          <li><a class="flat-box" title="/categories/善用佳软/" href="/categories/善用佳软/"><div class="name">善用佳软</div><div class="badge">(9)</div></a></li>
        
          <li><a class="flat-box" title="/categories/图像处理/" href="/categories/图像处理/"><div class="name">图像处理</div><div class="badge">(3)</div></a></li>
        
          <li><a class="flat-box" title="/categories/数据库/" href="/categories/数据库/"><div class="name">数据库</div><div class="badge">(5)</div></a></li>
        
      </ul>
    </div>
  </section>


            
          
        
          
          
        
          
          
        
      
        
          
          
        
          
          
        
          
          
        
          
          
            
              
  <section class="widget tagcloud">
    
<header class="pure">
  <div><i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;热门标签</div>
  
    <a class="rightBtn" rel="nofollow" href="/blog/tags/" title="blog/tags/">
    <i class="fas fa-expand-arrows-alt fa-fw"></i></a>
  
</header>

    <div class="content pure">
      <a href="/tags/MQ/" style="font-size: 14px; color: #999">MQ</a> <a href="/tags/RocketMQ/" style="font-size: 14.83px; color: #939393">RocketMQ</a> <a href="/tags/anaconda/" style="font-size: 14px; color: #999">anaconda</a> <a href="/tags/arp/" style="font-size: 14px; color: #999">arp</a> <a href="/tags/c/" style="font-size: 20.67px; color: #6c6c6c">c</a> <a href="/tags/c/" style="font-size: 24px; color: #555">c++</a> <a href="/tags/caffe/" style="font-size: 15.67px; color: #8e8e8e">caffe</a> <a href="/tags/darknet/" style="font-size: 14.83px; color: #939393">darknet</a> <a href="/tags/dataset/" style="font-size: 14.83px; color: #939393">dataset</a> <a href="/tags/deeplearning/" style="font-size: 22.33px; color: #606060">deeplearning</a> <a href="/tags/dns/" style="font-size: 14px; color: #999">dns</a> <a href="/tags/docker/" style="font-size: 14.83px; color: #939393">docker</a> <a href="/tags/ffmpeg/" style="font-size: 14px; color: #999">ffmpeg</a> <a href="/tags/gc/" style="font-size: 14px; color: #999">gc</a> <a href="/tags/git/" style="font-size: 14px; color: #999">git</a> <a href="/tags/http/" style="font-size: 14px; color: #999">http</a> <a href="/tags/idea/" style="font-size: 14px; color: #999">idea</a> <a href="/tags/imagenet/" style="font-size: 14px; color: #999">imagenet</a> <a href="/tags/java/" style="font-size: 23.17px; color: #5b5b5b">java</a> <a href="/tags/jvm/" style="font-size: 20.67px; color: #6c6c6c">jvm</a> <a href="/tags/k8s/" style="font-size: 14px; color: #999">k8s</a> <a href="/tags/linux/" style="font-size: 21.5px; color: #666">linux</a> <a href="/tags/mac/" style="font-size: 14px; color: #999">mac</a> <a href="/tags/machinelearning/" style="font-size: 14px; color: #999">machinelearning</a> <a href="/tags/markdown/" style="font-size: 14px; color: #999">markdown</a> <a href="/tags/maven/" style="font-size: 15.67px; color: #8e8e8e">maven</a> <a href="/tags/mybatis/" style="font-size: 15.67px; color: #8e8e8e">mybatis</a> <a href="/tags/mysql/" style="font-size: 17.33px; color: #828282">mysql</a> <a href="/tags/network/" style="font-size: 17.33px; color: #828282">network</a> <a href="/tags/numpy/" style="font-size: 14px; color: #999">numpy</a> <a href="/tags/opencv/" style="font-size: 19px; color: #777">opencv</a> <a href="/tags/protobuf/" style="font-size: 14px; color: #999">protobuf</a> <a href="/tags/python/" style="font-size: 15.67px; color: #8e8e8e">python</a> <a href="/tags/rabbitmq/" style="font-size: 14.83px; color: #939393">rabbitmq</a> <a href="/tags/redis/" style="font-size: 15.67px; color: #8e8e8e">redis</a> <a href="/tags/shell/" style="font-size: 14px; color: #999">shell</a> <a href="/tags/spring/" style="font-size: 15.67px; color: #8e8e8e">spring</a> <a href="/tags/spring-mvc/" style="font-size: 14px; color: #999">spring mvc</a> <a href="/tags/springboot/" style="font-size: 16.5px; color: #888">springboot</a> <a href="/tags/springcloud/" style="font-size: 15.67px; color: #8e8e8e">springcloud</a> <a href="/tags/ssh/" style="font-size: 14px; color: #999">ssh</a> <a href="/tags/stl/" style="font-size: 20.67px; color: #6c6c6c">stl</a> <a href="/tags/tcp/" style="font-size: 14px; color: #999">tcp</a> <a href="/tags/tcp-ip/" style="font-size: 14px; color: #999">tcp/ip</a> <a href="/tags/tensorflow/" style="font-size: 16.5px; color: #888">tensorflow</a> <a href="/tags/ubuntu/" style="font-size: 15.67px; color: #8e8e8e">ubuntu</a> <a href="/tags/udp/" style="font-size: 14px; color: #999">udp</a> <a href="/tags/zookeeper/" style="font-size: 17.33px; color: #828282">zookeeper</a> <a href="/tags/事务/" style="font-size: 14px; color: #999">事务</a> <a href="/tags/分布式/" style="font-size: 14.83px; color: #939393">分布式</a> <a href="/tags/动态代理/" style="font-size: 14px; color: #999">动态代理</a> <a href="/tags/反射/" style="font-size: 14px; color: #999">反射</a> <a href="/tags/图像处理/" style="font-size: 15.67px; color: #8e8e8e">图像处理</a> <a href="/tags/图片素材/" style="font-size: 14px; color: #999">图片素材</a> <a href="/tags/存储引擎/" style="font-size: 14px; color: #999">存储引擎</a> <a href="/tags/学习资料/" style="font-size: 14px; color: #999">学习资料</a> <a href="/tags/工具/" style="font-size: 14.83px; color: #939393">工具</a> <a href="/tags/并发工具类/" style="font-size: 14px; color: #999">并发工具类</a> <a href="/tags/并发编程/" style="font-size: 19.83px; color: #717171">并发编程</a> <a href="/tags/数据增强/" style="font-size: 14px; color: #999">数据增强</a> <a href="/tags/模型评估/" style="font-size: 14px; color: #999">模型评估</a> <a href="/tags/正则表达式/" style="font-size: 14px; color: #999">正则表达式</a> <a href="/tags/消息队列/" style="font-size: 18.17px; color: #7d7d7d">消息队列</a> <a href="/tags/管程/" style="font-size: 14px; color: #999">管程</a> <a href="/tags/网站/" style="font-size: 18.17px; color: #7d7d7d">网站</a> <a href="/tags/设计模式/" style="font-size: 17.33px; color: #828282">设计模式</a> <a href="/tags/通信协议/" style="font-size: 14px; color: #999">通信协议</a> <a href="/tags/音频处理/" style="font-size: 14px; color: #999">音频处理</a>
    </div>
  </section>


            
          
        
          
          
        
      
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
      
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
      
    

  
</aside>

<footer id="footer" class="clearfix">
  
  
    <div class="social-wrapper">
      
        
          <a href="/atom.xml" class="social fas fa-rss flat-btn" target="_blank" rel="external nofollow noopener noreferrer">
          </a>
        
      
        
          <a href="mailto:shuiyujie.cn@gmail.com" class="social fas fa-envelope flat-btn" target="_blank" rel="external nofollow noopener noreferrer">
          </a>
        
      
        
          <a href="https://github.com/YujieShui" class="social fab fa-github flat-btn" target="_blank" rel="external nofollow noopener noreferrer">
          </a>
        
      
    </div>
  
  <br>
  <div><p>博客内容遵循 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0) 协议</a></p>
</div>
  <div>
    本站使用
    <a href="https://xaoxuu.com/wiki/material-x/" target="_blank" class="codename">Material X</a>
    作为主题
    
      ，
      总访问量为
      <span id="busuanzi_value_site_pv"><i class="fas fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span>
      次
    
    。
  </div>
</footer>
<script>setLoadingBarProgress(80);</script>


      <script>setLoadingBarProgress(60);</script>
    </div>
    <a class="s-top fas fa-arrow-up fa-fw" href='javascript:void(0)'></a>
  </div>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>

  <script>
    var GOOGLE_CUSTOM_SEARCH_API_KEY = "";
    var GOOGLE_CUSTOM_SEARCH_ENGINE_ID = "";
    var ALGOLIA_API_KEY = "";
    var ALGOLIA_APP_ID = "";
    var ALGOLIA_INDEX_NAME = "";
    var AZURE_SERVICE_NAME = "";
    var AZURE_INDEX_NAME = "";
    var AZURE_QUERY_KEY = "";
    var BAIDU_API_ID = "";
    var SEARCH_SERVICE = "hexo" || "hexo";
    var ROOT = "/"||"/";
    if(!ROOT.endsWith('/'))ROOT += '/';
  </script>

<script src="//instant.page/1.2.2" type="module" integrity="sha384-2xV8M5griQmzyiY3CDqh1dn4z3llDVqZDqzjzcY+jCBCk/a5fXJmuZ/40JJAPeoU"></script>


  <script async src="https://cdn.jsdelivr.net/npm/scrollreveal@4.0.5/dist/scrollreveal.min.js"></script>
  <script type="text/javascript">
    $(function() {
      const $reveal = $('.reveal');
      if ($reveal.length === 0) return;
      const sr = ScrollReveal({ distance: 0 });
      sr.reveal('.reveal');
    });
  </script>


  <script src="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.js"></script>
  <script type="text/javascript">
    $(function() {
      Waves.attach('.flat-btn', ['waves-button']);
      Waves.attach('.float-btn', ['waves-button', 'waves-float']);
      Waves.attach('.float-btn-light', ['waves-button', 'waves-float', 'waves-light']);
      Waves.attach('.flat-box', ['waves-block']);
      Waves.attach('.float-box', ['waves-block', 'waves-float']);
      Waves.attach('.waves-image');
      Waves.init();
    });
  </script>


  <script async src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-busuanzi@2.3/js/busuanzi.pure.mini.js"></script>




  
  
  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-backstretch/2.0.4/jquery.backstretch.min.js"></script>
    <script type="text/javascript">
      $(function(){
        if ('') {
          $('').backstretch(
          ["http://image.shuiyujie.com/sunset-2191645.jpg"],
          {
            duration: "6000",
            fade: "2500"
          });
        } else {
          $.backstretch(
          ["http://image.shuiyujie.com/sunset-2191645.jpg"],
          {
            duration: "6000",
            fade: "2500"
          });
        }
      });
    </script>
  











  <script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-material-x@19.9/js/app.js"></script>


  <script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-material-x@19.9/js/search.js"></script>




<!-- 复制 -->
<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  let COPY_SUCCESS = "复制成功";
  let COPY_FAILURE = "复制失败";
  /*页面载入完成后，创建复制按钮*/
  !function (e, t, a) {
    /* code */
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '  <i class="fa fa-copy"></i><span>复制</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });

      clipboard.on('success', function(e) {
        //您可以加入成功提示
        console.info('Action:', e.action);
        console.info('Text:', e.text);
        console.info('Trigger:', e.trigger);
        success_prompt(COPY_SUCCESS);
        e.clearSelection();
      });
      clipboard.on('error', function(e) {
        //您可以加入失败提示
        console.error('Action:', e.action);
        console.error('Trigger:', e.trigger);
        fail_prompt(COPY_FAILURE);
      });
    }
    initCopyCode();

  }(window, document);

  /**
   * 弹出式提示框，默认1.5秒自动消失
   * @param message 提示信息
   * @param style 提示样式，有alert-success、alert-danger、alert-warning、alert-info
   * @param time 消失时间
   */
  var prompt = function (message, style, time)
  {
      style = (style === undefined) ? 'alert-success' : style;
      time = (time === undefined) ? 1500 : time*1000;
      $('<div>')
          .appendTo('body')
          .addClass('alert ' + style)
          .html(message)
          .show()
          .delay(time)
          .fadeOut();
  };

  // 成功提示
  var success_prompt = function(message, time)
  {
      prompt(message, 'alert-success', time);
  };

  // 失败提示
  var fail_prompt = function(message, time)
  {
      prompt(message, 'alert-danger', time);
  };

  // 提醒
  var warning_prompt = function(message, time)
  {
      prompt(message, 'alert-warning', time);
  };

  // 信息提示
  var info_prompt = function(message, time)
  {
      prompt(message, 'alert-info', time);
  };

</script>


<!-- fancybox -->
<script src="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>
<script>
  let LAZY_LOAD_IMAGE = "";
  $(".article-entry").find("fancybox").find("img").each(function () {
      var element = document.createElement("a");
      $(element).attr("data-fancybox", "gallery");
      $(element).attr("href", $(this).attr("src"));
      /* 图片采用懒加载处理时,
       * 一般图片标签内会有个属性名来存放图片的真实地址，比如 data-original,
       * 那么此处将原本的属性名src替换为对应属性名data-original,
       * 修改如下
       */
       if (LAZY_LOAD_IMAGE) {
         $(element).attr("href", $(this).attr("data-original"));
       }
      $(this).wrap(element);
  });
</script>





  <script>setLoadingBarProgress(100);</script>
</body>
</html>
